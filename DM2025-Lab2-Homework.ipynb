{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Student Information**\n",
    "Name: 郭揉香\n",
    "\n",
    "Student ID： 313700031\n",
    "\n",
    "GitHub ID: Kuo-Jou-Hsiang\n",
    "\n",
    "Kaggle name: Jou Hsiang, Kuo\n",
    "\n",
    "Kaggle private scoreboard snapshot: \n",
    "\n",
    "![result.png](photo\\results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Instructions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab we have divided the assignments into **three phases/parts**. The `first two phases` refer to the `exercises inside the Master notebooks` of the [DM2025-Lab2-Exercise Repo](https://github.com/difersalest/DM2025-Lab2-Exercise.git). The `third phase` refers to an `internal Kaggle competition` that we are gonna run among all the Data Mining students. Together they add up to `100 points` of your grade. There are also some `bonus points` to be gained if you complete `extra exercises` in the lab **(bonus 15 pts)** and in the `Kaggle Competition report` **(bonus 5 pts)**.\n",
    "\n",
    "**Environment recommendations to solve lab 2:**\n",
    "- **Phase 1 exercises:** Need GPU for training the models explained in that part, if you don't have a GPU in your laptop it is recommended to run in Colab or Kaggle for a faster experience, although with CPU they can still be solved but with a slower execution.\n",
    "- **Phase 2 exercises:** We use Gemini's API so everything can be run with only CPU without a problem.\n",
    "- **Phase 3 exercises:** For the competition you will probably need GPU to train your models, so it is recommended to use Colab or Kaggle if you don't have a laptop with a dedicated GPU.\n",
    "- **Optional Ollama Notebook (not graded):** You need GPU, at least 4GB of VRAM with 16 GB of RAM to run the local open-source LLM models. \n",
    "\n",
    "## **Phase 1 (30 pts):**\n",
    "\n",
    "1. __Main Exercises (25 pts):__ Do the **take home exercises** from Sections: `1. Data Preparation` to `9. High-dimension Visualization: t-SNE and UMAP`, in the [DM2025-Lab2-Master-Phase_1 Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_1.ipynb). Total: `8 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 3th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "## **Phase 2 (30 pts):**\n",
    "\n",
    "1. **Main Exercises (25 pts):** Do the remaining **take home exercises** from Section: `2. Large Language Models (LLMs)` in the [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb). Total: `5 exercises required from sections 2.1, 2.2, 2.4 and 2.6`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "3. **`Bonus (15 pts):`** Complete the bonus exercises in the [DM2025-Lab2-Master-Phase_2_Bonus Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Bonus.ipynb) and [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb) `where 2 exercises are counted as bonus from sections 2.3 and 2.5 in the main notebook`. Total: `7 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "## **Phase 3 (40 pts):**\n",
    "\n",
    "1. **Kaggle Competition Participation (30 pts):** Participate in the in-class **Kaggle Competition** regarding Emotion Recognition on Twitter by clicking in this link: **[Data Mining Class Kaggle Competition](https://www.kaggle.com/t/3a2df4c6d6b4417e8bf718ed648d7554)**. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20 pts of the 30 pts in this competition participation part.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**. Make sure to take a screenshot of your position at the end of the competition and store it as `pic_ranking.png` under the `pics` folder of this repository and rerun the cell **Student Information**.\n",
    "\n",
    "2. **Competition Report (10 pts)** A report section to be filled in inside this notebook in Markdown Format, we already provided you with the template below. You need to describe your work developing the model for the competition. The report should include a section describing briefly the following elements: \n",
    "* Your preprocessing steps.\n",
    "* The feature engineering steps.\n",
    "* Explanation of your model.\n",
    "\n",
    "* **`Bonus (5 pts):`**\n",
    "    * You will have to describe more detail in the previous steps.\n",
    "    * Mention different things you tried.\n",
    "    * Mention insights you gained. \n",
    "\n",
    "[Markdown Guide - Basic Syntax](https://www.markdownguide.org/basic-syntax/)\n",
    "\n",
    "**`Things to note for Phase 3:`**\n",
    "\n",
    "* **The code used for the competition should be in this Jupyter Notebook File** `DM2025-Lab2-Homework.ipynb`.\n",
    "\n",
    "* **Push the code used for the competition to your repository**.\n",
    "\n",
    "* **The code should have a clear separation for the same sections of the report, preprocessing, feature engineering and model explanation. Briefly comment your code for easier understanding, we provide a template at the end of this notebook.**\n",
    "\n",
    "* Showing the kaggle screenshot of the ranking plus the code in this notebook will ensure the validity of your participation and the report to obtain the corresponding points.\n",
    "\n",
    "After the competition ends you will have two days more to submit the `DM2025-Lab2-Homework.ipynb` with your report in markdown format and your code. Do everything **`BEFORE the deadline (Nov. 26th, 11:59 pm, Wednesday) to obtain 100% of the available points.`**\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding NTU Cool assignment.\n",
    "\n",
    "## **Deadlines:**\n",
    "\n",
    "![lab2_deadlines](./pics/lab2_deadlines.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Next you will find the template report with some simple markdown syntax explanations, use it to structure your content.\n",
    "\n",
    "You can delete the syntax suggestions after you use them.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Project Report**\n",
    "\n",
    "\n",
    "## 1. Model Development (10 pts Required)\n",
    "\n",
    "### **1.1 Preprocessing Steps**\n",
    "\n",
    "#### **1.1.1 Data Parsing & Extraction**\n",
    "\n",
    "* Read the data and navigate its nested structure `root` -> `_source` -> `post` to extract the required data: `post_id` (article ID) and `text` (article content)\n",
    "* Flatten the data into a LIST and convert it into a Pandas DataFrame\n",
    "\n",
    "####  **1.1.2 Data Integration**\n",
    "\n",
    "* Three tables are created after preprocessing:\n",
    "    * `posts_df`: Original post text\n",
    "    * `emotion_df`: Emotion labels\n",
    "    * `split_df`: Data split into train/test\n",
    "* Merge the three datasets and separate them into training and testing sets\n",
    "\n",
    "#### **1.1.3 Data Cleaning**\n",
    "\n",
    "* `dropna`: Remove rows where content is empty (NaN) or has no corresponding label\n",
    "    * Missing text content causes Tokenizer errors\n",
    "* `.astype(str)`: Force conversion of text columns to string format\n",
    "    * Numeric text content might be misidentified as floats; forcing string conversion ensures consistent formatting\n",
    "\n",
    "#### **1.1.4 Label Encoding**\n",
    "\n",
    "* Use `LabelEncoder` to convert emotion string labels into IDs (0, 1) to facilitate model training, and subsequently convert them back to original text via `inverse_transform`\n",
    "\n",
    "#### **1.1.5 Train/Validation Splitting**\n",
    "\n",
    "* Use `train_test_split` to carve out another 10% from the original training data as a validation set, and set `stratify`\n",
    "* `stratify` ensures that the proportion of various emotions in the extracted 10% data is completely consistent with the original data\n",
    "\n",
    "### **1.2 Feature Engineering Steps**\n",
    "\n",
    "#### **1.2.1 HF Dataset Formatting**\n",
    "\n",
    "* Convert pandas DataFrame to HuggingFace Dataset\n",
    "* Use the `.map()` function for batch `Tokenization` and convert the format to PyTorch tensors (`set_format(\"torch\")`)\n",
    "\n",
    "#### **1.2.2 Tokenization**\n",
    "\n",
    "* Used the `vinai/bertweet-base` tokenizer; this model is pre-trained on a large amount of tweet data and handles social media text features like colloquialisms, abbreviations, Hashtags, or Emojis better than standard BERT\n",
    "* `max_length=128`, a setting suitable for tweet lengths\n",
    "\n",
    "### **1.3 Explanation of Your Model**\n",
    "\n",
    "* Model architecture\n",
    "    * Use `AutoModelForSequenceClassification` to load `bertweet-base` and modify the final fully connected layer (Head) to match `num_labels`\n",
    "* Training Strategy\n",
    "    * `learning_rate=2e-5`: Standard LR for fine-tuning BERT models\n",
    "    * `num_train_epochs=4`: Too many epochs can easily lead to Overfitting\n",
    "    * `eval_strategy=\"epoch\"`: Perform evaluation once per epoch\n",
    "    * `load_best_model_at_end=True` + `metric_for_best_model=\"macro_f1\"`: Ensures that the model retained at the end is the one with the highest F1 score on the validation set\n",
    "    * `optim=\"adamw_torch\"`\n",
    "    * `Metric`: Adopts Macro F1 Score, suitable when data is imbalanced\n",
    "---\n",
    "\n",
    "## 2. Bonus Section (5 pts Optional)\n",
    "\n",
    "### 2.1 Mention Different Things You Tried\n",
    "\n",
    "* Dataset Balancing Approaches：\n",
    "Given the class imbalance in the dataset, multiple balancing strategies were evaluated:\n",
    "  * Random oversampling\n",
    "  * Class-weighted loss\n",
    "  * Focal Loss to make the model more sensitive to minority emotions\n",
    "These attempts aimed to improve recall for low-frequency classes such as fear and disgust.\n",
    "\n",
    "* Model Architecture Experiments：\n",
    "Different transformer-based models were tried and compared:\n",
    "  * BERTweet-base (best fit for social media text)\n",
    "  * BERT-base (baseline)\n",
    "  * RoBERTa-base\n",
    "  * Ensemble of multiple models using soft voting\n",
    "Experiments showed that domain-specific pretraining (like BERTweet) consistently improved downstream performance.\n",
    "\n",
    "### 2.2 Mention Insights You Gained\n",
    "\n",
    "* Domain-specific models outperform general models：\n",
    "Models pretrained on Twitter-like data (e.g., BERTweet) consistently outperformed general-purpose transformers.\n",
    "This confirms that domain adaptation is critical for short, noisy, emoji-rich texts.\n",
    "* Aggressive text cleaning hurts performance：\n",
    "Removing emojis, hashtags, or informal expressions significantly reduces emotional cues.\n",
    "Lighter cleaning (preserving sentiment-bearing symbols) yielded better performance.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`From here on starts the code section for the competition.`**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Competition Code**\n",
    "\n",
    "## 1. Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add the code related to the preprocessing steps in cells inside this section\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Load the main text dataset\n",
    "file_path_json = \"dm-lab-2-private-competition/final_posts.json\"\n",
    "\n",
    "with open(file_path_json, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "# extract post_id and text\n",
    "parsed_rows = []\n",
    "for item in raw_data:\n",
    "    post = item[\"root\"][\"_source\"][\"post\"]\n",
    "    parsed_rows.append({\n",
    "        \"id\": post[\"post_id\"],\n",
    "        \"text\": post[\"text\"]\n",
    "    })\n",
    "\n",
    "posts_df = pd.DataFrame(parsed_rows)\n",
    "print(\"Posts dataset loaded.\")\n",
    "\n",
    "# 2. Load Metadata and Merge\n",
    "emotion_df = pd.read_csv(\"dm-lab-2-private-competition/emotion.csv\")\n",
    "split_df = pd.read_csv(\"dm-lab-2-private-competition/data_identification.csv\")\n",
    "\n",
    "# Merge text + split info\n",
    "merged_df = posts_df.merge(split_df, on=\"id\", how=\"left\")\n",
    "\n",
    "# Create initial training and testing sets\n",
    "train_df_full = merged_df[merged_df[\"split\"] == \"train\"].merge(emotion_df, on=\"id\", how=\"left\")\n",
    "test_df = merged_df[merged_df[\"split\"] == \"test\"]\n",
    "\n",
    "# 3. Cleaning and Label Encoding\n",
    "train_df_full = train_df_full.dropna(subset=[\"text\", \"emotion\"]).reset_index(drop=True)\n",
    "test_df = test_df.dropna(subset=[\"text\"]).reset_index(drop=True)\n",
    "\n",
    "# Force conversion of text columns to string format\n",
    "train_df_full[\"text\"] = train_df_full[\"text\"].astype(str)\n",
    "test_df[\"text\"] = test_df[\"text\"].astype(str)\n",
    "\n",
    "# Label Encoding\n",
    "le = LabelEncoder()\n",
    "train_df_full[\"label\"] = le.fit_transform(train_df_full[\"emotion\"])\n",
    "num_labels = len(le.classes_)\n",
    "\n",
    "print(f\"Classes found: {le.classes_}\")\n",
    "print(f\"Number of labels: {num_labels}\")\n",
    "\n",
    "# 4. Train/Validation Split\n",
    "train_df, valid_df = train_test_split(\n",
    "    train_df_full,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=train_df_full[\"label\"]\n",
    ")\n",
    "\n",
    "print(f\"Final Train size: {len(train_df)}, Valid size: {len(valid_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add the code related to the feature engineering steps in cells inside this section\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "#1. Initialize Tokenizer\n",
    "model_name = \"vinai/bertweet-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "#2. Convert to Hugging Face Datasets \n",
    "train_ds = Dataset.from_pandas(train_df[[\"id\", \"text\", \"label\"]])\n",
    "valid_ds = Dataset.from_pandas(valid_df[[\"id\", \"text\", \"label\"]])\n",
    "test_ds  = Dataset.from_pandas(test_df[[\"id\", \"text\"]])\n",
    "\n",
    "#3. Apply Tokenization\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "# Map the function (batch processing is faster)\n",
    "train_ds_tok = train_ds.map(tokenize_batch, batched=True)\n",
    "valid_ds_tok = valid_ds.map(tokenize_batch, batched=True)\n",
    "test_ds_tok  = test_ds.map(tokenize_batch, batched=True)\n",
    "\n",
    "#4. Format for PyTorch\n",
    "# Remove raw text column as model only needs input_ids/attention_mask\n",
    "cols_to_remove = [\"text\"]\n",
    "train_ds_tok = train_ds_tok.remove_columns(cols_to_remove)\n",
    "valid_ds_tok = valid_ds_tok.remove_columns(cols_to_remove)\n",
    "test_ds_tok  = test_ds_tok.remove_columns(cols_to_remove)\n",
    "\n",
    "# Set format\n",
    "train_ds_tok.set_format(\"torch\")\n",
    "valid_ds_tok.set_format(\"torch\")\n",
    "test_ds_tok.set_format(\"torch\")\n",
    "\n",
    "print(\"Tokenization complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Implementation Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add the code related to the model implementation steps in cells inside this section\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# 1. Model Initialization\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels\n",
    ").to(device)\n",
    "\n",
    "# 2. Define Metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    macro_f1 = f1_score(labels, preds, average=\"macro\")\n",
    "    return {\"accuracy\": acc, \"macro_f1\": macro_f1}\n",
    "\n",
    "# 3. Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results/bertweet_emotion\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"macro_f1\",\n",
    "    greater_is_better=True,\n",
    "    logging_steps=100,\n",
    "    optim=\"adamw_torch\"\n",
    ")\n",
    "\n",
    "# 4. Trainer Execution\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds_tok,\n",
    "    eval_dataset=valid_ds_tok,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "# 5. Evaluation & Prediction\n",
    "# Evaluate on Validation Set\n",
    "print(\"Evaluating on validation set...\")\n",
    "eval_result = trainer.evaluate()\n",
    "print(eval_result)\n",
    "\n",
    "# Generate detailed report\n",
    "valid_logits, valid_labels, _ = trainer.predict(valid_ds_tok)\n",
    "valid_preds = np.argmax(valid_logits, axis=-1)\n",
    "print(classification_report(valid_labels, valid_preds, target_names=list(le.classes_)))\n",
    "\n",
    "# Predict on Test Set\n",
    "print(\"Predicting on test set...\")\n",
    "test_logits, _, _ = trainer.predict(test_ds_tok)\n",
    "test_preds = np.argmax(test_logits, axis=-1)\n",
    "\n",
    "# 6. Create Submission\n",
    "test_emotions = le.inverse_transform(test_preds)\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": test_df[\"id\"],\n",
    "    \"emotion\": test_emotions\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission_bertweet.csv\", index=False)\n",
    "print(\"Submission saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM2025-Lab2-Exercise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
