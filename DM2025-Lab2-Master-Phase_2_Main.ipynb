{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Data Mining Lab 2 - Phase 2](#toc1_)    \n",
    "  - [Before Starting](#toc1_1_)    \n",
    "  - [Introduction](#toc1_2_)    \n",
    "  - [**1. Data Preparation**](#toc1_3_)    \n",
    "  - [**1.1 Load data**](#toc1_4_)    \n",
    "    - [**1.2 Save data**](#toc1_4_1_)    \n",
    "  - [**2. Large Language Models (LLMs)**](#toc1_5_)    \n",
    "    - [Open-Source vs. Proprietary LLMs](#toc1_5_1_)    \n",
    "    - [Why Use Code (API) for Data Mining?](#toc1_5_2_)    \n",
    "    - [The Gemini API](#toc1_5_3_)    \n",
    "    - [Interacting with the Gemini API](#toc1_5_4_)    \n",
    "    - [**2.1 Text Prompting**](#toc1_5_5_)    \n",
    "        - [**>>> Exercise 1 (Take home):**](#toc1_5_5_1_1_)    \n",
    "    - [**2.2 Structured Output**](#toc1_5_6_)    \n",
    "        - [**>>> Exercise 2 (Take home):**](#toc1_5_6_1_1_)    \n",
    "    - [**2.3 Information Extraction and Grounding:**](#toc1_5_7_)    \n",
    "      - [**`langextract`: A Library for Grounded Extraction**](#toc1_5_7_1_)    \n",
    "        - [**2.3.1 Using PDF Documents:**](#toc1_5_7_1_1_)    \n",
    "        - [**>>> Bonus Exercise 3 (Take home):**](#toc1_5_7_1_2_)    \n",
    "    - [**2.4 Generating LLM Embeddings:**](#toc1_5_8_)    \n",
    "        - [**>>> Exercise 4 (Take home):**](#toc1_5_8_1_1_)    \n",
    "    - [**2.5 Retrieval-Augmented Generation (RAG)**](#toc1_5_9_)    \n",
    "        - [**Actual answer in the URL:**](#toc1_5_9_1_1_)    \n",
    "        - [**Content in the URL that might get into the generated answer because of similar semantic meaning:**](#toc1_5_9_1_2_)    \n",
    "        - [**>>> Bonus Exercise 5 (Take home):**](#toc1_5_9_1_3_)    \n",
    "    - [**2.6 Few-Shot Prompting Classification:**](#toc1_5_10_)    \n",
    "        - [**>>> Exercise 6 (Take home):**](#toc1_5_10_1_1_)    \n",
    "        - [**>>> Exercise 7 (Take home):**](#toc1_5_10_1_2_)    \n",
    "    - [**2.7 Extra LLM Related Materials:**](#toc1_5_11_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuutyCx4YTpX"
   },
   "source": [
    "# <a id='toc1_'></a>[Data Mining Lab 2 - Phase 2](#toc0_)\n",
    "In this lab's phase 2 session we will focus on exploring some basic LLMs' applications with data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Before Starting](#toc0_)\n",
    "\n",
    "**Make sure you have installed all the required libraries and you have the environment ready to run this lab.**\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIpAqCvMYTpX"
   },
   "source": [
    "---\n",
    "## <a id='toc1_2_'></a>[Introduction](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2paPeNbYTpX"
   },
   "source": [
    "**Dataset:** [SemEval 2017 Task](https://competitions.codalab.org/competitions/16380)\n",
    "\n",
    "**Task:** Classify text data into 4 different emotions using word embeddings and other deep information retrieval approaches.\n",
    "\n",
    "![pic0.png](./pics/pic0.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kuojouhsiang/Documents/DM2025-Lab2-Exercise/.venv/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "op_X7pR-YTpX"
   },
   "source": [
    "---\n",
    "## <a id='toc1_3_'></a>[**1. Data Preparation**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgoEbZzSYTpX"
   },
   "source": [
    "---\n",
    "## <a id='toc1_4_'></a>[**1.1 Load data**](#toc0_)\n",
    "\n",
    "We start by loading the csv files into a single pandas dataframe for training and one for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "anfjcPSSYTpX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "### training data\n",
    "anger_train = pd.read_csv(\"data/semeval/train/anger-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None,names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "sadness_train = pd.read_csv(\"data/semeval/train/sadness-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "fear_train = pd.read_csv(\"data/semeval/train/fear-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "joy_train = pd.read_csv(\"data/semeval/train/joy-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yVc2T5MIYTpX"
   },
   "outputs": [],
   "source": [
    "# combine 4 sub-dataset\n",
    "train_df = pd.concat([anger_train, fear_train, joy_train, sadness_train], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Kw8bGMv7YTpX",
    "outputId": "9f6f7052-302e-4794-ef69-b84450b61b36"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>So my Indian Uber driver just called someone t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>@DPD_UK I asked for my parcel to be delivered ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text emotion  intensity\n",
       "0  10000  How the fu*k! Who the heck! moved my fridge!.....   anger      0.938\n",
       "1  10001  So my Indian Uber driver just called someone t...   anger      0.896\n",
       "2  10002  @DPD_UK I asked for my parcel to be delivered ...   anger      0.896\n",
       "3  10003  so ef whichever butt wipe pulled the fire alar...   anger      0.896\n",
       "4  10004  Don't join @BTCare they put the phone down on ...   anger      0.896"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### testing data\n",
    "anger_test = pd.read_csv(\"data/semeval/dev/anger-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "sadness_test = pd.read_csv(\"data/semeval/dev/sadness-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "fear_test = pd.read_csv(\"data/semeval/dev/fear-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "joy_test = pd.read_csv(\"data/semeval/dev/joy-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "\n",
    "# combine 4 sub-dataset\n",
    "test_df = pd.concat([anger_test, fear_test, joy_test, sadness_test], ignore_index=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HBHwcL8sYTpX"
   },
   "outputs": [],
   "source": [
    "# shuffle dataset\n",
    "train_df = train_df.sample(frac=1)\n",
    "test_df = test_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9w_cDUwCYTpX",
    "outputId": "3582ac44-1f5f-4cb2-b833-d477f152461a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training df:  (3613, 4)\n",
      "Shape of Testing df:  (347, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Training df: \", train_df.shape)\n",
    "print(\"Shape of Testing df: \", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hr8aKhlYTpo"
   },
   "source": [
    "---\n",
    "### <a id='toc1_4_1_'></a>[**1.2 Save data**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dZzepBdpYTpo"
   },
   "outputs": [],
   "source": [
    "# save to pickle file\n",
    "train_df.to_pickle(\"./data/train_df.pkl\") \n",
    "test_df.to_pickle(\"./data/test_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "H5uO-kOUYTpo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load a pickle file\n",
    "train_df = pd.read_pickle(\"./data/train_df.pkl\")\n",
    "test_df = pd.read_pickle(\"./data/test_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sLDcQzeYTpo"
   },
   "source": [
    "For more information: https://reurl.cc/0Dzqx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <a id='toc1_5_'></a>[**2. Large Language Models (LLMs)**](#toc0_)\n",
    "\n",
    "Before we start we strongly suggest that you watch the following video explanations so you can understand the concepts that we are gonna discuss about LLMs: \n",
    "\n",
    "1. [How Large Language Models Work](https://www.youtube.com/watch?v=5sLYAQS9sWQ)\n",
    "2. [Large Language Models explained briefly](https://www.youtube.com/watch?v=LPZh9BOjkQs)\n",
    "3. [What is Prompt Tuning?](https://www.youtube.com/watch?v=yu27PWzJI_Y)\n",
    "4. [Why Large Language Models Hallucinate](https://www.youtube.com/watch?v=cfqtFvWOfg0)\n",
    "5. [What are LLM Embeddings?](https://www.youtube.com/watch?v=UShw_1NbpCw&t=182s)\n",
    "6. [What is Retrieval-Augmented Generation (RAG)?](https://www.youtube.com/watch?v=T-D1OfcDW1M)\n",
    "7. [RAG vs Fine-Tuning vs Prompt Engineering: Optimizing AI Models](https://www.youtube.com/watch?v=zYGDpG-pTho)\n",
    "8. [Discover Few-Shot Prompting | Google AI Essentials](https://www.youtube.com/watch?v=9qdgEBVkWR4)\n",
    "9. [What is Zero-Shot Learning?](https://www.youtube.com/watch?v=pVpr4GYLzAo)\n",
    "10. [Zero-shot, One-shot and Few-shot Prompting Explained | Prompt Engineering 101](https://www.youtube.com/watch?v=sW5xoicq5TY)\n",
    "\n",
    "`These videos can help you get a better grasp on the core concepts of LLMs if you were not familiar before.`\n",
    "\n",
    "**So now let's start with the main content of Lab 2 Phase 2.**\n",
    "\n",
    "Large Language Models (LLMs) are AI systems trained on vast amounts of text to understand and generate human language for tasks like summarization and translation.\n",
    "\n",
    "### <a id='toc1_5_1_'></a>[Open-Source vs. Proprietary LLMs](#toc0_)\n",
    "*   **Open-Source Models** (e.g., Llama, Gemma) are customizable and cost-effective but require technical skill to manage and may be less powerful.\n",
    "*   **Proprietary Models** (e.g., Gemini, ChatGPT) offer top performance and ease of use but are more costly and less flexible.\n",
    "\n",
    "For students interested in running models locally, the optional notebook `DM2025-Lab2-Optional-Ollama.ipynb` explores using Ollama ([Ollama GitHub Link](https://github.com/ollama/ollama)). It needs a capable GPU to run models (**at least 4GB VRAM**).\n",
    "\n",
    "You can explore the variety of models available through Ollama here:\n",
    "\n",
    "![pic10.png](./pics/pic10.png)\n",
    "\n",
    "### <a id='toc1_5_2_'></a>[Why Use Code (API) for Data Mining?](#toc0_)\n",
    "\n",
    "For data analysis, accessing LLMs programmatically is superior to using web chatbots because it allows for:\n",
    "*   **Automation:** Easily process entire datasets with loops.\n",
    "*   **Structured Output:** Receive data in usable formats like **JSON**, ready for analysis in tools like pandas.\n",
    "*   **Reproducibility:** Ensure consistent results by setting fixed parameters.\n",
    "*   **Privacy:** Maintain data security, especially when running models locally.\n",
    "\n",
    "For the main exercises in this lab, we will use **the Gemini API**. This approach offers several advantages over running local open-source models, such as access to state-of-the-art model performance without needing specialized hardware. While the API has usage limits (rate limits and token quotas), it provides a generous **free tier** that is more than sufficient for our exercises.\n",
    "\n",
    "![pic13.png](./pics/pic13.png)\n",
    "\n",
    "![pic14.png](./pics/pic14.png)\n",
    "\n",
    "### <a id='toc1_5_3_'></a>[The Gemini API](#toc0_)\n",
    "\n",
    "We will primarily use the **Gemini 2.5 Flash-Lite** (`gemini-2.5-flash-lite`) model. As shown in the rate limit table, this model is optimized for high-frequency tasks and offers a high request-per-day limit of 1,000, making it ideal for completing the lab exercises without interruption.\n",
    "\n",
    "Students are encouraged to explore other models available through the API but should remain mindful of their respective usage limits. For instance:\n",
    "*   **Gemini 2.5 Pro** is a more powerful model but has a lower daily request limit of 100.\n",
    "*   The **Gemma 3** model available via the API offers an impressive 14,400 requests per day, providing another excellent alternative for experimentation.\n",
    "\n",
    "Please be aware of your usage limits as you work through the exercises to ensure you do not get rate-limited.\n",
    "\n",
    "[Gemini Documentation](https://ai.google.dev/gemini-api/docs)\n",
    "\n",
    "[Gemini Rate Limits](https://ai.google.dev/gemini-api/docs/rate-limits)\n",
    "\n",
    "[Description of Gemini Models](https://ai.google.dev/gemini-api/docs/models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc1_5_4_'></a>[Interacting with the Gemini API](#toc0_)\n",
    "\n",
    "The code cell below contains the primary function, `prompt_gemini`, that we will use throughout this lab to communicate with the Gemini API. It's designed to be a flexible wrapper that handles the details of sending a request and receiving a response.\n",
    "\n",
    "Before you run the exercises, here are the key things you need to understand in this setup:\n",
    "\n",
    "*   **API Key Configuration**: The script loads your API key from a `.env` file located in the `./config/` directory. **You must create this file and add your API key** like this: `GOOGLE_API_KEY='YOUR_API_KEY_HERE'`. This is a security best practice to keep your credentials out of the code.\n",
    "\n",
    "*   **Global Settings**: At the top of the script, you can find and modify several important defaults:\n",
    "    *   `MODEL_NAME`: We've set this to `\"gemini-2.5-flash-lite\"`, but you can easily switch to other models like `\"gemini-2.5-pro\"` to experiment.\n",
    "    *   `SYSTEM_INSTRUCTION`: This sets the model's default behavior or persona (e.g., \"You are a helpful assistant\"). You can customize this for different tasks.\n",
    "    *   `SAFETY_SETTINGS`: For our academic exercises, these are turned off to prevent interference. In real-world applications, you would configure these carefully.\n",
    "\n",
    "*   **The `prompt_gemini` function**: This is the main tool you will use. Here are its most important parameters:\n",
    "    *   `input_prompt`: The list of contents (text, images, etc.) you want to send to the model.\n",
    "    *   `temperature`: Controls the randomness of the output. `0.0` makes the output deterministic and less creative, while a higher value (e.g., `0.7`) makes it more varied.\n",
    "    *   `schema`: A powerful feature that allows you to specify a JSON format for the model's output. This is extremely useful for structured data extraction.\n",
    "    *   `with_tokens_info`: If set to `True`, the function will also return the number of input and output tokens used, which is helpful for monitoring your usage against the free tier limits.\n",
    "\n",
    "In the following exercises, you will call this function with different prompts and configurations to solve various tasks.\n",
    "\n",
    "If needed, you can also check some tutorials on how a python function works: [Python Functions Tutorial](https://realpython.com/defining-your-own-python-function/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "env_path = \"./config/.env\"\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# System instruction that can dictate how the model behaves in the output, can be customized as needed\n",
    "SYSTEM_INSTRUCTION = (\n",
    "        \"You are a helpful assistant\"\n",
    "    )\n",
    "\n",
    "# Max amount of tokens that the model can output, the Gemini 2.5 Models have this maximum amount\n",
    "# For other models need to check their documentation \n",
    "MAX_OUTPUT_TOKENS = 65535\n",
    "MODEL_NAME = \"gemini-2.5-flash-lite\" # Other models: \"gemini-2.5-pro\", \"gemini-2.5-flash\"; Check different max output tokens: \"gemini-2.0-flash\" , \"gemini-2.0-flash-lite\" \n",
    "\n",
    "# We disable the safety settings, as no moderation is needed in our tasks\n",
    "SAFETY_SETTINGS = [\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_HATE_SPEECH\", threshold=\"OFF\"),\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_DANGEROUS_CONTENT\", threshold=\"OFF\"),\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\", threshold=\"OFF\"),\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_HARASSMENT\", threshold=\"OFF\")\n",
    "]\n",
    "\n",
    "#IMPORTANT: The script loads your API key from a `.env` file located in the `./config/` directory. \n",
    "# You must create this file and add your API key like this: `GOOGLE_API_KEY='YOUR_API_KEY_HERE'`\n",
    "\n",
    "# We input the API Key to be able to use the Gemini models\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "# We also set LangExtract to use the API key as well:\n",
    "if 'GEMINI_API_KEY' not in os.environ:\n",
    "    os.environ['GEMINI_API_KEY'] = api_key\n",
    "\n",
    "def prompt_gemini(\n",
    "        input_prompt: list,\n",
    "        schema = None,\n",
    "        temperature: float = 0.0,\n",
    "        system_instruction: str = SYSTEM_INSTRUCTION,\n",
    "        max_output_tokens: int = MAX_OUTPUT_TOKENS,\n",
    "        client: genai.Client = client,\n",
    "        model_name: str = MODEL_NAME,\n",
    "        new_config: types.GenerateContentConfig = None,\n",
    "        with_tools: bool = False,\n",
    "        with_parts: bool = False,\n",
    "        with_tokens_info: bool = False\n",
    "    ):\n",
    "        try:\n",
    "            # If we need a JSON schema we set up the following\n",
    "            if schema:\n",
    "                generate_content_config = types.GenerateContentConfig(\n",
    "                    temperature=temperature,\n",
    "                    system_instruction=system_instruction,\n",
    "                    max_output_tokens=max_output_tokens,\n",
    "                    response_modalities=[\"TEXT\"],\n",
    "                    response_mime_type=\"application/json\",\n",
    "                    response_schema=schema,\n",
    "                    safety_settings=SAFETY_SETTINGS\n",
    "                )\n",
    "            # If there is no need we leave it unstructured\n",
    "            else:\n",
    "                generate_content_config = types.GenerateContentConfig(\n",
    "                    temperature=temperature,\n",
    "                    system_instruction=system_instruction,\n",
    "                    max_output_tokens=max_output_tokens,\n",
    "                    response_modalities=[\"TEXT\"],\n",
    "                    safety_settings=SAFETY_SETTINGS\n",
    "                )\n",
    "            \n",
    "            # We add a different custom configuration if we need it\n",
    "            if new_config:\n",
    "                generate_content_config = new_config\n",
    "            \n",
    "            # For some tasks we need a more specific way to add the contents when prompting the model\n",
    "            # So we need custom parts for it sometimes from the \"types\" objects\n",
    "            if with_parts:\n",
    "                response = client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    contents=types.Content(parts=input_prompt),\n",
    "                    config=generate_content_config,\n",
    "                )\n",
    "            # In the simplest form the contents can be expressed as a list [] of simple objects like str and Pillow images\n",
    "            else:\n",
    "                response = client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    contents=input_prompt,\n",
    "                    config=generate_content_config,\n",
    "                )\n",
    "\n",
    "            if with_tools:\n",
    "                # print(response)\n",
    "                # Include raw response when function calling\n",
    "                completion = response\n",
    "                if with_tokens_info:\n",
    "                    log = {\n",
    "                        \"model\": model_name,\n",
    "                        \"input_tokens\": response.usage_metadata.prompt_token_count,\n",
    "                        \"output_tokens\": response.usage_metadata.candidates_token_count,\n",
    "                    }\n",
    "                    return completion, log\n",
    "                return completion\n",
    "            else:\n",
    "                completion = response.text\n",
    "                if with_tokens_info:\n",
    "                    log = {\n",
    "                        \"model\": model_name,\n",
    "                        \"input_tokens\": response.usage_metadata.prompt_token_count,\n",
    "                        \"output_tokens\": response.usage_metadata.candidates_token_count,\n",
    "                    }\n",
    "                    # Return the text response and logs (if selected)\n",
    "                    return completion, log\n",
    "                return completion\n",
    "        except Exception as e:\n",
    "             print(f\"Error occurred when generating response, error: {e}\")\n",
    "             return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_5_'></a>[**2.1 Text Prompting**](#toc0_)\n",
    "\n",
    "In the same way as with ChatGPT we can use the Gemini models to ask about anything. Here we are going to ask a question requesting the response to be in markdown format, this is to make it have a better display afterwards.\n",
    "\n",
    "For more information visit:\n",
    "[Gemini's Text Generation Documentation](https://ai.google.dev/gemini-api/docs/text-generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data mining is the process of **discovering patterns, insights, and knowledge from large datasets**. It's essentially about extracting valuable information that isn't immediately obvious from raw data. Think of it as sifting through a mountain of information to find hidden gems.\n",
      "\n",
      "Here's a breakdown of what that means:\n",
      "\n",
      "**Key Concepts:**\n",
      "\n",
      "*   **Large Datasets:** Data mining is typically applied to datasets that are too large and complex for manual analysis. This can include customer transaction records, website logs, sensor data, social media feeds, scientific experiment results, and much more.\n",
      "*   **Patterns and Insights:** The goal is to identify recurring trends, correlations, anomalies, and relationships within the data. These patterns can reveal underlying structures, predict future behavior, or explain observed phenomena.\n",
      "*   **Knowledge Discovery:** The ultimate aim is to transform raw data into actionable knowledge that can be used for decision-making, problem-solving, and strategic planning.\n",
      "\n",
      "**How it Works (The Process):**\n",
      "\n",
      "Data mining is usually an iterative process that involves several stages:\n",
      "\n",
      "1.  **Business Understanding:** Defining the problem or objective you want to achieve with data mining. What questions are you trying to answer? What business goals are you trying to meet?\n",
      "2.  **Data Understanding:** Exploring and getting familiar with the data. This involves collecting, cleaning, and understanding the data's structure, quality, and meaning.\n",
      "3.  **Data Preparation (Preprocessing):** This is often the most time-consuming stage. It involves:\n",
      "    *   **Cleaning:** Handling missing values, noisy data, and inconsistencies.\n",
      "    *   **Integration:** Combining data from multiple sources.\n",
      "    *   **Transformation:** Normalizing or aggregating data to make it suitable for mining.\n",
      "    *   **Reduction:** Reducing the size of the dataset while preserving important information.\n",
      "4.  **Modeling:** Selecting and applying appropriate data mining techniques (algorithms) to discover patterns. This is where the \"mining\" happens.\n",
      "5.  **Evaluation:** Assessing the quality and usefulness of the discovered patterns. Do they make sense? Are they statistically significant? Do they meet the business objectives?\n",
      "6.  **Deployment:** Putting the discovered knowledge into practice. This could involve integrating it into business processes, creating reports, or building predictive models.\n",
      "\n",
      "**Common Data Mining Techniques:**\n",
      "\n",
      "Data mining employs a variety of techniques, often drawing from statistics, machine learning, and database systems. Some of the most common include:\n",
      "\n",
      "*   **Classification:** Categorizing data into predefined classes (e.g., predicting whether a customer will churn or not).\n",
      "*   **Clustering:** Grouping similar data points together without predefined classes (e.g., segmenting customers into different groups based on their purchasing behavior).\n",
      "*   **Association Rule Mining:** Discovering relationships between items in a dataset (e.g., \"customers who buy bread also tend to buy milk\"). This is often used in market basket analysis.\n",
      "*   **Regression:** Predicting a continuous numerical value (e.g., predicting the price of a house based on its features).\n",
      "*   **Anomaly Detection (Outlier Detection):** Identifying data points that deviate significantly from the norm (e.g., detecting fraudulent transactions).\n",
      "*   **Sequential Pattern Mining:** Discovering patterns that occur in a sequence over time (e.g., identifying common user navigation paths on a website).\n",
      "\n",
      "**Why is Data Mining Important?**\n",
      "\n",
      "Data mining is crucial for businesses and organizations because it enables them to:\n",
      "\n",
      "*   **Make Better Decisions:** By understanding customer behavior, market trends, and operational efficiencies, organizations can make more informed and strategic decisions.\n",
      "*   **Improve Customer Relationships:** Identifying customer preferences and predicting their needs allows for personalized marketing, better customer service, and increased loyalty.\n",
      "*   **Detect Fraud and Risk:** Anomaly detection can help identify fraudulent activities, security breaches, and potential risks.\n",
      "*   **Optimize Operations:** Understanding patterns in operational data can lead to improved efficiency, reduced costs, and better resource allocation.\n",
      "*   **Drive Innovation:** Discovering new insights can spark new product development, service offerings, and business models.\n",
      "*   **Gain a Competitive Advantage:** Organizations that effectively leverage data mining can outperform their competitors by understanding their market and customers better.\n",
      "\n",
      "In essence, data mining is a powerful tool for transforming raw data into valuable intelligence, driving progress and innovation across various fields.\n"
     ]
    }
   ],
   "source": [
    "input_prompt = [\"What is Data Mining?\"]\n",
    "text_response, logs = prompt_gemini(input_prompt = input_prompt, with_tokens_info = True)\n",
    "print(text_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the logs of the usage with our model that we defined in our previous function. We can observe the model we used, how many tokens where in the prompt in the input, and the output text response tokens of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'gemini-2.5-flash-lite', 'input_tokens': 12, 'output_tokens': 911}\n"
     ]
    }
   ],
   "source": [
    "print(logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can use the IPython library to make the response look better:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Data mining is the process of **discovering patterns, insights, and knowledge from large datasets**. It's essentially about extracting valuable information that isn't immediately obvious from raw data. Think of it as sifting through a mountain of information to find hidden gems.\n",
       "\n",
       "Here's a breakdown of what that means:\n",
       "\n",
       "**Key Concepts:**\n",
       "\n",
       "*   **Large Datasets:** Data mining is typically applied to datasets that are too large and complex for manual analysis. This can include customer transaction records, website logs, sensor data, social media feeds, scientific experiment results, and much more.\n",
       "*   **Patterns and Insights:** The goal is to identify recurring trends, correlations, anomalies, and relationships within the data. These patterns can reveal underlying structures, predict future behavior, or explain observed phenomena.\n",
       "*   **Knowledge Discovery:** The ultimate aim is to transform raw data into actionable knowledge that can be used for decision-making, problem-solving, and strategic planning.\n",
       "\n",
       "**How it Works (The Process):**\n",
       "\n",
       "Data mining is usually an iterative process that involves several stages:\n",
       "\n",
       "1.  **Business Understanding:** Defining the problem or objective you want to achieve with data mining. What questions are you trying to answer? What business goals are you trying to meet?\n",
       "2.  **Data Understanding:** Exploring and getting familiar with the data. This involves collecting, cleaning, and understanding the data's structure, quality, and meaning.\n",
       "3.  **Data Preparation (Preprocessing):** This is often the most time-consuming stage. It involves:\n",
       "    *   **Cleaning:** Handling missing values, noisy data, and inconsistencies.\n",
       "    *   **Integration:** Combining data from multiple sources.\n",
       "    *   **Transformation:** Normalizing or aggregating data to make it suitable for mining.\n",
       "    *   **Reduction:** Reducing the size of the dataset while preserving important information.\n",
       "4.  **Modeling:** Selecting and applying appropriate data mining techniques (algorithms) to discover patterns. This is where the \"mining\" happens.\n",
       "5.  **Evaluation:** Assessing the quality and usefulness of the discovered patterns. Do they make sense? Are they statistically significant? Do they meet the business objectives?\n",
       "6.  **Deployment:** Putting the discovered knowledge into practice. This could involve integrating it into business processes, creating reports, or building predictive models.\n",
       "\n",
       "**Common Data Mining Techniques:**\n",
       "\n",
       "Data mining employs a variety of techniques, often drawing from statistics, machine learning, and database systems. Some of the most common include:\n",
       "\n",
       "*   **Classification:** Categorizing data into predefined classes (e.g., predicting whether a customer will churn or not).\n",
       "*   **Clustering:** Grouping similar data points together without predefined classes (e.g., segmenting customers into different groups based on their purchasing behavior).\n",
       "*   **Association Rule Mining:** Discovering relationships between items in a dataset (e.g., \"customers who buy bread also tend to buy milk\"). This is often used in market basket analysis.\n",
       "*   **Regression:** Predicting a continuous numerical value (e.g., predicting the price of a house based on its features).\n",
       "*   **Anomaly Detection (Outlier Detection):** Identifying data points that deviate significantly from the norm (e.g., detecting fraudulent transactions).\n",
       "*   **Sequential Pattern Mining:** Discovering patterns that occur in a sequence over time (e.g., identifying common user navigation paths on a website).\n",
       "\n",
       "**Why is Data Mining Important?**\n",
       "\n",
       "Data mining is crucial for businesses and organizations because it enables them to:\n",
       "\n",
       "*   **Make Better Decisions:** By understanding customer behavior, market trends, and operational efficiencies, organizations can make more informed and strategic decisions.\n",
       "*   **Improve Customer Relationships:** Identifying customer preferences and predicting their needs allows for personalized marketing, better customer service, and increased loyalty.\n",
       "*   **Detect Fraud and Risk:** Anomaly detection can help identify fraudulent activities, security breaches, and potential risks.\n",
       "*   **Optimize Operations:** Understanding patterns in operational data can lead to improved efficiency, reduced costs, and better resource allocation.\n",
       "*   **Drive Innovation:** Discovering new insights can spark new product development, service offerings, and business models.\n",
       "*   **Gain a Competitive Advantage:** Organizations that effectively leverage data mining can outperform their competitors by understanding their market and customers better.\n",
       "\n",
       "In essence, data mining is a powerful tool for transforming raw data into valuable intelligence, driving progress and innovation across various fields."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(text_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_5_1_1_'></a>[**>>> Exercise 1 (Take home):**](#toc0_)\n",
    "\n",
    "`With your own prompt`, run the previous example in the following way:\n",
    "\n",
    "1. Run it with the same model as the example (gemini-2.5-flash-lite). \n",
    "2. Run it with a different gemini model from the available options for the API.\n",
    "3. Discuss the differences on the results with different models.\n",
    "4. Discuss what would happen if you change the system prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# ===== gemini-2.5-flash-lite Output ====="
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Tuning a large language model (LLM) is crucial for adapting its general capabilities to specific tasks, domains, or desired behaviors. Here's a breakdown of the common methods used for LLM tuning, categorized for clarity:\n",
       "\n",
       "**I. Fine-tuning (The Most Common Approach)**\n",
       "\n",
       "Fine-tuning involves taking a pre-trained LLM and further training it on a smaller, task-specific dataset. This allows the model to learn new patterns and nuances relevant to the target application.\n",
       "\n",
       "*   **Full Fine-tuning:**\n",
       "    *   **Description:** All parameters of the pre-trained LLM are updated during training.\n",
       "    *   **Pros:** Can achieve the best performance for the specific task as the entire model adapts.\n",
       "    *   **Cons:** Computationally expensive, requires significant memory, and can lead to catastrophic forgetting (where the model loses its general capabilities).\n",
       "    *   **When to use:** When maximum performance on a specific task is paramount and computational resources are not a major constraint.\n",
       "\n",
       "*   **Parameter-Efficient Fine-tuning (PEFT):** These methods aim to reduce the number of trainable parameters, making fine-tuning more efficient in terms of computation, memory, and storage.\n",
       "\n",
       "    *   **LoRA (Low-Rank Adaptation):**\n",
       "        *   **Description:** Injects trainable low-rank matrices into specific layers of the pre-trained model. Only these low-rank matrices are trained, while the original model weights remain frozen.\n",
       "        *   **Pros:** Significantly reduces the number of trainable parameters, faster training, smaller storage footprint for adapters, less prone to catastrophic forgetting.\n",
       "        *   **Cons:** Might not reach the absolute peak performance of full fine-tuning in all cases.\n",
       "        *   **When to use:** A very popular and effective method for most fine-tuning tasks, especially when dealing with limited resources or when deploying multiple task-specific models.\n",
       "\n",
       "    *   **Adapter Layers:**\n",
       "        *   **Description:** Inserts small, trainable \"adapter\" modules between the layers of the pre-trained LLM. The original LLM weights are frozen.\n",
       "        *   **Pros:** Similar benefits to LoRA in terms of efficiency and reduced forgetting.\n",
       "        *   **Cons:** Can introduce slight latency due to the added layers.\n",
       "        *   **When to use:** Another good PEFT option, often compared to LoRA.\n",
       "\n",
       "    *   **Prefix Tuning / P-Tuning:**\n",
       "        *   **Description:** Learns a small, continuous \"prefix\" or \"prompt\" that is prepended to the input sequence. The LLM's weights are frozen.\n",
       "        *   **Pros:** Very parameter-efficient, can be effective for certain tasks.\n",
       "        *   **Cons:** Can be less flexible than LoRA or adapters for complex tasks.\n",
       "        *   **When to use:** When you want to steer the model's behavior without modifying its core weights, often for tasks like text generation or classification.\n",
       "\n",
       "    *   **Prompt Tuning:**\n",
       "        *   **Description:** Similar to prefix tuning, but learns a set of trainable \"soft prompts\" that are prepended to the input. The LLM's weights are frozen.\n",
       "        *   **Pros:** Extremely parameter-efficient, can be very effective for specific tasks.\n",
       "        *   **Cons:** The learned prompts are not human-readable.\n",
       "        *   **When to use:** When you need to adapt the model with minimal computational overhead and are comfortable with learned, non-interpretable prompts.\n",
       "\n",
       "    *   **QLoRA:**\n",
       "        *   **Description:** An optimization of LoRA that quantizes the pre-trained model to 4-bit precision, further reducing memory usage and enabling fine-tuning of very large models on consumer hardware.\n",
       "        *   **Pros:** Enables fine-tuning of massive LLMs on significantly less hardware.\n",
       "        *   **Cons:** Potential for slight degradation in performance compared to higher precision.\n",
       "        *   **When to use:** When you need to fine-tune extremely large LLMs and have limited GPU memory.\n",
       "\n",
       "**II. Instruction Tuning**\n",
       "\n",
       "Instruction tuning focuses on training LLMs to follow instructions given in natural language. This makes them more versatile and better at zero-shot or few-shot learning.\n",
       "\n",
       "*   **Description:** The LLM is trained on a dataset of (instruction, input, output) triplets. The goal is to teach the model to understand and execute a wide range of tasks based on textual instructions.\n",
       "*   **Pros:** Improves the model's ability to generalize to unseen tasks, makes it more user-friendly, and enhances its performance in zero-shot and few-shot settings.\n",
       "*   **Cons:** Requires carefully curated instruction datasets.\n",
       "*   **When to use:** To create general-purpose chatbots, assistants, or models that can perform many different tasks without explicit fine-tuning for each.\n",
       "\n",
       "**III. Reinforcement Learning from Human Feedback (RLHF)**\n",
       "\n",
       "RLHF is a powerful technique for aligning LLM behavior with human preferences, making them safer, more helpful, and less prone to generating undesirable content.\n",
       "\n",
       "*   **Description:**\n",
       "    1.  **Supervised Fine-tuning (SFT):** A base LLM is fine-tuned on a dataset of high-quality demonstrations.\n",
       "    2.  **Reward Model Training:** Human annotators rank different model outputs for the same prompt. A reward model is trained to predict these human preferences.\n",
       "    3.  **Reinforcement Learning:** The LLM is further fine-tuned using reinforcement learning (e.g., PPO algorithm), where the reward model provides feedback to guide the LLM towards generating outputs that are preferred by humans.\n",
       "*   **Pros:** Crucial for aligning LLMs with human values, improving safety, reducing toxicity, and enhancing helpfulness.\n",
       "*   **Cons:** Complex to implement, requires significant human annotation effort, and can be computationally intensive.\n",
       "*   **When to use:** To create safe, ethical, and helpful AI assistants, chatbots, and other applications where human alignment is critical.\n",
       "\n",
       "**IV. Prompt Engineering (Not strictly \"tuning\" but a related adaptation method)**\n",
       "\n",
       "While not modifying the model's weights, prompt engineering is a crucial technique for guiding LLM behavior.\n",
       "\n",
       "*   **Description:** Carefully crafting the input prompt to elicit the desired output from the LLM. This can involve providing context, examples (few-shot learning), specifying the desired format, or using specific keywords.\n",
       "*   **Pros:** No training required, quick to iterate, can be very effective for many tasks.\n",
       "*   **Cons:** Can be brittle, requires experimentation, and may not be sufficient for complex or highly specialized tasks.\n",
       "*   **When to use:** For quick experimentation, when you don't have the resources for fine-tuning, or to complement fine-tuned models.\n",
       "\n",
       "**V. Other Advanced Techniques**\n",
       "\n",
       "*   **Knowledge Distillation:** Training a smaller, \"student\" model to mimic the behavior of a larger, \"teacher\" LLM. This is useful for deploying LLMs on resource-constrained devices.\n",
       "*   **Continual Learning:** Methods that allow LLMs to learn new information or adapt to new tasks over time without forgetting previously learned knowledge.\n",
       "*   **Domain Adaptation:** Specifically tailoring an LLM to a particular domain (e.g., medical, legal, financial) by training on domain-specific data. This can be a form of fine-tuning.\n",
       "\n",
       "**Choosing the Right Method:**\n",
       "\n",
       "The best method for tuning an LLM depends on several factors:\n",
       "\n",
       "*   **Task Complexity:** Simple tasks might be solvable with prompt engineering, while complex tasks often require fine-tuning.\n",
       "*   **Data Availability:** The amount and quality of your task-specific data will influence your choice.\n",
       "*   **Computational Resources:** Full fine-tuning is resource-intensive, while PEFT methods are more efficient.\n",
       "*   **Desired Performance:** If peak performance is critical, full fine-tuning might be necessary, but PEFT often offers a good trade-off.\n",
       "*   **Safety and Alignment Requirements:** RLHF is essential for ensuring safe and aligned behavior.\n",
       "*   **Deployment Constraints:** For edge devices or mobile applications, parameter-efficient methods or distillation are preferred.\n",
       "\n",
       "In practice, a combination of these methods is often used. For example, an LLM might first be instruction-tuned, then further fine-tuned using LoRA for a specific task, and finally aligned with human preferences using RLHF."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'gemini-2.5-flash-lite', 'input_tokens': 22, 'output_tokens': 1774}\n"
     ]
    }
   ],
   "source": [
    "# Answer here\n",
    "#gemini-2.5-flash-lite\n",
    "input_prompt = [\"What kind of methods that can be used to tune a large language model?\"]\n",
    "text_response1, logs1 = prompt_gemini(input_prompt = input_prompt,model_name=\"gemini-2.5-flash-lite\", with_tokens_info = True)\n",
    "display(Markdown(\"# ===== gemini-2.5-flash-lite Output =====\"))\n",
    "display(Markdown(text_response1))\n",
    "print(logs1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# ===== gemini-2.5-flash Output ====="
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Tuning a Large Language Model (LLM) refers to the process of adapting a pre-trained model to perform better on specific tasks, datasets, or to align its behavior with desired outcomes. This is distinct from the initial \"pre-training\" phase, where the model learns general language patterns from vast amounts of text.\n",
       "\n",
       "Here's a breakdown of the main methods used to tune LLMs, ranging from full model updates to parameter-efficient techniques and behavioral alignment:\n",
       "\n",
       "---\n",
       "\n",
       "### 1. Full Fine-Tuning\n",
       "\n",
       "*   **Description:** This is the most straightforward method where *all* parameters of the pre-trained LLM are updated using a new, task-specific dataset. The model continues to learn from the new data, adjusting its weights to optimize for the target task.\n",
       "*   **How it works:** You take a pre-trained LLM (e.g., Llama 2, GPT-3.5), provide it with a dataset of input-output pairs relevant to your task (e.g., summarization, sentiment analysis, question answering), and train it using standard backpropagation.\n",
       "*   **Pros:**\n",
       "    *   Potentially achieves the highest performance on the target task, as the entire model is optimized.\n",
       "    *   Can significantly adapt the model's capabilities.\n",
       "*   **Cons:**\n",
       "    *   **Computationally Expensive:** Requires substantial GPU memory and compute power, often comparable to pre-training for large models.\n",
       "    *   **Time-Consuming:** Training can take a long time.\n",
       "    *   **Storage Intensive:** Saving multiple fine-tuned versions of a large model requires a lot of disk space.\n",
       "    *   **Catastrophic Forgetting:** The model might \"forget\" some of its general knowledge learned during pre-training, especially if the fine-tuning dataset is small or very different.\n",
       "*   **When to use:** When you have ample computational resources, a high-quality and sufficiently large task-specific dataset, and require maximum performance for a critical application.\n",
       "\n",
       "---\n",
       "\n",
       "### 2. Parameter-Efficient Fine-Tuning (PEFT)\n",
       "\n",
       "PEFT methods aim to reduce the computational and memory costs of fine-tuning by updating only a small subset of the model's parameters or by introducing a small number of new, trainable parameters. The vast majority of the pre-trained weights remain frozen.\n",
       "\n",
       "*   **a. LoRA (Low-Rank Adaptation)**\n",
       "    *   **Description:** LoRA injects small, trainable matrices (adapters) into the existing layers of the pre-trained model. Instead of training the original weight matrices, it trains these much smaller low-rank decomposition matrices that represent the *change* to the original weights.\n",
       "    *   **How it works:** For each weight matrix $W_0$ in the original model, LoRA adds a low-rank decomposition $BA$ (where $B$ and $A$ are much smaller matrices). During fine-tuning, $W_0$ is frozen, and only $A$ and $B$ are trained. The output is then $W_0x + BAx$.\n",
       "    *   **Pros:**\n",
       "        *   Significantly reduces the number of trainable parameters (e.g., by 10,000x).\n",
       "        *   Much faster training and lower memory footprint.\n",
       "        *   Allows for easy switching between different task adaptations by loading different sets of LoRA weights.\n",
       "        *   Less prone to catastrophic forgetting.\n",
       "    *   **Cons:** May not always reach the absolute peak performance of full fine-tuning, though often very close.\n",
       "*   **b. QLoRA (Quantized LoRA)**\n",
       "    *   **Description:** QLoRA builds upon LoRA by quantizing the base pre-trained model to 4-bit precision (or similar) to further reduce memory usage during training. The LoRA adapters are then trained on top of this quantized model.\n",
       "    *   **How it works:** The base model weights are loaded in a quantized format (e.g., 4-bit NormalFloat), which drastically reduces memory. A small set of LoRA adapters are then trained in higher precision (e.g., 16-bit) on top of this quantized model.\n",
       "    *   **Pros:**\n",
       "        *   Extremely memory efficient, enabling fine-tuning of very large models (e.g., 70B parameters) on consumer-grade GPUs.\n",
       "        *   Retains most of LoRA's performance benefits.\n",
       "    *   **Cons:** Potential for slight performance degradation due to the quantization of the base model.\n",
       "*   **c. Prompt Tuning / Prefix Tuning / P-Tuning**\n",
       "    *   **Description:** These methods involve adding a small, trainable \"soft prompt\" or \"prefix\" to the input sequence, rather than modifying the model's internal weights. The model learns to condition its output on this learned prompt.\n",
       "    *   **How it works:** A sequence of trainable vectors (the soft prompt/prefix) is prepended to the input embeddings. The LLM then processes this augmented input. Only these prompt vectors are updated during training.\n",
       "    *   **Pros:**\n",
       "        *   Very few trainable parameters.\n",
       "        *   No changes to the core model weights, making deployment and sharing easy.\n",
       "    *   **Cons:** Can be less effective than adapter-based methods for complex tasks, and performance can be sensitive to the initial prompt initialization.\n",
       "*   **d. Adapter-based Methods (e.g., Houlsby Adapters, Compacter)**\n",
       "    *   **Description:** These methods insert small, task-specific neural network modules (adapters) between the layers of the pre-trained model. Only these adapter modules are trained, while the original model weights remain frozen.\n",
       "    *   **How it works:** An adapter typically consists of a down-projection, a non-linearity, and an up-projection. When an input passes through a transformer layer, it also passes through the adapter, and the adapter's output is added to the layer's output.\n",
       "    *   **Pros:**\n",
       "        *   Relatively few trainable parameters compared to full fine-tuning.\n",
       "        *   Can achieve good performance.\n",
       "    *   **Cons:** Can add latency during inference due to the additional layers.\n",
       "*   **e. IA3 (Infused Adapters by Inhibiting and Amplifying Inner Activations)**\n",
       "    *   **Description:** IA3 learns a set of vectors that scale the key, value, and feed-forward activations within the transformer layers.\n",
       "    *   **How it works:** Instead of adding new layers, IA3 learns simple scaling factors for specific internal activations. Only these scaling factors are trained.\n",
       "    *   **Pros:** Extremely parameter-efficient, often outperforming other PEFT methods with fewer parameters.\n",
       "    *   **Cons:** Can be slightly more complex to implement than LoRA.\n",
       "\n",
       "---\n",
       "\n",
       "### 3. Reinforcement Learning from Human Feedback (RLHF)\n",
       "\n",
       "*   **Description:** RLHF is a powerful technique used to align LLMs with human preferences, making them more helpful, harmless, and honest. It's a multi-step process that goes beyond just task performance to focus on the quality and safety of the model's outputs.\n",
       "*   **How it works:**\n",
       "    1.  **Supervised Fine-Tuning (SFT):** An initial fine-tuning step on a dataset of high-quality human-written demonstrations to teach the model desired behaviors.\n",
       "    2.  **Reward Model Training:** A separate \"reward model\" is trained to predict human preferences. This model is trained on a dataset of human comparisons, where annotators rank different LLM outputs for a given prompt.\n",
       "    3.  **Reinforcement Learning:** The LLM is then fine-tuned using an RL algorithm (e.g., Proximal Policy Optimization - PPO) to maximize the reward signal from the reward model. The LLM learns to generate responses that the reward model predicts humans would prefer.\n",
       "*   **Pros:**\n",
       "    *   Produces highly aligned and safe models (e.g., ChatGPT, Claude).\n",
       "    *   Significantly improves conversational quality, reduces hallucination, and enhances adherence to instructions.\n",
       "*   **Cons:**\n",
       "    *   **Extremely Complex:** Involves multiple models and training stages.\n",
       "    *   **Data-Intensive:** Requires vast amounts of high-quality human preference data.\n",
       "    *   **Computationally Expensive:** Training the reward model and the RL phase are resource-intensive.\n",
       "    *   **Difficult to Debug:** RL training can be unstable and hard to troubleshoot.\n",
       "*   **When to use:** For developing general-purpose conversational AI, chatbots, or any application where safety, helpfulness, and alignment with human values are paramount.\n",
       "\n",
       "---\n",
       "\n",
       "### 4. Knowledge Distillation\n",
       "\n",
       "*   **Description:** Knowledge distillation involves training a smaller \"student\" model to mimic the behavior of a larger, more powerful \"teacher\" model. While not strictly \"tuning\" the teacher, it's a method to create a tuned, smaller version of an LLM.\n",
       "*   **How it works:** The student model is trained not only on the ground truth labels but also on the \"soft targets\" (e.g., probability distributions over classes, hidden states) produced by the teacher model. This allows the student to learn the nuances and generalization capabilities of the teacher.\n",
       "*   **Pros:**\n",
       "    *   Creates smaller, faster, and more efficient models for deployment.\n",
       "    *   Reduces inference costs.\n",
       "    *   Can transfer knowledge from proprietary or very large models to smaller, open-source ones.\n",
       "*   **Cons:** The student model will generally be less capable than the teacher model.\n",
       "\n",
       "---\n",
       "\n",
       "### 5. Prompt Engineering / In-Context Learning\n",
       "\n",
       "*   **Description:** While not \"tuning\" the model's weights, prompt engineering is a crucial method to *tune the model's behavior* without any training. It involves carefully crafting input prompts to elicit desired responses from a pre-trained LLM.\n",
       "*   **How it works:**\n",
       "    *   **Zero-shot:** Providing only the instruction (e.g., \"Translate this to French: 'Hello'\").\n",
       "    *   **Few-shot:** Providing a few examples within the prompt to guide the model (e.g., \"English: Cat -> French: Chat. English: Dog -> French: Chien. English: Hello -> French:\").\n",
       "    *   **Chain-of-Thought (CoT):** Prompting the model to show its reasoning steps before giving the final answer (e.g., \"Let's think step by step.\").\n",
       "    *   **Advanced Techniques:** Tree-of-Thought, Self-Consistency, etc.\n",
       "*   **Pros:**\n",
       "    *   No training required, making it extremely fast and cheap.\n",
       "    *   Highly flexible and adaptable to new tasks on the fly.\n",
       "    *   Leverages the vast knowledge already present in the pre-trained model.\n",
       "*   **Cons:**\n",
       "    *   Performance can be highly sensitive to prompt wording.\n",
       "    *   Limited by the inherent capabilities of the base model.\n",
       "    *   Not a true \"tuning\" of the model's underlying parameters.\n",
       "*   **When to use:** For rapid prototyping, tasks where a small performance drop is acceptable for the sake of speed and cost, or when you don't have a large fine-tuning dataset.\n",
       "\n",
       "---\n",
       "\n",
       "### Key Considerations When Choosing a Method:\n",
       "\n",
       "*   **Computational Resources:** GPUs, memory, and time.\n",
       "*   **Dataset Size and Quality:** The amount and relevance of your task-specific data.\n",
       "*   **Performance Requirements:** How critical is peak performance vs. cost/speed?\n",
       "*   **Deployment Constraints:** Model size, inference latency, and cost.\n",
       "*   **Alignment Needs:** Is it a general-purpose assistant requiring safety and helpfulness, or a specialized task model?\n",
       "\n",
       "The choice of tuning method depends heavily on the specific use case, available resources, and desired outcomes. Often, a combination of these methods (e.g., SFT with LoRA, followed by RLHF) is used for state-of-the-art LLM development."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'gemini-2.5-flash', 'input_tokens': 22, 'output_tokens': 2582}\n"
     ]
    }
   ],
   "source": [
    "#gemini-2.5-flash\n",
    "input_prompt = [\"What kind of methods that can be used to tune a large language model?\"]\n",
    "text_response2, logs2 = prompt_gemini(input_prompt = input_prompt,model_name=\"gemini-2.5-flash\", with_tokens_info = True)\n",
    "display(Markdown(\"# ===== gemini-2.5-flash Output =====\"))\n",
    "display(Markdown(text_response2))\n",
    "print(logs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **Difference Between gemini-2.5-flash-lite and gemini-2.5-flash**\n",
    "\n",
    "##### **Flash-lite**\n",
    "Delivers a more instructional and easy-to-read explanation, using simplified concepts, clear categorization, and minimal technical depth. Its tone is approachable, and the content focuses on high-level understanding. \n",
    "\n",
    "##### **Flash** \n",
    "Provides a significantly more detailed, technically rich, and research-oriented answer. It includes engineering-level descriptions, mathematical notation, implementation mechanisms, and extensive domain-specific terminology, resulting in higher information density and longer output. \n",
    "\n",
    "In essence, Flash-lite is suited for conceptual overviews, while Flash is tailored for expert-level analysis requiring depth, precision, and comprehensive technical coverage.\n",
    "\n",
    "|                                                  | Input Tokens | Output Tokens |  Tokens |\n",
    "| -------------------------------------------------- | ------------ | ------------- | -------- |\n",
    "| **gemini-2.5-flash-lite**                      | 22           | 1774          | **1796** |\n",
    "| **gemini-2.5-flash**                           | 22           | 2512          | **2534** |\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# ===== gemini-2.5-flash-lite Output ---AI expert ====="
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Tuning a large language model (LLM) is a crucial step to adapt its general capabilities to specific tasks, domains, or desired behaviors. There are several categories of methods, each with its own strengths and weaknesses. Here's a breakdown of the most common and effective approaches:\n",
       "\n",
       "## 1. Fine-tuning (Full Fine-tuning)\n",
       "\n",
       "This is the most traditional and comprehensive method.\n",
       "\n",
       "*   **How it works:** You take a pre-trained LLM and continue training it on a new, task-specific dataset. This involves updating *all* the parameters of the model.\n",
       "*   **Pros:**\n",
       "    *   Can achieve state-of-the-art performance on the target task.\n",
       "    *   Allows the model to deeply learn the nuances of the new data.\n",
       "*   **Cons:**\n",
       "    *   **Computationally expensive:** Requires significant GPU resources and time.\n",
       "    *   **Large storage requirements:** The fine-tuned model is as large as the original pre-trained model.\n",
       "    *   **Catastrophic forgetting:** The model might forget some of its general knowledge from pre-training if the fine-tuning dataset is very different or too small.\n",
       "*   **When to use:** When you have a substantial amount of high-quality, task-specific data and the computational resources to support it. This is often the go-to for achieving the best possible performance on a specific downstream task.\n",
       "\n",
       "## 2. Parameter-Efficient Fine-Tuning (PEFT) Methods\n",
       "\n",
       "These methods aim to reduce the computational and storage costs of fine-tuning by only updating a small subset of the model's parameters or by introducing a small number of new parameters.\n",
       "\n",
       "### a) Adapter-based Methods\n",
       "\n",
       "*   **How it works:** Small, trainable \"adapter\" modules are inserted between the layers of the pre-trained LLM. Only the parameters of these adapters are trained, while the original LLM weights remain frozen.\n",
       "*   **Examples:** Adapters, LoRA (Low-Rank Adaptation), QLoRA (Quantized LoRA).\n",
       "*   **Pros:**\n",
       "    *   Significantly reduces the number of trainable parameters.\n",
       "    *   Much faster training and lower memory usage compared to full fine-tuning.\n",
       "    *   Smaller storage footprint for the fine-tuned components.\n",
       "    *   Less prone to catastrophic forgetting.\n",
       "*   **Cons:**\n",
       "    *   May not reach the absolute peak performance of full fine-tuning in all cases.\n",
       "    *   Adds a slight inference latency due to the extra adapter layers.\n",
       "*   **When to use:** When computational resources are limited, you need to fine-tune for many different tasks, or you want to avoid catastrophic forgetting. LoRA and QLoRA are currently very popular and effective.\n",
       "\n",
       "### b) Prompt Tuning / Prefix Tuning\n",
       "\n",
       "*   **How it works:** Instead of modifying the model's weights, these methods learn a small set of continuous \"prompt\" or \"prefix\" embeddings that are prepended to the input. The LLM's weights are frozen.\n",
       "*   **Examples:** Prompt Tuning, Prefix Tuning, P-Tuning.\n",
       "*   **Pros:**\n",
       "    *   Extremely parameter-efficient (only a few hundred or thousand parameters to train).\n",
       "    *   Very fast training.\n",
       "    *   No modification to the original LLM architecture.\n",
       "*   **Cons:**\n",
       "    *   Performance can be more sensitive to initialization and hyperparameter tuning.\n",
       "    *   May not be as effective as adapter-based methods for complex tasks.\n",
       "*   **When to use:** For tasks where a simple prompt can effectively guide the model, and extreme parameter efficiency is paramount.\n",
       "\n",
       "### c) LoRA (Low-Rank Adaptation)\n",
       "\n",
       "*   **How it works:** This is a very popular PEFT method. It injects trainable low-rank decomposition matrices into specific layers (typically attention layers) of the pre-trained model. Instead of updating the full weight matrix, it updates these smaller, low-rank matrices.\n",
       "*   **Pros:**\n",
       "    *   Highly effective at reducing trainable parameters while maintaining performance.\n",
       "    *   Can be combined with quantization (QLoRA) for even greater efficiency.\n",
       "    *   Relatively easy to implement and integrate.\n",
       "*   **Cons:**\n",
       "    *   Still requires some computational resources, though much less than full fine-tuning.\n",
       "*   **When to use:** A strong default choice for most PEFT scenarios due to its balance of efficiency and performance.\n",
       "\n",
       "### d) QLoRA (Quantized LoRA)\n",
       "\n",
       "*   **How it works:** An optimization of LoRA that uses quantization techniques (e.g., 4-bit NormalFloat) to further reduce memory usage. It quantizes the pre-trained model weights to a lower precision while keeping the LoRA adapters in higher precision during training.\n",
       "*   **Pros:**\n",
       "    *   Enables fine-tuning of very large models on consumer-grade hardware.\n",
       "    *   Significant memory savings.\n",
       "*   **Cons:**\n",
       "    *   Potential for slight degradation in performance due to quantization, though often negligible.\n",
       "*   **When to use:** When you need to fine-tune extremely large models (e.g., 65B parameters) on limited hardware.\n",
       "\n",
       "## 3. Instruction Tuning\n",
       "\n",
       "*   **How it works:** This is a form of fine-tuning where the model is trained on a dataset of instructions and their corresponding outputs. The goal is to teach the model to follow instructions and perform a wide range of tasks in a zero-shot or few-shot manner.\n",
       "*   **Pros:**\n",
       "    *   Improves the model's ability to generalize to new, unseen tasks described by instructions.\n",
       "    *   Enhances conversational abilities and task completion.\n",
       "*   **Cons:**\n",
       "    *   Requires a diverse and well-curated instruction dataset.\n",
       "    *   Can be computationally intensive if done on a large scale.\n",
       "*   **When to use:** To make LLMs more versatile and better at understanding and executing user commands. Many modern LLMs are instruction-tuned.\n",
       "\n",
       "## 4. Reinforcement Learning from Human Feedback (RLHF)\n",
       "\n",
       "*   **How it works:** This is a multi-stage process:\n",
       "    1.  **Supervised Fine-tuning (SFT):** The LLM is fine-tuned on a dataset of high-quality demonstrations.\n",
       "    2.  **Reward Model Training:** Human annotators rank different model outputs for the same prompt. A separate reward model is trained to predict these human preferences.\n",
       "    3.  **Reinforcement Learning:** The LLM is further fine-tuned using reinforcement learning (e.g., PPO algorithm), where the reward model provides the reward signal.\n",
       "*   **Pros:**\n",
       "    *   Aligns the model's behavior with human values, safety, and preferences.\n",
       "    *   Can lead to more helpful, honest, and harmless outputs.\n",
       "*   **Cons:**\n",
       "    *   Complex and resource-intensive to implement.\n",
       "    *   Requires significant human annotation effort.\n",
       "    *   Can be challenging to balance reward signals effectively.\n",
       "*   **When to use:** To make LLMs safer, more aligned with human intent, and to improve their helpfulness and conversational quality. This is a key technique behind models like ChatGPT.\n",
       "\n",
       "## 5. Direct Preference Optimization (DPO)\n",
       "\n",
       "*   **How it works:** A more recent and simpler alternative to RLHF. DPO directly optimizes the LLM on a dataset of human preferences (pairs of preferred and dispreferred responses) without needing to train a separate reward model or use complex RL algorithms.\n",
       "*   **Pros:**\n",
       "    *   Simpler to implement than RLHF.\n",
       "    *   More stable training.\n",
       "    *   Often achieves comparable or better results than RLHF.\n",
       "*   **Cons:**\n",
       "    *   Still requires a dataset of human preferences.\n",
       "*   **When to use:** As a more efficient and stable alternative to RLHF for aligning LLMs with human preferences.\n",
       "\n",
       "## 6. Few-Shot Learning / In-Context Learning\n",
       "\n",
       "*   **How it works:** This isn't strictly \"tuning\" in the sense of updating model weights. Instead, you provide the LLM with a few examples of the task directly within the prompt. The model then uses these examples to infer the task and generate an output for a new query.\n",
       "*   **Pros:**\n",
       "    *   No training required, extremely fast to adapt.\n",
       "    *   No computational cost for adaptation.\n",
       "*   **Cons:**\n",
       "    *   Performance is limited by the LLM's inherent capabilities and the quality of the few examples.\n",
       "    *   Context window limitations can restrict the number of examples.\n",
       "    *   Can be less robust than fine-tuning.\n",
       "*   **When to use:** For quick experimentation, when you have very few examples, or when you want to leverage the LLM's existing knowledge without modifying it.\n",
       "\n",
       "## Choosing the Right Method\n",
       "\n",
       "The best method for tuning an LLM depends on several factors:\n",
       "\n",
       "*   **Task Complexity:** Simple tasks might be fine with prompt tuning or few-shot learning, while complex tasks often benefit from fine-tuning.\n",
       "*   **Data Availability:** Full fine-tuning requires a large dataset, while PEFT methods can work with smaller datasets. RLHF and DPO require preference data.\n",
       "*   **Computational Resources:** Full fine-tuning is the most demanding, followed by adapter-based PEFT, then prompt tuning, and finally few-shot learning.\n",
       "*   **Desired Performance:** For maximum performance, full fine-tuning is often the best, but PEFT methods are closing the gap.\n",
       "*   **Alignment Needs:** If aligning with human values and safety is critical, RLHF or DPO are essential.\n",
       "*   **Storage Constraints:** PEFT methods offer significant advantages in terms of storage.\n",
       "\n",
       "In practice, a combination of these methods is often used. For example, a model might be instruction-tuned first, then further aligned using RLHF or DPO, and finally adapted to a specific downstream task using LoRA."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'gemini-2.5-flash-lite', 'input_tokens': 27, 'output_tokens': 2127}\n"
     ]
    }
   ],
   "source": [
    "# System instruction -- AI expert\n",
    "input_prompt = [\"What kind of methods that can be used to tune a large language model?\"]\n",
    "SYSTEM_INSTRUCTION = \"You are an expert in AI and machine learning.\"\n",
    "text_response1, logs1 = prompt_gemini(input_prompt = input_prompt,model_name=\"gemini-2.5-flash-lite\", system_instruction = SYSTEM_INSTRUCTION, with_tokens_info = True)\n",
    "display(Markdown(\"# ===== gemini-2.5-flash-lite Output ---AI expert =====\"))\n",
    "display(Markdown(text_response1))\n",
    "print(logs1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **Effect of changing System Instruction on gemini-2.5-flash-lite**\n",
    "\n",
    "Adding the AI expert system instruction noticeably shifts the tone and depth of the gemini-2.5-flash-lite response. Compared to the original version, which was more conceptual, concise, and written in an instructional or introductory style. The modified output becomes significantly more technical, structured, and expert-oriented. The model expands each tuning method with clearer operational details, explicit pros and cons, practical use cases, and more specific terminology. It even introduces additional techniques such as DPO and P-Tuning that were not mentioned in the default response. \n",
    "\n",
    "Overall, the system instruction effectively repositions the models persona, leading to a more comprehensive, detailed, and professional explanation that resembles a technical document rather than a beginner-friendly overview.\n",
    "\n",
    "|                                                  | Input Tokens | Output Tokens |  Tokens |\n",
    "| -------------------------------------------------- | ------------ | ------------- | -------- |\n",
    "| **gemini-2.5-flash-lite**                      | 22           | 1774          | **1796**  | \n",
    "| **gemini-2.5-flash-liteAI expert system prompt** | 27           | 2127          | **2154** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_6_'></a>[**2.2 Structured Output**](#toc0_)\n",
    "\n",
    "By default, an LLM responds with unstructured, free-form text. For data mining, this is often impractical, as we need data in a predictable format to load into tools like a pandas DataFrame for analysis. **Structured output** is a powerful feature that forces the model to return its response in a specific, machine-readable format, such as JSON.\n",
    "\n",
    "The key to enabling this is to provide the model with a **response schema**. This schema acts as a strict template or blueprint that the model's output must conform to. Instead of generating a paragraph, the model will fill in the fields defined in your schema with the relevant information it extracts from the prompt.\n",
    "\n",
    "In the following code, we define this schema using Python classes. Think of each class as defining a JSON object:\n",
    "*   The **attributes** of the class (e.g., `topic_name`, `sub_title`) become the keys in the final JSON object.\n",
    "*   The **type hints** for those attributes (e.g., `str`, `list`) tell the model what kind of data is expected for each key's value.\n",
    "\n",
    "We can even nest these classes inside one another to create complex, hierarchical JSON structures. This allows us to precisely control the format of the output, transforming the LLM from a simple text generator into a reliable tool for automated and structured data extraction.\n",
    "\n",
    "[Gemini's Structured Output Documentation](https://ai.google.dev/gemini-api/docs/structured-output)\n",
    "\n",
    "For data validation of schemas Gemini API uses the Pydantic library, for more documentation on it you can check: [Pydantic](https://docs.pydantic.dev/latest/) \n",
    "\n",
    "[JSON Format Documentation](https://docs.python.org/3/library/json.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "# We define our structure schema that Gemini should follow for the output response\n",
    "\n",
    "# Subsections on the topics we query\n",
    "class Subsection(BaseModel):\n",
    "    sub_title: str\n",
    "    sub_explanation: str\n",
    "\n",
    "# The top-level structure for the entire topic analysis\n",
    "class Topic(BaseModel):\n",
    "    topic_name: str\n",
    "    subsections: list[Subsection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"topic_name\": \"Machine Learning\",\n",
      "    \"subsections\": [\n",
      "      {\n",
      "        \"sub_title\": \"Definition\",\n",
      "        \"sub_explanation\": \"Machine learning (ML) is a subset of artificial intelligence (AI) that focuses on building systems that can learn from and make decisions based on data. Instead of being explicitly programmed, ML algorithms use statistical techniques to enable systems to 'learn' from data, identify patterns, and make predictions or decisions without human intervention.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Types of Machine Learning\",\n",
      "        \"sub_explanation\": \"Common types include supervised learning (learning from labeled data), unsupervised learning (finding patterns in unlabeled data), and reinforcement learning (learning through trial and error with rewards and penalties).\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Applications\",\n",
      "        \"sub_explanation\": \"ML is used in a wide range of applications, such as image recognition, natural language processing, recommendation systems, fraud detection, and medical diagnosis.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"topic_name\": \"Data Centers\",\n",
      "    \"subsections\": [\n",
      "      {\n",
      "        \"sub_title\": \"Definition\",\n",
      "        \"sub_explanation\": \"A data center is a dedicated physical facility that an organization uses to house its critical IT infrastructure, including servers, storage systems, networking equipment, and related components. These facilities are designed to provide a secure, reliable, and controlled environment for computing operations.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Key Components\",\n",
      "        \"sub_explanation\": \"Essential components include servers, storage devices, network switches and routers, power supplies (including UPS and generators), cooling systems (HVAC), and physical security measures.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Purpose\",\n",
      "        \"sub_explanation\": \"Data centers serve as the central hub for data storage, processing, and management, enabling businesses to run applications, host websites, and manage their digital operations.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"topic_name\": \"Large Language Models (LLMs)\",\n",
      "    \"subsections\": [\n",
      "      {\n",
      "        \"sub_title\": \"Definition\",\n",
      "        \"sub_explanation\": \"Large Language Models (LLMs) are a type of artificial intelligence model that are trained on massive amounts of text data. They are designed to understand, generate, and manipulate human language. LLMs are characterized by their enormous size (billions or trillions of parameters) and their ability to perform a wide variety of natural language processing tasks.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Capabilities\",\n",
      "        \"sub_explanation\": \"LLMs can perform tasks such as text generation, translation, summarization, question answering, code generation, and creative writing. They learn complex linguistic patterns, grammar, facts, and reasoning abilities from their training data.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Underlying Technology\",\n",
      "        \"sub_explanation\": \"LLMs are typically built using deep learning architectures, most notably the Transformer architecture, which allows them to process sequential data like text very effectively.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"topic_name\": \"Relationship Between Machine Learning, Data Centers, and LLMs\",\n",
      "    \"subsections\": [\n",
      "      {\n",
      "        \"sub_title\": \"LLMs as a Product of Machine Learning\",\n",
      "        \"sub_explanation\": \"LLMs are a sophisticated application and outcome of machine learning research and development. The techniques used to train LLMs, such as deep learning and neural networks, are core machine learning concepts. Therefore, LLMs are a specific, advanced type of machine learning model.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Data Centers as the Foundation for LLMs and ML\",\n",
      "        \"sub_explanation\": \"Training and running LLMs, as well as many other complex machine learning models, requires immense computational power and vast amounts of data storage. Data centers provide the necessary infrastructure  high-performance servers, specialized hardware (like GPUs and TPUs), robust networking, and reliable power  to handle these computationally intensive tasks. Without data centers, it would be practically impossible to develop, train, and deploy LLMs at scale.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Interdependence\",\n",
      "        \"sub_explanation\": \"In essence, machine learning is the field of study and the set of techniques. LLMs are a powerful manifestation of these techniques. Data centers are the physical environments and infrastructure that enable the training, deployment, and operation of both general machine learning models and highly demanding LLMs. LLMs rely on ML principles, and both ML and LLMs rely heavily on the resources provided by data centers.\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "input_prompt = [\"Explain what are machine learning, data centers, llms and how do they relate to each other.\"]\n",
    "text_response = prompt_gemini(input_prompt = input_prompt, schema = list[Topic])\n",
    "print(text_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'topic_name': 'Machine Learning', 'subsections': [{'sub_title': 'Definition', 'sub_explanation': \"Machine learning (ML) is a subset of artificial intelligence (AI) that focuses on building systems that can learn from and make decisions based on data. Instead of being explicitly programmed, ML algorithms use statistical techniques to enable systems to 'learn' from data, identify patterns, and make predictions or decisions without human intervention.\"}, {'sub_title': 'Types of Machine Learning', 'sub_explanation': 'Common types include supervised learning (learning from labeled data), unsupervised learning (finding patterns in unlabeled data), and reinforcement learning (learning through trial and error with rewards and penalties).'}, {'sub_title': 'Applications', 'sub_explanation': 'ML is used in a wide range of applications, such as image recognition, natural language processing, recommendation systems, fraud detection, and medical diagnosis.'}]}, {'topic_name': 'Data Centers', 'subsections': [{'sub_title': 'Definition', 'sub_explanation': 'A data center is a dedicated physical facility that an organization uses to house its critical IT infrastructure, including servers, storage systems, networking equipment, and related components. These facilities are designed to provide a secure, reliable, and controlled environment for computing operations.'}, {'sub_title': 'Key Components', 'sub_explanation': 'Essential components include servers, storage devices, network switches and routers, power supplies (including UPS and generators), cooling systems (HVAC), and physical security measures.'}, {'sub_title': 'Purpose', 'sub_explanation': 'Data centers serve as the central hub for data storage, processing, and management, enabling businesses to run applications, host websites, and manage their digital operations.'}]}, {'topic_name': 'Large Language Models (LLMs)', 'subsections': [{'sub_title': 'Definition', 'sub_explanation': 'Large Language Models (LLMs) are a type of artificial intelligence model that are trained on massive amounts of text data. They are designed to understand, generate, and manipulate human language. LLMs are characterized by their enormous size (billions or trillions of parameters) and their ability to perform a wide variety of natural language processing tasks.'}, {'sub_title': 'Capabilities', 'sub_explanation': 'LLMs can perform tasks such as text generation, translation, summarization, question answering, code generation, and creative writing. They learn complex linguistic patterns, grammar, facts, and reasoning abilities from their training data.'}, {'sub_title': 'Underlying Technology', 'sub_explanation': 'LLMs are typically built using deep learning architectures, most notably the Transformer architecture, which allows them to process sequential data like text very effectively.'}]}, {'topic_name': 'Relationship Between Machine Learning, Data Centers, and LLMs', 'subsections': [{'sub_title': 'LLMs as a Product of Machine Learning', 'sub_explanation': 'LLMs are a sophisticated application and outcome of machine learning research and development. The techniques used to train LLMs, such as deep learning and neural networks, are core machine learning concepts. Therefore, LLMs are a specific, advanced type of machine learning model.'}, {'sub_title': 'Data Centers as the Foundation for LLMs and ML', 'sub_explanation': 'Training and running LLMs, as well as many other complex machine learning models, requires immense computational power and vast amounts of data storage. Data centers provide the necessary infrastructure  high-performance servers, specialized hardware (like GPUs and TPUs), robust networking, and reliable power  to handle these computationally intensive tasks. Without data centers, it would be practically impossible to develop, train, and deploy LLMs at scale.'}, {'sub_title': 'Interdependence', 'sub_explanation': 'In essence, machine learning is the field of study and the set of techniques. LLMs are a powerful manifestation of these techniques. Data centers are the physical environments and infrastructure that enable the training, deployment, and operation of both general machine learning models and highly demanding LLMs. LLMs rely on ML principles, and both ML and LLMs rely heavily on the resources provided by data centers.'}]}]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Now the response can be parsed to a python object using the JSON dictionary structure loading\n",
    "structured_resp = json.loads(text_response)\n",
    "print(structured_resp)\n",
    "print(type(structured_resp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning \n",
      "\n",
      "\t Definition \n",
      "\n",
      "\t\t Machine learning (ML) is a subset of artificial intelligence (AI) that focuses on building systems that can learn from and make decisions based on data. Instead of being explicitly programmed, ML algorithms use statistical techniques to enable systems to 'learn' from data, identify patterns, and make predictions or decisions without human intervention. \n",
      "\n",
      "\t Types of Machine Learning \n",
      "\n",
      "\t\t Common types include supervised learning (learning from labeled data), unsupervised learning (finding patterns in unlabeled data), and reinforcement learning (learning through trial and error with rewards and penalties). \n",
      "\n",
      "\t Applications \n",
      "\n",
      "\t\t ML is used in a wide range of applications, such as image recognition, natural language processing, recommendation systems, fraud detection, and medical diagnosis. \n",
      "\n",
      "Data Centers \n",
      "\n",
      "\t Definition \n",
      "\n",
      "\t\t A data center is a dedicated physical facility that an organization uses to house its critical IT infrastructure, including servers, storage systems, networking equipment, and related components. These facilities are designed to provide a secure, reliable, and controlled environment for computing operations. \n",
      "\n",
      "\t Key Components \n",
      "\n",
      "\t\t Essential components include servers, storage devices, network switches and routers, power supplies (including UPS and generators), cooling systems (HVAC), and physical security measures. \n",
      "\n",
      "\t Purpose \n",
      "\n",
      "\t\t Data centers serve as the central hub for data storage, processing, and management, enabling businesses to run applications, host websites, and manage their digital operations. \n",
      "\n",
      "Large Language Models (LLMs) \n",
      "\n",
      "\t Definition \n",
      "\n",
      "\t\t Large Language Models (LLMs) are a type of artificial intelligence model that are trained on massive amounts of text data. They are designed to understand, generate, and manipulate human language. LLMs are characterized by their enormous size (billions or trillions of parameters) and their ability to perform a wide variety of natural language processing tasks. \n",
      "\n",
      "\t Capabilities \n",
      "\n",
      "\t\t LLMs can perform tasks such as text generation, translation, summarization, question answering, code generation, and creative writing. They learn complex linguistic patterns, grammar, facts, and reasoning abilities from their training data. \n",
      "\n",
      "\t Underlying Technology \n",
      "\n",
      "\t\t LLMs are typically built using deep learning architectures, most notably the Transformer architecture, which allows them to process sequential data like text very effectively. \n",
      "\n",
      "Relationship Between Machine Learning, Data Centers, and LLMs \n",
      "\n",
      "\t LLMs as a Product of Machine Learning \n",
      "\n",
      "\t\t LLMs are a sophisticated application and outcome of machine learning research and development. The techniques used to train LLMs, such as deep learning and neural networks, are core machine learning concepts. Therefore, LLMs are a specific, advanced type of machine learning model. \n",
      "\n",
      "\t Data Centers as the Foundation for LLMs and ML \n",
      "\n",
      "\t\t Training and running LLMs, as well as many other complex machine learning models, requires immense computational power and vast amounts of data storage. Data centers provide the necessary infrastructure  high-performance servers, specialized hardware (like GPUs and TPUs), robust networking, and reliable power  to handle these computationally intensive tasks. Without data centers, it would be practically impossible to develop, train, and deploy LLMs at scale. \n",
      "\n",
      "\t Interdependence \n",
      "\n",
      "\t\t In essence, machine learning is the field of study and the set of techniques. LLMs are a powerful manifestation of these techniques. Data centers are the physical environments and infrastructure that enable the training, deployment, and operation of both general machine learning models and highly demanding LLMs. LLMs rely on ML principles, and both ML and LLMs rely heavily on the resources provided by data centers. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# So now we have an object that we can explore/use in a pythonic way for our purposes\n",
    "for topic in structured_resp:\n",
    "    print(topic[\"topic_name\"], \"\\n\")\n",
    "    # We can access each subsection as well\n",
    "    for subsection in topic[\"subsections\"]:\n",
    "        print(\"\\t\", subsection[\"sub_title\"], \"\\n\")\n",
    "        print(\"\\t\\t\", subsection[\"sub_explanation\"], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc1_5_6_1_1_'></a>[**>>> Exercise 2 (Take home):**](#toc0_)\n",
    "\n",
    "Try a prompt with your own schema structure, it needs to be completely different to the example. It should show an intuitive way to represent the text output of the model based on the prompt you chose. See the documentation for reference: https://ai.google.dev/gemini-api/docs/structured-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "# Contents of the methods\n",
    "class contents(BaseModel):\n",
    "    How_it_works: str\n",
    "    Example: str\n",
    "    Pros_Cons: str\n",
    "    When_to_use: str\n",
    "\n",
    "# The methods used to tune LLMs\n",
    "class Methods(BaseModel):\n",
    "    Method_Name: str\n",
    "    Contents:list[contents]\n",
    "   \n",
    "# The top-level structure for the Ouery analysis\n",
    "class Overview(BaseModel):\n",
    "    overall_summary: str\n",
    "    Methods: list[Methods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"overall_summary\": \"Tuning large language models (LLMs) involves adapting a pre-trained model to specific tasks or datasets. This can be achieved through various methods, each with its own strengths and weaknesses, suitable for different scenarios.\",\n",
      "    \"Methods\": [\n",
      "      {\n",
      "        \"Method_Name\": \"Fine-tuning\",\n",
      "        \"Contents\": [\n",
      "          {\n",
      "            \"How_it_works\": \"Fine-tuning involves taking a pre-trained LLM and further training it on a smaller, task-specific dataset. This process adjusts the model's weights to better perform the target task. It can involve training all layers or only a subset of the top layers.\",\n",
      "            \"Example\": \"A general LLM pre-trained on a massive corpus can be fine-tuned on a dataset of medical texts to create a model specialized in answering medical questions.\",\n",
      "            \"Pros_Cons\": \"Pros: Achieves high performance on specific tasks, adapts the model's knowledge. Cons: Can be computationally expensive, requires a labeled dataset, risks catastrophic forgetting of general knowledge if not done carefully.\",\n",
      "            \"When_to_use\": \"When high accuracy on a specific downstream task is required, and a relevant dataset is available. Useful for classification, summarization, translation, and question-answering on specialized domains.\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"Method_Name\": \"Parameter-Efficient Fine-Tuning (PEFT)\",\n",
      "        \"Contents\": [\n",
      "          {\n",
      "            \"How_it_works\": \"PEFT methods update only a small subset of the model's parameters or add a small number of new parameters, keeping the majority of the pre-trained weights frozen. Examples include LoRA (Low-Rank Adaptation), Adapters, and Prefix Tuning.\",\n",
      "            \"Example\": \"Using LoRA to fine-tune a large language model for sentiment analysis by adding small, trainable low-rank matrices to specific layers, rather than updating all weights.\",\n",
      "            \"Pros_Cons\": \"Pros: Significantly reduces computational cost and memory requirements, faster training, less prone to catastrophic forgetting, smaller storage for fine-tuned models. Cons: May not achieve the absolute peak performance of full fine-tuning in all cases.\",\n",
      "            \"When_to_use\": \"When computational resources are limited, or when fine-tuning many different tasks from the same base model. Ideal for scenarios where storage efficiency is important.\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"Method_Name\": \"Prompt Engineering\",\n",
      "        \"Contents\": [\n",
      "          {\n",
      "            \"How_it_works\": \"This method involves carefully crafting the input prompt given to the LLM to elicit the desired output, without modifying the model's weights. Techniques include few-shot learning (providing examples in the prompt), chain-of-thought prompting (asking the model to reason step-by-step), and instruction tuning.\",\n",
      "            \"Example\": \"Instead of just asking 'Translate this to French: Hello', providing a prompt like 'Translate the following English sentences to French. Example 1: English: Goodbye, French: Au revoir. Example 2: English: Thank you, French: Merci. Now translate: English: Hello, French:'\",\n",
      "            \"Pros_Cons\": \"Pros: No training required, computationally inexpensive, flexible and quick to iterate. Cons: Performance can be sensitive to prompt wording, may not be sufficient for complex tasks requiring deep domain knowledge, can be difficult to optimize.\",\n",
      "            \"When_to_use\": \"For rapid prototyping, when no labeled data is available, or for tasks that can be clearly defined with instructions and examples. Useful for zero-shot or few-shot learning scenarios.\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"Method_Name\": \"Reinforcement Learning from Human Feedback (RLHF)\",\n",
      "        \"Contents\": [\n",
      "          {\n",
      "            \"How_it_works\": \"RLHF aligns the LLM's behavior with human preferences. It typically involves training a reward model based on human rankings of model outputs, and then using reinforcement learning to fine-tune the LLM to maximize this reward.\",\n",
      "            \"Example\": \"Training a chatbot to be more helpful and less toxic by having humans rank different responses to prompts, then using RL to optimize the chatbot's responses based on these rankings.\",\n",
      "            \"Pros_Cons\": \"Pros: Improves alignment with human values and preferences, enhances safety and helpfulness. Cons: Complex to implement, requires significant human annotation effort for ranking, can be computationally intensive.\",\n",
      "            \"When_to_use\": \"When the goal is to make the LLM's outputs more aligned with human preferences, safety guidelines, or desired conversational styles. Crucial for developing responsible AI.\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"Method_Name\": \"Instruction Tuning\",\n",
      "        \"Contents\": [\n",
      "          {\n",
      "            \"How_it_works\": \"Instruction tuning is a form of fine-tuning where the model is trained on a dataset of instructions and their corresponding desired outputs. This teaches the model to follow instructions across a wide range of tasks.\",\n",
      "            \"Example\": \"Training a model on datasets like FLAN, which contains tasks formatted as instructions (e.g., 'Summarize the following article: [article text]').\",\n",
      "            \"Pros_Cons\": \"Pros: Improves generalization to unseen tasks, enhances the model's ability to follow instructions. Cons: Requires curated instruction datasets, can still be computationally intensive.\",\n",
      "            \"When_to_use\": \"To improve a model's ability to perform a wide variety of tasks described via natural language instructions, enhancing its versatility and usability.\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "input_prompt = [\"What kind of methods that can be used to tune a large language model?\"]\n",
    "text_response = prompt_gemini(input_prompt = input_prompt, schema = list[Overview])\n",
    "print(text_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_7_'></a>[**2.3 Information Extraction and Grounding:**](#toc0_)\n",
    "\n",
    "`NOTE: This whole section including the exercise is now considered a bonus section, not counted for the main grade.`\n",
    "\n",
    "When using LLMs to extract structured data from text, two main challenges arise:\n",
    "\n",
    "1.  **Trust:** LLMs can \"hallucinate\" or invent information. We need to ensure the extracted data is accurate and comes directly from the source text.\n",
    "2.  **Scalability:** We need a reliable way to extract complex information consistently from thousands of large, messy documents.\n",
    "\n",
    "The solution to these challenges is **grounding**the process of linking every piece of extracted data back to its specific origin in the source document. This creates a verifiable audit trail, building trust in the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### <a id='toc1_5_7_1_'></a>[**`langextract`: A Library for Grounded Extraction**](#toc0_)\n",
    "\n",
    "**`langextract`** is an open-source Python library from Google designed to create trustworthy data extraction pipelines. It uses LLMs to convert unstructured text into structured data with a focus on reliability and traceability.\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "*   **Precise Grounding:** Its core feature. It maps every extracted item to its exact character position in the original text, allowing for easy verification.\n",
    "*   **Reliable Structured Output:** Uses examples (few-shot prompting) to ensure the LLM's output consistently follows a predefined format.\n",
    "*   **Adaptable & No Fine-Tuning:** Can be adapted to any domain (e.g., legal, medical) simply by changing the examples and instructions, without needing to retrain a model.\n",
    "*   **Handles Long Documents:** Built to process lengthy texts that might exceed an LLM's standard context window.\n",
    "*   **Flexible LLM Support:** It is model-agnostic and works with various LLMs like Gemini, OpenAI models, and even local open-source models through Ollama.\n",
    "\n",
    "**`Github repository:`** [langextract](https://github.com/google/langextract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##### <a id='toc1_5_7_1_1_'></a>[**2.3.1 Using PDF Documents:**](#toc0_)\n",
    "\n",
    "For PDF Document information extraction we are going to use the `pymupdf` library. Documentation: [pymupdf](https://pymupdf.readthedocs.io/en/latest/)\n",
    "\n",
    "And then we are going to pass it on to langextract to get insights on the document's content.\n",
    "\n",
    "We can also process documents using Gemini, for more information you can check their documentation: [Document Understanding](https://ai.google.dev/gemini-api/docs/document-processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Extracted text from './data/documents/doc_example_review_interstellar.pdf'\n"
     ]
    }
   ],
   "source": [
    "import pymupdf\n",
    "# Extract text from the PDF and format it for the prompt\n",
    "# This is a review from the movie interstellar\n",
    "pdf_path = \"./data/documents/doc_example_review_interstellar.pdf\"\n",
    "formatted_text = \"\"\n",
    "try:\n",
    "    doc = pymupdf.open(pdf_path)\n",
    "    # In case the PDF documents have more than one page, in this example it only has one\n",
    "    for i, page in enumerate(doc):\n",
    "        text = page.get_text(\"text\")\n",
    "        # Format follows the prompt's requirement: **Page X** \"\"\"document's text\"\"\"\n",
    "        formatted_text += f'**Page {i + 1}**\\n'\n",
    "        formatted_text += f'\"\"\"\\n{text.strip()}\\n\"\"\"\\n\\n'\n",
    "    doc.close()\n",
    "    print(f\" Extracted text from '{pdf_path}'\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not read PDF: {e}\")\n",
    "    formatted_text = \"Error: Could not process PDF file.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Page 1**\n",
      "\"\"\"\n",
      "Dan Baldwin\n",
      "Group 4\n",
      "Auteur Review - Interstellar \n",
      "I believe Christopher Nolan: the director behind the 2014 sci-/adventure cinematic Interstellar, \n",
      "to be a very intellectual and imaginative inventive talent.  \n",
      "His style in his previous lms sets characters in epic unique locations, with gargantuan issues to \n",
      "face, and artistically impresses the audience with how the characters solve their problems. For \n",
      "example, in Nolans 2010 lm Inception, he tackles the idea of dreams, and sets his characters \n",
      "diving through dreams within dreams within even more dreams to complete their goals. Because \n",
      "this idea is so farfetched, and dreams are a subject in which science has made little factual \n",
      "discovery in, Nolan is free to use his creativity to present ideas such as landscapes folding in on \n",
      "themselves and corridors spinning, without seeming unrealistic. \n",
      "This brain-racking epic theme is once again evident in Interstellar, as Nolan sets his characters \n",
      "during a second American dust bowl on future Earth. The world is short of food, and will soon be \n",
      "uninhabitable. So, ex-NASA pilot Cooper (Matthew McConaughey) is summoned back to space \n",
      "travel in a bid to nd a new planet for the species to inhabit. Luckily for Cooper and his team, a \n",
      "black hole orbiting Saturn can transport them further into space to land on these potential \n",
      "planets. \n",
      "Throughout the ick, the crew explore multiple worlds - again feeding Nolans mind more \n",
      "opportunities to create crazy scenarios. For example, one planet that Cooper and his friends, \n",
      "Brand, (Anne Hathaway) and Romilly, (David Gyasi) visit initially seems like an innite sea of two \n",
      "feet deep water. Not threatening at all right? Well think again, because the crew suddenly nd out \n",
      "that a giant 100ft tidal wave is about to hit them, and they have minutes to y away. Nolan further \n",
      "increases the stakes in this scene as it is explained that every hour spent on this planet counts for \n",
      "seven years on earth, meaning the planet will be destroyed before they return if their ship sinks. \n",
      "At the climax of the lm, the crew end up sending themselves through a black hole into a \n",
      "tesseract (a 3D representation of a larger dimension) to nd the secret to harnessing gravity \n",
      "which will let the human race bend space-time in order to survive o earth. I know. Mental. \n",
      "The imagination that Nolan possesses and implicates into Interstellar is farfetched and \n",
      "wonderful, not only impressing his audience with the appealing visuals he creates, but induces \n",
      "them to think and discuss what is going on due its scientic depth. Personally, as someone who is \n",
      "bamboozled by the idea of how big the universe is, I nd it unendingly entertaining to repeatedly \n",
      "watch this lm and understanding it more each time, and can only hope the technology portrayed \n",
      "will one day come true. \n",
      "Overall, Interstellar is a clear example of Nolans auteur talent, as he once again gments yet \n",
      "another cluster of conditions for us to marvel at. With a fantastic score from world famous \n",
      "composer Hanz Zimmer, his epic, orchestral theme sets the audience in the palm of his hands as \n",
      "we stress over how we are all going to be saved once again.\n",
      "\"\"\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(formatted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our prompt and examples based on our required type of data, in this case we are going to do it having `movie reviews` in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langextract as lx\n",
    "import textwrap\n",
    "\n",
    "# Defining the extraction prompt for \"movie review\" type of data\n",
    "prompt = textwrap.dedent(\"\"\"\\\n",
    "    Extract specific opinions and their impact on the audience from this movie review.\n",
    "    Important: Use exact text verbatim from the input for extraction_text. Do not paraphrase.\n",
    "    Extract entities in order of appearance with no overlapping text spans.\n",
    "\n",
    "    Use the 'opinion_statement' class for direct judgments about film elements (like plot, score, or acting).\n",
    "    - 'subject' should be the element being reviewed.\n",
    "    - 'sentiment' should be Positive, Negative, or Neutral.\n",
    "    - 'key_phrase' should be the core descriptive words.\n",
    "\n",
    "    Use the 'audience_impact' class for phrases describing the effect on the viewer.\n",
    "    - 'emotion_evoked' should be the feeling or reaction (e.g., stress, joy, confusion).\n",
    "    - 'causal_element' is what part of the film caused the reaction.\n",
    "    - 'target_audience' is who was affected (e.g., 'the audience', 'the reviewer').\n",
    "    \"\"\")\n",
    "\n",
    "# Providing high-quality examples to guide the model\n",
    "# These examples show the model exactly how to differentiate between the two classes\n",
    "examples = [\n",
    "    # Example 1: Demonstrates a positive opinion on the plot and its direct impact on the reviewer\n",
    "    lx.data.ExampleData(\n",
    "        text=\"The film boasts a truly clever plot that kept me guessing until the very end.\",\n",
    "        extractions=[\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"opinion_statement\",\n",
    "                extraction_text=\"a truly clever plot\",\n",
    "                attributes={\n",
    "                    \"subject\": \"The plot\",\n",
    "                    \"sentiment\": \"Positive\",\n",
    "                    \"key_phrase\": \"truly clever\"\n",
    "                }\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"audience_impact\",\n",
    "                extraction_text=\"kept me guessing until the very end\",\n",
    "                attributes={\n",
    "                    \"emotion_evoked\": [\"engaged\", \"curious\"],\n",
    "                    \"causal_element\": \"The plot\",\n",
    "                    \"target_audience\": \"the reviewer\"\n",
    "                }\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    # Example 2: Shows a negative opinion and a separate audience impact caused by the soundtrack\n",
    "    lx.data.ExampleData(\n",
    "        text=\"Unfortunately, the dialogue felt clunky and unnatural, and the jarring soundtrack made the audience jump.\",\n",
    "        extractions=[\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"opinion_statement\",\n",
    "                extraction_text=\"the dialogue felt clunky and unnatural\",\n",
    "                attributes={\n",
    "                    \"subject\": \"The dialogue\",\n",
    "                    \"sentiment\": \"Negative\",\n",
    "                    \"key_phrase\": \"clunky and unnatural\"\n",
    "                }\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"audience_impact\",\n",
    "                extraction_text=\"made the audience jump\",\n",
    "                attributes={\n",
    "                    \"emotion_evoked\": [\"startled\", \"on edge\"],\n",
    "                    \"causal_element\": \"The soundtrack\",\n",
    "                    \"target_audience\": \"the audience\"\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define our main function to call for langextract information extraction, note that there are some constants in the functions that we are not going to change for the example but it would be required to explore and understand in the exercise. In this function we obtain the resulting raw extracted information into a .jsonl file and the visualization into a .html file. Check the documentation for more information.\n",
    "\n",
    "The files will be saved in the following directory: `results/info_extractions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import langextract as lx\n",
    "\n",
    "# We define our main langextract function \n",
    "def grounded_info_extraction(input_documents, prompt, examples, file_name, model_id =\"gemini-2.5-flash-lite\", extraction_passes = 1, max_workers = 5, max_char_buffer = 2000):\n",
    "    result = lx.extract(\n",
    "        text_or_documents=input_documents,\n",
    "        prompt_description=prompt,\n",
    "        examples=examples,\n",
    "        model_id=model_id,\n",
    "        extraction_passes=extraction_passes,    # Improves recall through multiple passes over the same text, needs temperature above 0.0\n",
    "        max_workers=max_workers,         # Parallel processing for speed, remember there are API call rate limits, so do not abuse\n",
    "        max_char_buffer=max_char_buffer    # Smaller contexts for better accuracy, currently: 1000 characters per batch\n",
    "    )\n",
    "\n",
    "    # Display results\n",
    "    print(f\"Extracted {len(result.extractions)} entities:\\n\")\n",
    "    for extraction in result.extractions:\n",
    "        print(f\" {extraction.extraction_class}: '{extraction.extraction_text}'\")\n",
    "        if extraction.attributes:\n",
    "            for key, value in extraction.attributes.items():\n",
    "                print(f\"  - {key}: {value}\")\n",
    "    \n",
    "    output_dir = \"./results/info_extractions\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # Save results to JSONL\n",
    "    lx.io.save_annotated_documents([result], output_name=f\"{file_name}.jsonl\", output_dir=output_dir)\n",
    "\n",
    "    # Generate interactive visualization\n",
    "    html_content = lx.visualize(f\"{output_dir}/{file_name}.jsonl\")\n",
    "    with open(f\"{output_dir}/{file_name}_vis.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        if hasattr(html_content, 'data'):\n",
    "            f.write(html_content.data)\n",
    "        else:\n",
    "            f.write(html_content)\n",
    "\n",
    "    print(f\" Visualization saved to {output_dir}/{file_name}_vis.html\")\n",
    "    \n",
    "    # returning html content for display\n",
    "    return html_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google_genai._api_client:Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 13 entities:\n",
      "\n",
      " opinion_statement: 'a very intellectual and imaginative inventive talent'\n",
      "  - subject: Christopher Nolan\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: very intellectual and imaginative inventive talent\n",
      " opinion_statement: 'artistically impresses the audience'\n",
      "  - subject: Nolan's style\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: artistically impresses\n",
      " opinion_statement: 'This brain-racking epic theme is once again evident in Interstellar,'\n",
      "  - subject: The theme\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: brain-racking epic theme\n",
      " opinion_statement: 'crazy scenarios'\n",
      "  - subject: Nolan's mind\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: crazy\n",
      " opinion_statement: 'Not threatening at all right?'\n",
      "  - subject: The planet\n",
      "  - sentiment: Neutral\n",
      "  - key_phrase: Not threatening at all\n",
      " opinion_statement: 'a giant 100ft tidal wave is about to hit them'\n",
      "  - subject: The tidal wave\n",
      "  - sentiment: Negative\n",
      "  - key_phrase: giant 100ft tidal wave\n",
      " audience_impact: 'minutes to y away'\n",
      "  - emotion_evoked: ['stress', 'urgency']\n",
      "  - causal_element: The tidal wave\n",
      "  - target_audience: the crew\n",
      " opinion_statement: 'farfetched and wonderful'\n",
      "  - subject: The imagination that Nolan possesses and implicates into Interstellar\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: farfetched and wonderful\n",
      " audience_impact: 'not only impressing his audience with the appealing visuals he creates, but induces them to think and discuss what is going on due its scientic depth'\n",
      "  - emotion_evoked: ['impressed', 'thoughtful', 'engaged']\n",
      "  - causal_element: The appealing visuals and scientific depth\n",
      "  - target_audience: his audience\n",
      " audience_impact: 'I nd it unendingly entertaining to repeatedly watch this lm and understanding it more each time'\n",
      "  - emotion_evoked: ['entertained', 'intellectually stimulated']\n",
      "  - causal_element: The film's complexity and depth\n",
      "  - target_audience: the reviewer\n",
      " opinion_statement: 'a clear example of Nolans auteur talent'\n",
      "  - subject: Interstellar\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: clear example of Nolans auteur talent\n",
      " opinion_statement: 'fantastic score'\n",
      "  - subject: The score\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: fantastic\n",
      " audience_impact: 'sets the audience in the palm of his hands as we stress over how we are all going to be saved once again'\n",
      "  - emotion_evoked: ['captivated', 'stressed']\n",
      "  - causal_element: His epic, orchestral theme\n",
      "  - target_audience: the audience\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mLangExtract\u001b[0m: Saving to \u001b[92mreview_extraction_example.jsonl\u001b[0m: 1 docs [00:00, 449.41 docs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[0m Saved \u001b[1m1\u001b[0m documents to \u001b[92mreview_extraction_example.jsonl\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[94m\u001b[1mLangExtract\u001b[0m: Loading \u001b[92mreview_extraction_example.jsonl\u001b[0m: 100%|| 8.58k/8.58k [00:00<00:00, 14.8MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[0m Loaded \u001b[1m1\u001b[0m documents from \u001b[92mreview_extraction_example.jsonl\u001b[0m\n",
      " Visualization saved to ./results/info_extractions/review_extraction_example_vis.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "html_content = grounded_info_extraction(formatted_text, prompt, examples, \"review_extraction_example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'extractions': [{'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'a very intellectual and imaginative inventive talent',\n",
       "   'char_interval': {'start_pos': 172, 'end_pos': 224},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 1,\n",
       "   'group_index': 0,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'Christopher Nolan',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'very intellectual and imaginative inventive talent'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'artistically impresses the audience',\n",
       "   'char_interval': {'start_pos': 338, 'end_pos': 373},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 2,\n",
       "   'group_index': 1,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': \"Nolan's style\",\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'artistically impresses'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'This brain-racking epic theme is once again evident in Interstellar,',\n",
       "   'char_interval': {'start_pos': 878, 'end_pos': 948},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 3,\n",
       "   'group_index': 2,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The theme',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'brain-racking epic theme'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'crazy scenarios',\n",
       "   'char_interval': {'start_pos': 1484, 'end_pos': 1499},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 4,\n",
       "   'group_index': 3,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': \"Nolan's mind\",\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'crazy'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'Not threatening at all right?',\n",
       "   'char_interval': {'start_pos': 1676, 'end_pos': 1705},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 5,\n",
       "   'group_index': 4,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The planet',\n",
       "    'sentiment': 'Neutral',\n",
       "    'key_phrase': 'Not threatening at all'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'a giant 100ft tidal wave is about to hit them',\n",
       "   'char_interval': {'start_pos': 1764, 'end_pos': 1809},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 6,\n",
       "   'group_index': 5,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The tidal wave',\n",
       "    'sentiment': 'Negative',\n",
       "    'key_phrase': 'giant 100ft tidal wave'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'minutes to y away',\n",
       "   'char_interval': {'start_pos': 1825, 'end_pos': 1843},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 7,\n",
       "   'group_index': 6,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['stress', 'urgency'],\n",
       "    'causal_element': 'The tidal wave',\n",
       "    'target_audience': 'the crew'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'farfetched and wonderful',\n",
       "   'char_interval': {'start_pos': 2418, 'end_pos': 2443},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 1,\n",
       "   'group_index': 0,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The imagination that Nolan possesses and implicates into Interstellar',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'farfetched and wonderful'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'not only impressing his audience with the appealing visuals he creates, but induces them to think and discuss what is going on due its scientic depth',\n",
       "   'char_interval': {'start_pos': 2445, 'end_pos': 2596},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 2,\n",
       "   'group_index': 1,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['impressed', 'thoughtful', 'engaged'],\n",
       "    'causal_element': 'The appealing visuals and scientific depth',\n",
       "    'target_audience': 'his audience'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'I nd it unendingly entertaining to repeatedly watch this lm and understanding it more each time',\n",
       "   'char_interval': {'start_pos': 2680, 'end_pos': 2778},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 3,\n",
       "   'group_index': 2,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['entertained',\n",
       "     'intellectually stimulated'],\n",
       "    'causal_element': \"The film's complexity and depth\",\n",
       "    'target_audience': 'the reviewer'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'a clear example of Nolans auteur talent',\n",
       "   'char_interval': {'start_pos': 2876, 'end_pos': 2916},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 4,\n",
       "   'group_index': 3,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'Interstellar',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'clear example of Nolans auteur talent'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'fantastic score',\n",
       "   'char_interval': {'start_pos': 3006, 'end_pos': 3021},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 5,\n",
       "   'group_index': 4,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The score',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'fantastic'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'sets the audience in the palm of his hands as we stress over how we are all going to be saved once again',\n",
       "   'char_interval': {'start_pos': 3090, 'end_pos': 3195},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 6,\n",
       "   'group_index': 5,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['captivated', 'stressed'],\n",
       "    'causal_element': 'His epic, orchestral theme',\n",
       "    'target_audience': 'the audience'}}],\n",
       " 'text': '**Page 1**\\n\"\"\"\\nDan Baldwin\\nGroup 4\\nAuteur Review - Interstellar \\nI believe Christopher Nolan: the director behind the 2014 sci-/adventure cinematic Interstellar, \\nto be a very intellectual and imaginative inventive talent.  \\nHis style in his previous lms sets characters in epic unique locations, with gargantuan issues to \\nface, and artistically impresses the audience with how the characters solve their problems. For \\nexample, in Nolans 2010 lm Inception, he tackles the idea of dreams, and sets his characters \\ndiving through dreams within dreams within even more dreams to complete their goals. Because \\nthis idea is so farfetched, and dreams are a subject in which science has made little factual \\ndiscovery in, Nolan is free to use his creativity to present ideas such as landscapes folding in on \\nthemselves and corridors spinning, without seeming unrealistic. \\nThis brain-racking epic theme is once again evident in Interstellar, as Nolan sets his characters \\nduring a second American dust bowl on future Earth. The world is short of food, and will soon be \\nuninhabitable. So, ex-NASA pilot Cooper (Matthew McConaughey) is summoned back to space \\ntravel in a bid to nd a new planet for the species to inhabit. Luckily for Cooper and his team, a \\nblack hole orbiting Saturn can transport them further into space to land on these potential \\nplanets. \\nThroughout the ick, the crew explore multiple worlds - again feeding Nolans mind more \\nopportunities to create crazy scenarios. For example, one planet that Cooper and his friends, \\nBrand, (Anne Hathaway) and Romilly, (David Gyasi) visit initially seems like an innite sea of two \\nfeet deep water. Not threatening at all right? Well think again, because the crew suddenly nd out \\nthat a giant 100ft tidal wave is about to hit them, and they have minutes to y away. Nolan further \\nincreases the stakes in this scene as it is explained that every hour spent on this planet counts for \\nseven years on earth, meaning the planet will be destroyed before they return if their ship sinks. \\nAt the climax of the lm, the crew end up sending themselves through a black hole into a \\ntesseract (a 3D representation of a larger dimension) to nd the secret to harnessing gravity \\nwhich will let the human race bend space-time in order to survive o earth. I know. Mental. \\nThe imagination that Nolan possesses and implicates into Interstellar is farfetched and \\nwonderful, not only impressing his audience with the appealing visuals he creates, but induces \\nthem to think and discuss what is going on due its scientic depth. Personally, as someone who is \\nbamboozled by the idea of how big the universe is, I nd it unendingly entertaining to repeatedly \\nwatch this lm and understanding it more each time, and can only hope the technology portrayed \\nwill one day come true. \\nOverall, Interstellar is a clear example of Nolans auteur talent, as he once again gments yet \\nanother cluster of conditions for us to marvel at. With a fantastic score from world famous \\ncomposer Hanz Zimmer, his epic, orchestral theme sets the audience in the palm of his hands as \\nwe stress over how we are all going to be saved once again.\\n\"\"\"\\n\\n',\n",
       " 'document_id': 'doc_bd084ab2'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "# We can also observe the structure of the raw extracted data\n",
    "with open(\"./results/info_extractions/review_extraction_example.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    content_extracted_raw = json.load(f)\n",
    "content_extracted_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".lx-highlight { position: relative; border-radius:3px; padding:1px 2px;}\n",
       ".lx-highlight .lx-tooltip {\n",
       "  visibility: hidden;\n",
       "  opacity: 0;\n",
       "  transition: opacity 0.2s ease-in-out;\n",
       "  background: #333;\n",
       "  color: #fff;\n",
       "  text-align: left;\n",
       "  border-radius: 4px;\n",
       "  padding: 6px 8px;\n",
       "  position: absolute;\n",
       "  z-index: 1000;\n",
       "  bottom: 125%;\n",
       "  left: 50%;\n",
       "  transform: translateX(-50%);\n",
       "  font-size: 12px;\n",
       "  max-width: 240px;\n",
       "  white-space: normal;\n",
       "  box-shadow: 0 2px 6px rgba(0,0,0,0.3);\n",
       "}\n",
       ".lx-highlight:hover .lx-tooltip { visibility: visible; opacity:1; }\n",
       ".lx-animated-wrapper { max-width: 100%; font-family: Arial, sans-serif; }\n",
       ".lx-controls {\n",
       "  background: #fafafa; border: 1px solid #90caf9; border-radius: 8px;\n",
       "  padding: 12px; margin-bottom: 16px;\n",
       "}\n",
       ".lx-button-row {\n",
       "  display: flex; justify-content: center; gap: 8px; margin-bottom: 12px;\n",
       "}\n",
       ".lx-control-btn {\n",
       "  background: #4285f4; color: white; border: none; border-radius: 4px;\n",
       "  padding: 8px 16px; cursor: pointer; font-size: 13px; font-weight: 500;\n",
       "  transition: background-color 0.2s;\n",
       "}\n",
       ".lx-control-btn:hover { background: #3367d6; }\n",
       ".lx-progress-container {\n",
       "  margin-bottom: 8px;\n",
       "}\n",
       ".lx-progress-slider {\n",
       "  width: 100%; margin: 0; appearance: none; height: 6px;\n",
       "  background: #ddd; border-radius: 3px; outline: none;\n",
       "}\n",
       ".lx-progress-slider::-webkit-slider-thumb {\n",
       "  appearance: none; width: 18px; height: 18px; background: #4285f4;\n",
       "  border-radius: 50%; cursor: pointer;\n",
       "}\n",
       ".lx-progress-slider::-moz-range-thumb {\n",
       "  width: 18px; height: 18px; background: #4285f4; border-radius: 50%;\n",
       "  cursor: pointer; border: none;\n",
       "}\n",
       ".lx-status-text {\n",
       "  text-align: center; font-size: 12px; color: #666; margin-top: 4px;\n",
       "}\n",
       ".lx-text-window {\n",
       "  font-family: monospace; white-space: pre-wrap; border: 1px solid #90caf9;\n",
       "  padding: 12px; max-height: 260px; overflow-y: auto; margin-bottom: 12px;\n",
       "  line-height: 1.6;\n",
       "}\n",
       ".lx-attributes-panel {\n",
       "  background: #fafafa; border: 1px solid #90caf9; border-radius: 6px;\n",
       "  padding: 8px 10px; margin-top: 8px; font-size: 13px;\n",
       "}\n",
       ".lx-current-highlight {\n",
       "  border-bottom: 4px solid #ff4444;\n",
       "  font-weight: bold;\n",
       "  animation: lx-pulse 1s ease-in-out;\n",
       "}\n",
       "@keyframes lx-pulse {\n",
       "  0% { text-decoration-color: #ff4444; }\n",
       "  50% { text-decoration-color: #ff0000; }\n",
       "  100% { text-decoration-color: #ff4444; }\n",
       "}\n",
       ".lx-legend {\n",
       "  font-size: 12px; margin-bottom: 8px;\n",
       "  padding-bottom: 8px; border-bottom: 1px solid #e0e0e0;\n",
       "}\n",
       ".lx-label {\n",
       "  display: inline-block;\n",
       "  padding: 2px 4px;\n",
       "  border-radius: 3px;\n",
       "  margin-right: 4px;\n",
       "  color: #000;\n",
       "}\n",
       ".lx-attr-key {\n",
       "  font-weight: 600;\n",
       "  color: #1565c0;\n",
       "  letter-spacing: 0.3px;\n",
       "}\n",
       ".lx-attr-value {\n",
       "  font-weight: 400;\n",
       "  opacity: 0.85;\n",
       "  letter-spacing: 0.2px;\n",
       "}\n",
       "\n",
       "/* Add optimizations with larger fonts and better readability for GIFs */\n",
       ".lx-gif-optimized .lx-text-window { font-size: 16px; line-height: 1.8; }\n",
       ".lx-gif-optimized .lx-attributes-panel { font-size: 15px; }\n",
       ".lx-gif-optimized .lx-current-highlight { text-decoration-thickness: 4px; }\n",
       "</style>\n",
       "    <div class=\"lx-animated-wrapper lx-gif-optimized\">\n",
       "      <div class=\"lx-attributes-panel\">\n",
       "        <div class=\"lx-legend\">Highlights Legend: <span class=\"lx-label\" style=\"background-color:#D2E3FC;\">audience_impact</span> <span class=\"lx-label\" style=\"background-color:#C8E6C9;\">opinion_statement</span></div>\n",
       "        <div id=\"attributesContainer\"></div>\n",
       "      </div>\n",
       "      <div class=\"lx-text-window\" id=\"textWindow\">\n",
       "        **Page 1**\n",
       "&quot;&quot;&quot;\n",
       "Dan Baldwin\n",
       "Group 4\n",
       "Auteur Review - Interstellar \n",
       "I believe Christopher Nolan: the director behind the 2014 sci-/adventure cinematic Interstellar, \n",
       "to be <span class=\"lx-highlight lx-current-highlight\" data-idx=\"0\" style=\"background-color:#C8E6C9;\">a very intellectual and imaginative inventive talent</span>.  \n",
       "His style in his previous lms sets characters in epic unique locations, with gargantuan issues to \n",
       "face, and <span class=\"lx-highlight\" data-idx=\"1\" style=\"background-color:#C8E6C9;\">artistically impresses the audience</span> with how the characters solve their problems. For \n",
       "example, in Nolans 2010 lm Inception, he tackles the idea of dreams, and sets his characters \n",
       "diving through dreams within dreams within even more dreams to complete their goals. Because \n",
       "this idea is so farfetched, and dreams are a subject in which science has made little factual \n",
       "discovery in, Nolan is free to use his creativity to present ideas such as landscapes folding in on \n",
       "themselves and corridors spinning, without seeming unrealistic. \n",
       "<span class=\"lx-highlight\" data-idx=\"2\" style=\"background-color:#C8E6C9;\">This brain-racking epic theme is once again evident in Interstellar,</span> as Nolan sets his characters \n",
       "during a second American dust bowl on future Earth. The world is short of food, and will soon be \n",
       "uninhabitable. So, ex-NASA pilot Cooper (Matthew McConaughey) is summoned back to space \n",
       "travel in a bid to nd a new planet for the species to inhabit. Luckily for Cooper and his team, a \n",
       "black hole orbiting Saturn can transport them further into space to land on these potential \n",
       "planets. \n",
       "Throughout the ick, the crew explore multiple worlds - again feeding Nolans mind more \n",
       "opportunities to create <span class=\"lx-highlight\" data-idx=\"3\" style=\"background-color:#C8E6C9;\">crazy scenarios</span>. For example, one planet that Cooper and his friends, \n",
       "Brand, (Anne Hathaway) and Romilly, (David Gyasi) visit initially seems like an innite sea of two \n",
       "feet deep water. <span class=\"lx-highlight\" data-idx=\"4\" style=\"background-color:#C8E6C9;\">Not threatening at all right?</span> Well think again, because the crew suddenly nd out \n",
       "that <span class=\"lx-highlight\" data-idx=\"5\" style=\"background-color:#C8E6C9;\">a giant 100ft tidal wave is about to hit them</span>, and they have <span class=\"lx-highlight\" data-idx=\"6\" style=\"background-color:#D2E3FC;\">minutes to y away</span>. Nolan further \n",
       "increases the stakes in this scene as it is explained that every hour spent on this planet counts for \n",
       "seven years on earth, meaning the planet will be destroyed before they return if their ship sinks. \n",
       "At the climax of the lm, the crew end up sending themselves through a black hole into a \n",
       "tesseract (a 3D representation of a larger dimension) to nd the secret to harnessing gravity \n",
       "which will let the human race bend space-time in order to survive o earth. I know. Mental. \n",
       "The imagination that Nolan possesses and implicates into Interstellar is <span class=\"lx-highlight\" data-idx=\"7\" style=\"background-color:#C8E6C9;\">farfetched and \n",
       "wonderful</span>, <span class=\"lx-highlight\" data-idx=\"8\" style=\"background-color:#D2E3FC;\">not only impressing his audience with the appealing visuals he creates, but induces \n",
       "them to think and discuss what is going on due its scientic depth</span>. Personally, as someone who is \n",
       "bamboozled by the idea of how big the universe is, <span class=\"lx-highlight\" data-idx=\"9\" style=\"background-color:#D2E3FC;\">I nd it unendingly entertaining to repeatedly \n",
       "watch this lm and understanding it more each time</span>, and can only hope the technology portrayed \n",
       "will one day come true. \n",
       "Overall, Interstellar is <span class=\"lx-highlight\" data-idx=\"10\" style=\"background-color:#C8E6C9;\">a clear example of Nolans auteur talent</span>, as he once again gments yet \n",
       "another cluster of conditions for us to marvel at. With a <span class=\"lx-highlight\" data-idx=\"11\" style=\"background-color:#C8E6C9;\">fantastic score</span> from world famous \n",
       "composer Hanz Zimmer, his epic, orchestral theme <span class=\"lx-highlight\" data-idx=\"12\" style=\"background-color:#D2E3FC;\">sets the audience in the palm of his hands as \n",
       "we stress over how we are all going to be saved once again</span>.\n",
       "&quot;&quot;&quot;\n",
       "\n",
       "\n",
       "      </div>\n",
       "      <div class=\"lx-controls\">\n",
       "        <div class=\"lx-button-row\">\n",
       "          <button class=\"lx-control-btn\" onclick=\"playPause()\"> Play</button>\n",
       "          <button class=\"lx-control-btn\" onclick=\"prevExtraction()\"> Previous</button>\n",
       "          <button class=\"lx-control-btn\" onclick=\"nextExtraction()\"> Next</button>\n",
       "        </div>\n",
       "        <div class=\"lx-progress-container\">\n",
       "          <input type=\"range\" id=\"progressSlider\" class=\"lx-progress-slider\"\n",
       "                 min=\"0\" max=\"12\" value=\"0\"\n",
       "                 onchange=\"jumpToExtraction(this.value)\">\n",
       "        </div>\n",
       "        <div class=\"lx-status-text\">\n",
       "          Entity <span id=\"entityInfo\">1/13</span> |\n",
       "          Pos <span id=\"posInfo\">[172-224]</span>\n",
       "        </div>\n",
       "      </div>\n",
       "    </div>\n",
       "\n",
       "    <script>\n",
       "      (function() {\n",
       "        const extractions = [{\"index\": 0, \"class\": \"opinion_statement\", \"text\": \"a very intellectual and imaginative inventive talent\", \"color\": \"#C8E6C9\", \"startPos\": 172, \"endPos\": 224, \"beforeText\": \"dwin\\nGroup 4\\nAuteur Review - Interstellar \\nI believe Christopher Nolan: the director behind the 2014 sci-\\ufb01/adventure cinematic \\u2018Interstellar,\\u2019 \\nto be \", \"extractionText\": \"a very intellectual and imaginative inventive talent\", \"afterText\": \".  \\nHis style in his previous \\ufb01lms sets characters in epic unique locations, with gargantuan issues to \\nface, and artistically impresses the audience \", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Christopher Nolan</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">very intellectual and imaginative inventive talent</span>}</div>\"}, {\"index\": 1, \"class\": \"opinion_statement\", \"text\": \"artistically impresses the audience\", \"color\": \"#C8E6C9\", \"startPos\": 338, \"endPos\": 373, \"beforeText\": \"ual and imaginative inventive talent.  \\nHis style in his previous \\ufb01lms sets characters in epic unique locations, with gargantuan issues to \\nface, and \", \"extractionText\": \"artistically impresses the audience\", \"afterText\": \" with how the characters solve their problems. For \\nexample, in Nolan\\u2019s 2010 \\ufb01lm \\u2018Inception,\\u2019 he tackles the idea of dreams, and sets his characters \\n\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Nolan&#x27;s style</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">artistically impresses</span>}</div>\"}, {\"index\": 2, \"class\": \"opinion_statement\", \"text\": \"This brain-racking epic theme is once again evident in \\u2018Interstellar,\\u2019\", \"color\": \"#C8E6C9\", \"startPos\": 878, \"endPos\": 948, \"beforeText\": \"lan is free to use his creativity to present ideas such as landscapes folding in on \\nthemselves and corridors spinning, without seeming unrealistic. \\n\", \"extractionText\": \"This brain-racking epic theme is once again evident in \\u2018Interstellar,\\u2019\", \"afterText\": \" as Nolan sets his characters \\nduring a second American dust bowl on future Earth. The world is short of food, and will soon be \\nuninhabitable. So, ex\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The theme</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">brain-racking epic theme</span>}</div>\"}, {\"index\": 3, \"class\": \"opinion_statement\", \"text\": \"crazy scenarios\", \"color\": \"#C8E6C9\", \"startPos\": 1484, \"endPos\": 1499, \"beforeText\": \"o land on these potential \\nplanets. \\nThroughout the \\ufb02ick, the crew explore multiple worlds - again feeding Nolan\\u2019s mind more \\nopportunities to create \", \"extractionText\": \"crazy scenarios\", \"afterText\": \". For example, one planet that Cooper and his friends, \\n\\u2018Brand,\\u2019 (Anne Hathaway) and \\u2018Romilly,\\u2019 (David Gyasi) visit initially seems like an in\\ufb01nite se\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Nolan&#x27;s mind</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">crazy</span>}</div>\"}, {\"index\": 4, \"class\": \"opinion_statement\", \"text\": \"Not threatening at all right?\", \"color\": \"#C8E6C9\", \"startPos\": 1676, \"endPos\": 1705, \"beforeText\": \"hat Cooper and his friends, \\n\\u2018Brand,\\u2019 (Anne Hathaway) and \\u2018Romilly,\\u2019 (David Gyasi) visit initially seems like an in\\ufb01nite sea of two \\nfeet deep water. \", \"extractionText\": \"Not threatening at all right?\", \"afterText\": \" Well think again, because the crew suddenly \\ufb01nd out \\nthat a giant 100ft tidal wave is about to hit them, and they have minutes to \\ufb02y away. Nolan furt\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The planet</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Neutral</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">Not threatening at all</span>}</div>\"}, {\"index\": 5, \"class\": \"opinion_statement\", \"text\": \"a giant 100ft tidal wave is about to hit them\", \"color\": \"#C8E6C9\", \"startPos\": 1764, \"endPos\": 1809, \"beforeText\": \" initially seems like an in\\ufb01nite sea of two \\nfeet deep water. Not threatening at all right? Well think again, because the crew suddenly \\ufb01nd out \\nthat \", \"extractionText\": \"a giant 100ft tidal wave is about to hit them\", \"afterText\": \", and they have minutes to \\ufb02y away. Nolan further \\nincreases the stakes in this scene as it is explained that every hour spent on this planet counts f\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The tidal wave</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Negative</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">giant 100ft tidal wave</span>}</div>\"}, {\"index\": 6, \"class\": \"audience_impact\", \"text\": \"minutes to \\ufb02y away\", \"color\": \"#D2E3FC\", \"startPos\": 1825, \"endPos\": 1843, \"beforeText\": \" Not threatening at all right? Well think again, because the crew suddenly \\ufb01nd out \\nthat a giant 100ft tidal wave is about to hit them, and they have \", \"extractionText\": \"minutes to \\ufb02y away\", \"afterText\": \". Nolan further \\nincreases the stakes in this scene as it is explained that every hour spent on this planet counts for \\nseven years on earth, meaning \", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">stress, urgency</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">The tidal wave</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">the crew</span>}</div>\"}, {\"index\": 7, \"class\": \"opinion_statement\", \"text\": \"farfetched and wonderful\", \"color\": \"#C8E6C9\", \"startPos\": 2418, \"endPos\": 2443, \"beforeText\": \" human race bend space-time in order to survive o\\ufb00 earth. I know. Mental. \\nThe imagination that Nolan possesses and implicates into \\u2018Interstellar\\u2019 is \", \"extractionText\": \"farfetched and \\nwonderful\", \"afterText\": \", not only impressing his audience with the appealing visuals he creates, but induces \\nthem to think and discuss what is going on due its scienti\\ufb01c de\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The imagination that Nolan possesses and implicates into \\u2018Interstellar\\u2019</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">farfetched and wonderful</span>}</div>\"}, {\"index\": 8, \"class\": \"audience_impact\", \"text\": \"not only impressing his audience with the appealing visuals he creates, but induces them to think and discuss what is going on due its scienti\\ufb01c depth\", \"color\": \"#D2E3FC\", \"startPos\": 2445, \"endPos\": 2596, \"beforeText\": \" in order to survive o\\ufb00 earth. I know. Mental. \\nThe imagination that Nolan possesses and implicates into \\u2018Interstellar\\u2019 is farfetched and \\nwonderful, \", \"extractionText\": \"not only impressing his audience with the appealing visuals he creates, but induces \\nthem to think and discuss what is going on due its scienti\\ufb01c depth\", \"afterText\": \". Personally, as someone who is \\nbamboozled by the idea of how big the universe is, I \\ufb01nd it unendingly entertaining to repeatedly \\nwatch this \\ufb01lm and\", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">impressed, thoughtful, engaged</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">The appealing visuals and scientific depth</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">his audience</span>}</div>\"}, {\"index\": 9, \"class\": \"audience_impact\", \"text\": \"I \\ufb01nd it unendingly entertaining to repeatedly watch this \\ufb01lm and understanding it more each time\", \"color\": \"#D2E3FC\", \"startPos\": 2680, \"endPos\": 2778, \"beforeText\": \"them to think and discuss what is going on due its scienti\\ufb01c depth. Personally, as someone who is \\nbamboozled by the idea of how big the universe is, \", \"extractionText\": \"I \\ufb01nd it unendingly entertaining to repeatedly \\nwatch this \\ufb01lm and understanding it more each time\", \"afterText\": \", and can only hope the technology portrayed \\nwill one day come true. \\nOverall, \\u2018Interstellar\\u2019 is a clear example of Nolan\\u2019s auteur talent, as he once\", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">entertained, intellectually stimulated</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">The film&#x27;s complexity and depth</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">the reviewer</span>}</div>\"}, {\"index\": 10, \"class\": \"opinion_statement\", \"text\": \"a clear example of Nolan\\u2019s auteur talent\", \"color\": \"#C8E6C9\", \"startPos\": 2876, \"endPos\": 2916, \"beforeText\": \" \\nwatch this \\ufb01lm and understanding it more each time, and can only hope the technology portrayed \\nwill one day come true. \\nOverall, \\u2018Interstellar\\u2019 is \", \"extractionText\": \"a clear example of Nolan\\u2019s auteur talent\", \"afterText\": \", as he once again \\ufb01gments yet \\nanother cluster of conditions for us to marvel at. With a fantastic score from world famous \\ncomposer Hanz Zimmer, his\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u2018Interstellar\\u2019</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">clear example of Nolan\\u2019s auteur talent</span>}</div>\"}, {\"index\": 11, \"class\": \"opinion_statement\", \"text\": \"fantastic score\", \"color\": \"#C8E6C9\", \"startPos\": 3006, \"endPos\": 3021, \"beforeText\": \", \\u2018Interstellar\\u2019 is a clear example of Nolan\\u2019s auteur talent, as he once again \\ufb01gments yet \\nanother cluster of conditions for us to marvel at. With a \", \"extractionText\": \"fantastic score\", \"afterText\": \" from world famous \\ncomposer Hanz Zimmer, his epic, orchestral theme sets the audience in the palm of his hands as \\nwe stress over how we are all goin\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The score</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">fantastic</span>}</div>\"}, {\"index\": 12, \"class\": \"audience_impact\", \"text\": \"sets the audience in the palm of his hands as we stress over how we are all going to be saved once again\", \"color\": \"#D2E3FC\", \"startPos\": 3090, \"endPos\": 3195, \"beforeText\": \"ts yet \\nanother cluster of conditions for us to marvel at. With a fantastic score from world famous \\ncomposer Hanz Zimmer, his epic, orchestral theme \", \"extractionText\": \"sets the audience in the palm of his hands as \\nwe stress over how we are all going to be saved once again\", \"afterText\": \".\\n&quot;&quot;&quot;\\n\\n\", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">captivated, stressed</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">His epic, orchestral theme</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">the audience</span>}</div>\"}];\n",
       "        let currentIndex = 0;\n",
       "        let isPlaying = false;\n",
       "        let animationInterval = null;\n",
       "        let animationSpeed = 1.0;\n",
       "\n",
       "        function updateDisplay() {\n",
       "          const extraction = extractions[currentIndex];\n",
       "          if (!extraction) return;\n",
       "\n",
       "          document.getElementById('attributesContainer').innerHTML = extraction.attributesHtml;\n",
       "          document.getElementById('entityInfo').textContent = (currentIndex + 1) + '/' + extractions.length;\n",
       "          document.getElementById('posInfo').textContent = '[' + extraction.startPos + '-' + extraction.endPos + ']';\n",
       "          document.getElementById('progressSlider').value = currentIndex;\n",
       "\n",
       "          const playBtn = document.querySelector('.lx-control-btn');\n",
       "          if (playBtn) playBtn.textContent = isPlaying ? ' Pause' : ' Play';\n",
       "\n",
       "          const prevHighlight = document.querySelector('.lx-text-window .lx-current-highlight');\n",
       "          if (prevHighlight) prevHighlight.classList.remove('lx-current-highlight');\n",
       "          const currentSpan = document.querySelector('.lx-text-window span[data-idx=\"' + currentIndex + '\"]');\n",
       "          if (currentSpan) {\n",
       "            currentSpan.classList.add('lx-current-highlight');\n",
       "            currentSpan.scrollIntoView({block: 'center', behavior: 'smooth'});\n",
       "          }\n",
       "        }\n",
       "\n",
       "        function nextExtraction() {\n",
       "          currentIndex = (currentIndex + 1) % extractions.length;\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function prevExtraction() {\n",
       "          currentIndex = (currentIndex - 1 + extractions.length) % extractions.length;\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function jumpToExtraction(index) {\n",
       "          currentIndex = parseInt(index);\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function playPause() {\n",
       "          if (isPlaying) {\n",
       "            clearInterval(animationInterval);\n",
       "            isPlaying = false;\n",
       "          } else {\n",
       "            animationInterval = setInterval(nextExtraction, animationSpeed * 1000);\n",
       "            isPlaying = true;\n",
       "          }\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        window.playPause = playPause;\n",
       "        window.nextExtraction = nextExtraction;\n",
       "        window.prevExtraction = prevExtraction;\n",
       "        window.jumpToExtraction = jumpToExtraction;\n",
       "\n",
       "        updateDisplay();\n",
       "      })();\n",
       "    </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_7_1_2_'></a>[**>>> Bonus Exercise 3 (Take home):**](#toc0_)\n",
    "\n",
    "`NOTE: This exercise is now considered a bonus one, not counted for the main grade, only as extra points.`\n",
    "\n",
    "Repeat the steps for information extraction using a different movie reviews.\n",
    "1. Search for movie reviews online and save them in a PDF, we suggest **at least 1 page worth of reviews** like in the example.\n",
    "2. Load the PDF and pass them to langextract to extract information from it.\n",
    "3. Display html with the grounded extracted attributes.\n",
    "4. Discuss about the quality of the extracted information with langextract, how could it be improved based on the options the documentation gives that we didn't try?\n",
    "\n",
    "**`Github repository for reference:`** [langextract](https://github.com/google/langextract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Extracted text from './data/documents/movie_review.pdf'\n",
      "**Page 1**\n",
      "\"\"\"\n",
      "Movie Reviews \n",
      "by Bob Mondello \n",
      "  \n",
      "'Wall-E,' Speaking Volumes with Stillness and Stars \n",
      "Listen Now [4 min 37 sec] add to playlist  \n",
      "  \n",
      " \n",
      "Enlarge \n",
      " \n",
      "Evolutionary thinking: Wall-E may have started out as a glorified trash compactor, but he's learned how to look to the sky. Pixar \n",
      "Wall-E \n",
      " \n",
      "Director: Andrew Stanton  \n",
      " \n",
      "Genre: Sci-Fi  \n",
      " \n",
      "Running Time: 97 minutes \n",
      "Rated G: Big-hearted and full of wonder, but too smart to be saccharine. \n",
      "The first hour of Wall-E is a crazily inventive, deliriously engaging and almost wordless silent comedy of the sort that \n",
      "Charlie Chaplin and Buster Keaton used to make. \n",
      " \n",
      "All Things Considered, June 27, 2008  The camera descends, at the start of Wall-E, from \n",
      "outer space to a landscape that looks eerily familiar  and sort of not. The sun filters \n",
      "down through a brownish haze. What seem at first like skyscrapers turn out to be neatly \n",
      "stacked mountains of trash. Stillness is everywhere, broken only by the unlikely sound of \n",
      "a song from Hello, Dolly!  and a solitary figure zipping around a junk-strewn \n",
      "cityscape.  \n",
      "Apparently, humans never changed course on pollution and consumerism, and sometime \n",
      "in the 22nd century they were forced to leave a planet they had turned into a giant \n",
      "garbage dump. But they left without turning off a robot they'd left behind. He's basically \n",
      "a trash compactor on treads  a Waste Allocation Load-Lifter: Earth Class, or WALL-E \n",
      " who has, over the course of 700 years, developed a personality.\n",
      "\"\"\"\n",
      "\n",
      "**Page 2**\n",
      "\"\"\"\n",
      "He tries to puzzle out what mankind's detritus was for (a Rubik's cube, a spork, a fire \n",
      "extinguisher), and he saves a few items  an alarmingly fresh 700-year-old Twinkie, \n",
      "say, for his pet cockroach.  \n",
      "But most of the trash he compacts and stacks, in a routine that is interrupted only when he \n",
      "falls head-over-treads for a sleek robot from the stars: EVE (for Extra-terrestrial \n",
      "Vegetation Evaluator), whom he watches from afar so he won't be incinerated.  \n",
      "Eve has an itchy trigger-finger, it turns out. \n",
      "The first hour of Wall-E is a crazily inventive, deliriously engaging and almost wordless \n",
      "silent comedy of the sort that Charlie Chaplin and Buster Keaton used to make. Things \n",
      "turn more conventional in the last half hour, when pudgy, machine-dependent humans \n",
      "make an appearance, but the glow of that first part will carry you through.  \n",
      "That and the majesty of the filmmaking: Wall-E's world, in all its epic decay, looks real. \n",
      "You can almost taste the dust. And it's emotionally real too  enough so that a \n",
      "cautionary tale about the environment, and about big corporations that don't take care of \n",
      "it, and about getting so caught up in our gadgetry that we forget to look at the stars all \n",
      "take a back seat to romance.  \n",
      "So do some specifically cinematic subtexts. Director Andrew Stanton and his animators \n",
      "have slipped in nods not just to Hello, Dolly!, but to Star Wars and Blade Runner, An \n",
      "Inconvenient Truth and the comedies of Chaplin and Jacques Tati. More than just a nod \n",
      "to Chaplin, actually: Wall-E, with his workaholic scruffiness and his yearning for \n",
      "someone to hold hands with, might as well be Chaplin's Little Tramp. \n",
      "There's actually a nice parallel between this largely silent film and Chaplin's first sound \n",
      "film, Modern Times. In that one, the silent clown used the soundtrack mostly for music \n",
      "and effects, not for speech, just as Pixar does here. Chaplin only let you hear a human \n",
      "voice a couple of times, and only on some sort of mechanical contraption  say a closed-\n",
      "circuit TV screen  to emphasize its artificiality. It was his way of saying to the sound \n",
      "world, \"OK, everybody's doing this talking thing now, but look how much more \n",
      "expressive our silent world is.\"  \n",
      "For the first time in a Pixar movie, Wall-E's filmmakers give a nod to the world of actual \n",
      "actors and cameras  and make them artificial in the same way: by only letting you see \n",
      "them on video screens, where they look flat and washed-out compared to the digital \n",
      "world around them. \n",
      "But there's one difference. Chaplin knew he had lost the battle: Silence was finished; \n",
      "sound had won. In today's Hollywood, digital is what's taking over  in special effects, \n",
      "in green-screen work, in animation. And Pixar's animators, bless them, are at the\n",
      "\"\"\"\n",
      "\n",
      "**Page 3**\n",
      "\"\"\"\n",
      "forefront, insisting that imagery created on computers doesn't have to be soulless. Wall-\n",
      "E's images are filled with emotion, just as silent film's images were  even though its \n",
      "characters look like they're made of metal and plastic, and can't say a word.  \n",
      "Wall-E is being sold as a futuristic fantasy, of course. But I have to say I'm just as \n",
      "gratified by their look back 70 years to silent movies as I am by their look forward 700 \n",
      "years to a silent planet.\n",
      "\"\"\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Answer here\n",
    "pdf_path = \"./data/documents/movie_review.pdf\"\n",
    "formatted_text = \"\"\n",
    "try:\n",
    "    doc = pymupdf.open(pdf_path)\n",
    "    # In case the PDF documents have more than one page, in this example it only has one\n",
    "    for i, page in enumerate(doc):\n",
    "        text = page.get_text(\"text\")\n",
    "        # Format follows the prompt's requirement: **Page X** \"\"\"document's text\"\"\"\n",
    "        formatted_text += f'**Page {i + 1}**\\n'\n",
    "        formatted_text += f'\"\"\"\\n{text.strip()}\\n\"\"\"\\n\\n'\n",
    "    doc.close()\n",
    "    print(f\" Extracted text from '{pdf_path}'\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not read PDF: {e}\")\n",
    "    formatted_text = \"Error: Could not process PDF file.\"\n",
    "print(formatted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langextract as lx\n",
    "import textwrap\n",
    "\n",
    "# Defining the extraction prompt for \"movie review\" type of data\n",
    "prompt = textwrap.dedent(\"\"\"\\\n",
    "    Extract specific opinions and their impact on the audience from this movie review.\n",
    "    Important: Use exact text verbatim from the input for extraction_text. Do not paraphrase.\n",
    "    Extract entities in order of appearance with no overlapping text spans.\n",
    "\n",
    "    Use the 'opinion_statement' class for direct judgments about film elements (like plot, score, or acting).\n",
    "    - 'subject' should be the element being reviewed.\n",
    "    - 'sentiment' should be Positive, Negative, or Neutral.\n",
    "    - 'key_phrase' should be the core descriptive words.\n",
    "\n",
    "    Use the 'audience_impact' class for phrases describing the effect on the viewer.\n",
    "    - 'emotion_evoked' should be the feeling or reaction (e.g., stress, joy, confusion).\n",
    "    - 'causal_element' is what part of the film caused the reaction.\n",
    "    - 'target_audience' is who was affected (e.g., 'the audience', 'the reviewer').\n",
    "    \"\"\")\n",
    "\n",
    "# Providing high-quality examples to guide the model\n",
    "# These examples show the model exactly how to differentiate between the two classes\n",
    "examples = [\n",
    "    # Example 1: Demonstrates a positive opinion on the plot and its direct impact on the reviewer\n",
    "    lx.data.ExampleData(\n",
    "        text=\"Wall-E's world, in all its epic decay, looks real. You can almost taste the dust.\",\n",
    "        extractions=[\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"opinion_statement\",\n",
    "                extraction_text=\"looks real\",\n",
    "                attributes={\n",
    "                    \"subject\": \"Wall-E's world\",\n",
    "                    \"sentiment\": \"Positive\",\n",
    "                    \"key_phrase\": \"looks real\"\n",
    "                }\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"audience_impact\",\n",
    "                extraction_text=\"You can almost taste the dust\",\n",
    "                attributes={\n",
    "                    \"emotion_evoked\":  [\"immersion\", \"sensory vividness\"],\n",
    "                    \"causal_element\": \"The dust\",\n",
    "                    \"target_audience\": \"the reviewer\"\n",
    "                }\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    # Example 2: Shows a negative opinion and a separate audience impact caused by the soundtrack\n",
    "    lx.data.ExampleData(\n",
    "        text=\"The first hour of Wall-E is a crazily inventive, deliriously engaging and almost wordless silent comedy of the sort that Charlie Chaplin and Buster Keaton used to make.\",\n",
    "        extractions=[\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"opinion_statement\",\n",
    "                extraction_text=\"a crazily inventive, deliriously engaging and almost wordless silent comedy\",\n",
    "                attributes={\n",
    "                    \"subject\": \"The first hour of Wall-E\",\n",
    "                    \"sentiment\": \"Positive\",\n",
    "                    \"key_phrase\": \"crazily inventive, deliriously engaging and almost wordless silent comedy\"\n",
    "                }\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"audience_impact\",\n",
    "                extraction_text=\"deliriously engaging\",\n",
    "                attributes={\n",
    "                    \"emotion_evoked\": [\"delight\", \"captivation\"],\n",
    "                    \"causal_element\": \"the silent comedy style\",\n",
    "                    \"target_audience\": \"the audience\"\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: non-exact match: [example#1] class='audience_impact' status=AlignmentStatus.MATCH_FUZZY text='deliriously engaging' char_span=(49, 69)\n",
      "WARNING:google_genai._api_client:Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 24 entities:\n",
      "\n",
      " opinion_statement: 'Big-hearted and full of wonder, but too smart to be saccharine.'\n",
      "  - subject: Rated G\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: Big-hearted and full of wonder, but too smart to be saccharine\n",
      " opinion_statement: 'a crazily inventive, deliriously engaging and almost wordless silent comedy of the sort that Charlie Chaplin and Buster Keaton used to make.'\n",
      "  - subject: The first hour of Wall-E\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: crazily inventive, deliriously engaging and almost wordless silent comedy\n",
      " audience_impact: 'deliriously engaging'\n",
      "  - emotion_evoked: ['delight', 'captivation']\n",
      "  - causal_element: the silent comedy style\n",
      "  - target_audience: the audience\n",
      " opinion_statement: 'looks eerily familiar  and sort of not.'\n",
      "  - subject: a landscape\n",
      "  - sentiment: Neutral\n",
      "  - key_phrase: looks eerily familiar  and sort of not\n",
      " opinion_statement: 'Stillness is everywhere'\n",
      "  - subject: the landscape\n",
      "  - sentiment: Neutral\n",
      "  - key_phrase: Stillness is everywhere\n",
      " opinion_statement: 'developed a personality.'\n",
      "  - subject: He\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: developed a personality\n",
      " opinion_statement: 'a crazily inventive, deliriously engaging and almost wordless silent comedy'\n",
      "  - subject: The first hour of Wall-E\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: crazily inventive, deliriously engaging and almost wordless silent comedy\n",
      " opinion_statement: 'more conventional'\n",
      "  - subject: Things\n",
      "  - sentiment: Negative\n",
      "  - key_phrase: more conventional\n",
      " audience_impact: 'the glow of that first part will carry you through'\n",
      "  - emotion_evoked: ['sustained engagement', 'satisfaction']\n",
      "  - causal_element: the glow of that first part\n",
      "  - target_audience: the audience\n",
      " opinion_statement: 'looks real'\n",
      "  - subject: Wall-E's world\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: looks real\n",
      " audience_impact: 'You can almost taste the dust'\n",
      "  - emotion_evoked: ['immersion', 'sensory vividness']\n",
      "  - causal_element: The dust\n",
      "  - target_audience: the reviewer\n",
      " opinion_statement: 'emotionally real'\n",
      "  - subject: it\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: emotionally real\n",
      " opinion_statement: 'a cautionary tale about the environment, and about big corporations that don't take care of it, and about getting so caught up in our gadgetry that we forget to look at the stars all take a back seat to romance'\n",
      "  - subject: cautionary tale\n",
      "  - sentiment: Negative\n",
      "  - key_phrase: take a back seat to romance\n",
      " opinion_statement: 'nods not just to Hello, Dolly!, but to Star Wars and Blade Runner, An Inconvenient Truth and the comedies of Chaplin and Jacques Tati'\n",
      "  - subject: Director Andrew Stanton and his animators\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: slipped in nods\n",
      " opinion_statement: 'might as well be Chaplin's Little Tramp'\n",
      "  - subject: Wall-E\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: might as well be Chaplin's Little Tramp\n",
      " opinion_statement: 'nice parallel'\n",
      "  - subject: this largely silent film and Chaplin's first sound film, Modern Times\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: nice parallel\n",
      " opinion_statement: 'silent clown used the soundtrack mostly for music and effects, not for speech'\n",
      "  - subject: the silent clown\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: used the soundtrack mostly for music and effects, not for speech\n",
      " opinion_statement: 'look how much more expressive our silent world is'\n",
      "  - subject: our silent world\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: more expressive\n",
      " opinion_statement: 'look flat and washed-out'\n",
      "  - subject: actual actors and cameras\n",
      "  - sentiment: Negative\n",
      "  - key_phrase: flat and washed-out\n",
      " opinion_statement: 'digital is what's taking over'\n",
      "  - subject: digital\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: taking over\n",
      " opinion_statement: 'imagery created on computers doesn't have to be soulless'\n",
      "  - subject: imagery created on computers\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: doesn't have to be soulless\n",
      " opinion_statement: 'Wall-E's images are filled with emotion'\n",
      "  - subject: Wall-E's images\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: filled with emotion\n",
      " opinion_statement: 'gratified by their look back 70 years to silent movies'\n",
      "  - subject: their look back 70 years to silent movies\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: gratified\n",
      " opinion_statement: 'gratified by their look forward 700 years to a silent planet'\n",
      "  - subject: their look forward 700 years to a silent planet\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: gratified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mLangExtract\u001b[0m: Saving to \u001b[92mmovie_review_extraction_example.jsonl\u001b[0m: 1 docs [00:00, 518.97 docs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[0m Saved \u001b[1m1\u001b[0m documents to \u001b[92mmovie_review_extraction_example.jsonl\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[94m\u001b[1mLangExtract\u001b[0m: Loading \u001b[92mmovie_review_extraction_example.jsonl\u001b[0m: 100%|| 14.5k/14.5k [00:00<00:00, 32.6MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[0m Loaded \u001b[1m1\u001b[0m documents from \u001b[92mmovie_review_extraction_example.jsonl\u001b[0m\n",
      " Visualization saved to ./results/info_extractions/movie_review_extraction_example_vis.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'extractions': [{'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'Big-hearted and full of wonder, but too smart to be saccharine.',\n",
       "   'char_interval': {'start_pos': 389, 'end_pos': 452},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 1,\n",
       "   'group_index': 0,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'Rated G',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'Big-hearted and full of wonder, but too smart to be saccharine'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'a crazily inventive, deliriously engaging and almost wordless silent comedy of the sort that Charlie Chaplin and Buster Keaton used to make.',\n",
       "   'char_interval': {'start_pos': 483, 'end_pos': 623},\n",
       "   'alignment_status': 'match_lesser',\n",
       "   'extraction_index': 2,\n",
       "   'group_index': 1,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The first hour of Wall-E',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'crazily inventive, deliriously engaging and almost wordless silent comedy'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'deliriously engaging',\n",
       "   'char_interval': {'start_pos': 504, 'end_pos': 524},\n",
       "   'alignment_status': 'match_fuzzy',\n",
       "   'extraction_index': 3,\n",
       "   'group_index': 2,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['delight', 'captivation'],\n",
       "    'causal_element': 'the silent comedy style',\n",
       "    'target_audience': 'the audience'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'looks eerily familiar  and sort of not.',\n",
       "   'char_interval': {'start_pos': 751, 'end_pos': 791},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 4,\n",
       "   'group_index': 3,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'a landscape',\n",
       "    'sentiment': 'Neutral',\n",
       "    'key_phrase': 'looks eerily familiar  and sort of not'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'Stillness is everywhere',\n",
       "   'char_interval': {'start_pos': 926, 'end_pos': 949},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 5,\n",
       "   'group_index': 4,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'the landscape',\n",
       "    'sentiment': 'Neutral',\n",
       "    'key_phrase': 'Stillness is everywhere'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'developed a personality.',\n",
       "   'char_interval': {'start_pos': 1470, 'end_pos': 1494},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 6,\n",
       "   'group_index': 5,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'He',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'developed a personality'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'a crazily inventive, deliriously engaging and almost wordless silent comedy',\n",
       "   'char_interval': {'start_pos': 2052, 'end_pos': 2128},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 1,\n",
       "   'group_index': 0,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The first hour of Wall-E',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'crazily inventive, deliriously engaging and almost wordless silent comedy'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'more conventional',\n",
       "   'char_interval': {'start_pos': 2207, 'end_pos': 2224},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 2,\n",
       "   'group_index': 1,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'Things',\n",
       "    'sentiment': 'Negative',\n",
       "    'key_phrase': 'more conventional'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'the glow of that first part will carry you through',\n",
       "   'char_interval': {'start_pos': 2310, 'end_pos': 2360},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 3,\n",
       "   'group_index': 2,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['sustained engagement', 'satisfaction'],\n",
       "    'causal_element': 'the glow of that first part',\n",
       "    'target_audience': 'the audience'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'looks real',\n",
       "   'char_interval': {'start_pos': 2443, 'end_pos': 2453},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 4,\n",
       "   'group_index': 3,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': \"Wall-E's world\",\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'looks real'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'You can almost taste the dust',\n",
       "   'char_interval': {'start_pos': 2456, 'end_pos': 2485},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 5,\n",
       "   'group_index': 4,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['immersion', 'sensory vividness'],\n",
       "    'causal_element': 'The dust',\n",
       "    'target_audience': 'the reviewer'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'emotionally real',\n",
       "   'char_interval': {'start_pos': 2496, 'end_pos': 2512},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 6,\n",
       "   'group_index': 5,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'it',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'emotionally real'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': \"a cautionary tale about the environment, and about big corporations that don't take care of it, and about getting so caught up in our gadgetry that we forget to look at the stars all take a back seat to romance\",\n",
       "   'char_interval': {'start_pos': 2534, 'end_pos': 2747},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 7,\n",
       "   'group_index': 6,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'cautionary tale',\n",
       "    'sentiment': 'Negative',\n",
       "    'key_phrase': 'take a back seat to romance'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'nods not just to Hello, Dolly!, but to Star Wars and Blade Runner, An Inconvenient Truth and the comedies of Chaplin and Jacques Tati',\n",
       "   'char_interval': {'start_pos': 2854, 'end_pos': 2988},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 8,\n",
       "   'group_index': 7,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'Director Andrew Stanton and his animators',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'slipped in nods'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': \"might as well be Chaplin's Little Tramp\",\n",
       "   'char_interval': {'start_pos': 3124, 'end_pos': 3163},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 9,\n",
       "   'group_index': 8,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'Wall-E',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': \"might as well be Chaplin's Little Tramp\"}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'nice parallel',\n",
       "   'char_interval': {'start_pos': 3185, 'end_pos': 3198},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 10,\n",
       "   'group_index': 9,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': \"this largely silent film and Chaplin's first sound film, Modern Times\",\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'nice parallel'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'silent clown used the soundtrack mostly for music and effects, not for speech',\n",
       "   'char_interval': {'start_pos': 3296, 'end_pos': 3374},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 11,\n",
       "   'group_index': 10,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'the silent clown',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'used the soundtrack mostly for music and effects, not for speech'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'look how much more expressive our silent world is',\n",
       "   'char_interval': {'start_pos': 3674, 'end_pos': 3724},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 12,\n",
       "   'group_index': 11,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'our silent world',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'more expressive'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'look flat and washed-out',\n",
       "   'char_interval': {'start_pos': 3943, 'end_pos': 3967},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 1,\n",
       "   'group_index': 0,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'actual actors and cameras',\n",
       "    'sentiment': 'Negative',\n",
       "    'key_phrase': 'flat and washed-out'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': \"digital is what's taking over\",\n",
       "   'char_interval': {'start_pos': 4138, 'end_pos': 4167},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 2,\n",
       "   'group_index': 1,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'digital',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'taking over'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': \"imagery created on computers doesn't have to be soulless\",\n",
       "   'char_interval': {'start_pos': 4319, 'end_pos': 4375},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 3,\n",
       "   'group_index': 2,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'imagery created on computers',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': \"doesn't have to be soulless\"}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': \"Wall-E's images are filled with emotion\",\n",
       "   'char_interval': {'start_pos': 4377, 'end_pos': 4417},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 4,\n",
       "   'group_index': 3,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': \"Wall-E's images\",\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'filled with emotion'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'gratified by their look back 70 years to silent movies',\n",
       "   'char_interval': {'start_pos': 4640, 'end_pos': 4694},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 5,\n",
       "   'group_index': 4,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'their look back 70 years to silent movies',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'gratified'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'gratified by their look forward 700 years to a silent planet',\n",
       "   'char_interval': {'start_pos': 4640, 'end_pos': 4754},\n",
       "   'alignment_status': 'match_fuzzy',\n",
       "   'extraction_index': 6,\n",
       "   'group_index': 5,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'their look forward 700 years to a silent planet',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'gratified'}}],\n",
       " 'text': '**Page 1**\\n\"\"\"\\nMovie Reviews \\nby Bob Mondello \\n  \\n\\'Wall-E,\\' Speaking Volumes with Stillness and Stars \\nListen Now [4 min 37 sec] add to playlist  \\n  \\n \\nEnlarge \\n \\nEvolutionary thinking: Wall-E may have started out as a glorified trash compactor, but he\\'s learned how to look to the sky. Pixar \\nWall-E \\n \\nDirector: Andrew Stanton  \\n \\nGenre: Sci-Fi  \\n \\nRunning Time: 97 minutes \\nRated G: Big-hearted and full of wonder, but too smart to be saccharine. \\nThe first hour of Wall-E is a crazily inventive, deliriously engaging and almost wordless silent comedy of the sort that \\nCharlie Chaplin and Buster Keaton used to make. \\n \\nAll Things Considered, June 27, 2008  The camera descends, at the start of Wall-E, from \\nouter space to a landscape that looks eerily familiar  and sort of not. The sun filters \\ndown through a brownish haze. What seem at first like skyscrapers turn out to be neatly \\nstacked mountains of trash. Stillness is everywhere, broken only by the unlikely sound of \\na song from Hello, Dolly!  and a solitary figure zipping around a junk-strewn \\ncityscape.  \\nApparently, humans never changed course on pollution and consumerism, and sometime \\nin the 22nd century they were forced to leave a planet they had turned into a giant \\ngarbage dump. But they left without turning off a robot they\\'d left behind. He\\'s basically \\na trash compactor on treads  a Waste Allocation Load-Lifter: Earth Class, or WALL-E \\n who has, over the course of 700 years, developed a personality.\\n\"\"\"\\n\\n**Page 2**\\n\"\"\"\\nHe tries to puzzle out what mankind\\'s detritus was for (a Rubik\\'s cube, a spork, a fire \\nextinguisher), and he saves a few items  an alarmingly fresh 700-year-old Twinkie, \\nsay, for his pet cockroach.  \\nBut most of the trash he compacts and stacks, in a routine that is interrupted only when he \\nfalls head-over-treads for a sleek robot from the stars: EVE (for Extra-terrestrial \\nVegetation Evaluator), whom he watches from afar so he won\\'t be incinerated.  \\nEve has an itchy trigger-finger, it turns out. \\nThe first hour of Wall-E is a crazily inventive, deliriously engaging and almost wordless \\nsilent comedy of the sort that Charlie Chaplin and Buster Keaton used to make. Things \\nturn more conventional in the last half hour, when pudgy, machine-dependent humans \\nmake an appearance, but the glow of that first part will carry you through.  \\nThat and the majesty of the filmmaking: Wall-E\\'s world, in all its epic decay, looks real. \\nYou can almost taste the dust. And it\\'s emotionally real too  enough so that a \\ncautionary tale about the environment, and about big corporations that don\\'t take care of \\nit, and about getting so caught up in our gadgetry that we forget to look at the stars all \\ntake a back seat to romance.  \\nSo do some specifically cinematic subtexts. Director Andrew Stanton and his animators \\nhave slipped in nods not just to Hello, Dolly!, but to Star Wars and Blade Runner, An \\nInconvenient Truth and the comedies of Chaplin and Jacques Tati. More than just a nod \\nto Chaplin, actually: Wall-E, with his workaholic scruffiness and his yearning for \\nsomeone to hold hands with, might as well be Chaplin\\'s Little Tramp. \\nThere\\'s actually a nice parallel between this largely silent film and Chaplin\\'s first sound \\nfilm, Modern Times. In that one, the silent clown used the soundtrack mostly for music \\nand effects, not for speech, just as Pixar does here. Chaplin only let you hear a human \\nvoice a couple of times, and only on some sort of mechanical contraption  say a closed-\\ncircuit TV screen  to emphasize its artificiality. It was his way of saying to the sound \\nworld, \"OK, everybody\\'s doing this talking thing now, but look how much more \\nexpressive our silent world is.\"  \\nFor the first time in a Pixar movie, Wall-E\\'s filmmakers give a nod to the world of actual \\nactors and cameras  and make them artificial in the same way: by only letting you see \\nthem on video screens, where they look flat and washed-out compared to the digital \\nworld around them. \\nBut there\\'s one difference. Chaplin knew he had lost the battle: Silence was finished; \\nsound had won. In today\\'s Hollywood, digital is what\\'s taking over  in special effects, \\nin green-screen work, in animation. And Pixar\\'s animators, bless them, are at the\\n\"\"\"\\n\\n**Page 3**\\n\"\"\"\\nforefront, insisting that imagery created on computers doesn\\'t have to be soulless. Wall-\\nE\\'s images are filled with emotion, just as silent film\\'s images were  even though its \\ncharacters look like they\\'re made of metal and plastic, and can\\'t say a word.  \\nWall-E is being sold as a futuristic fantasy, of course. But I have to say I\\'m just as \\ngratified by their look back 70 years to silent movies as I am by their look forward 700 \\nyears to a silent planet.\\n\"\"\"\\n\\n',\n",
       " 'document_id': 'doc_c1146f5d'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_content = grounded_info_extraction(formatted_text, prompt, examples, \"movie_review_extraction_example\")\n",
    "\n",
    "with open(\"./results/info_extractions/movie_review_extraction_example.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    content_extracted_raw = json.load(f)\n",
    "content_extracted_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".lx-highlight { position: relative; border-radius:3px; padding:1px 2px;}\n",
       ".lx-highlight .lx-tooltip {\n",
       "  visibility: hidden;\n",
       "  opacity: 0;\n",
       "  transition: opacity 0.2s ease-in-out;\n",
       "  background: #333;\n",
       "  color: #fff;\n",
       "  text-align: left;\n",
       "  border-radius: 4px;\n",
       "  padding: 6px 8px;\n",
       "  position: absolute;\n",
       "  z-index: 1000;\n",
       "  bottom: 125%;\n",
       "  left: 50%;\n",
       "  transform: translateX(-50%);\n",
       "  font-size: 12px;\n",
       "  max-width: 240px;\n",
       "  white-space: normal;\n",
       "  box-shadow: 0 2px 6px rgba(0,0,0,0.3);\n",
       "}\n",
       ".lx-highlight:hover .lx-tooltip { visibility: visible; opacity:1; }\n",
       ".lx-animated-wrapper { max-width: 100%; font-family: Arial, sans-serif; }\n",
       ".lx-controls {\n",
       "  background: #fafafa; border: 1px solid #90caf9; border-radius: 8px;\n",
       "  padding: 12px; margin-bottom: 16px;\n",
       "}\n",
       ".lx-button-row {\n",
       "  display: flex; justify-content: center; gap: 8px; margin-bottom: 12px;\n",
       "}\n",
       ".lx-control-btn {\n",
       "  background: #4285f4; color: white; border: none; border-radius: 4px;\n",
       "  padding: 8px 16px; cursor: pointer; font-size: 13px; font-weight: 500;\n",
       "  transition: background-color 0.2s;\n",
       "}\n",
       ".lx-control-btn:hover { background: #3367d6; }\n",
       ".lx-progress-container {\n",
       "  margin-bottom: 8px;\n",
       "}\n",
       ".lx-progress-slider {\n",
       "  width: 100%; margin: 0; appearance: none; height: 6px;\n",
       "  background: #ddd; border-radius: 3px; outline: none;\n",
       "}\n",
       ".lx-progress-slider::-webkit-slider-thumb {\n",
       "  appearance: none; width: 18px; height: 18px; background: #4285f4;\n",
       "  border-radius: 50%; cursor: pointer;\n",
       "}\n",
       ".lx-progress-slider::-moz-range-thumb {\n",
       "  width: 18px; height: 18px; background: #4285f4; border-radius: 50%;\n",
       "  cursor: pointer; border: none;\n",
       "}\n",
       ".lx-status-text {\n",
       "  text-align: center; font-size: 12px; color: #666; margin-top: 4px;\n",
       "}\n",
       ".lx-text-window {\n",
       "  font-family: monospace; white-space: pre-wrap; border: 1px solid #90caf9;\n",
       "  padding: 12px; max-height: 260px; overflow-y: auto; margin-bottom: 12px;\n",
       "  line-height: 1.6;\n",
       "}\n",
       ".lx-attributes-panel {\n",
       "  background: #fafafa; border: 1px solid #90caf9; border-radius: 6px;\n",
       "  padding: 8px 10px; margin-top: 8px; font-size: 13px;\n",
       "}\n",
       ".lx-current-highlight {\n",
       "  border-bottom: 4px solid #ff4444;\n",
       "  font-weight: bold;\n",
       "  animation: lx-pulse 1s ease-in-out;\n",
       "}\n",
       "@keyframes lx-pulse {\n",
       "  0% { text-decoration-color: #ff4444; }\n",
       "  50% { text-decoration-color: #ff0000; }\n",
       "  100% { text-decoration-color: #ff4444; }\n",
       "}\n",
       ".lx-legend {\n",
       "  font-size: 12px; margin-bottom: 8px;\n",
       "  padding-bottom: 8px; border-bottom: 1px solid #e0e0e0;\n",
       "}\n",
       ".lx-label {\n",
       "  display: inline-block;\n",
       "  padding: 2px 4px;\n",
       "  border-radius: 3px;\n",
       "  margin-right: 4px;\n",
       "  color: #000;\n",
       "}\n",
       ".lx-attr-key {\n",
       "  font-weight: 600;\n",
       "  color: #1565c0;\n",
       "  letter-spacing: 0.3px;\n",
       "}\n",
       ".lx-attr-value {\n",
       "  font-weight: 400;\n",
       "  opacity: 0.85;\n",
       "  letter-spacing: 0.2px;\n",
       "}\n",
       "\n",
       "/* Add optimizations with larger fonts and better readability for GIFs */\n",
       ".lx-gif-optimized .lx-text-window { font-size: 16px; line-height: 1.8; }\n",
       ".lx-gif-optimized .lx-attributes-panel { font-size: 15px; }\n",
       ".lx-gif-optimized .lx-current-highlight { text-decoration-thickness: 4px; }\n",
       "</style>\n",
       "    <div class=\"lx-animated-wrapper lx-gif-optimized\">\n",
       "      <div class=\"lx-attributes-panel\">\n",
       "        <div class=\"lx-legend\">Highlights Legend: <span class=\"lx-label\" style=\"background-color:#D2E3FC;\">audience_impact</span> <span class=\"lx-label\" style=\"background-color:#C8E6C9;\">opinion_statement</span></div>\n",
       "        <div id=\"attributesContainer\"></div>\n",
       "      </div>\n",
       "      <div class=\"lx-text-window\" id=\"textWindow\">\n",
       "        **Page 1**\n",
       "&quot;&quot;&quot;\n",
       "Movie Reviews \n",
       "by Bob Mondello \n",
       "\n",
       "&#x27;Wall-E,&#x27; Speaking Volumes with Stillness and Stars \n",
       "Listen Now [4 min 37 sec] add to playlist  \n",
       "\n",
       "\n",
       "Enlarge \n",
       "\n",
       "Evolutionary thinking: Wall-E may have started out as a glorified trash compactor, but he&#x27;s learned how to look to the sky. Pixar \n",
       "Wall-E \n",
       " \n",
       "Director: Andrew Stanton  \n",
       " \n",
       "Genre: Sci-Fi  \n",
       " \n",
       "Running Time: 97 minutes \n",
       "Rated G: <span class=\"lx-highlight lx-current-highlight\" data-idx=\"0\" style=\"background-color:#C8E6C9;\">Big-hearted and full of wonder, but too smart to be saccharine.</span> \n",
       "The first hour of Wall-E is <span class=\"lx-highlight\" data-idx=\"1\" style=\"background-color:#C8E6C9;\">a crazily inventive, <span class=\"lx-highlight\" data-idx=\"2\" style=\"background-color:#D2E3FC;\">deliriously engaging</span> and almost wordless silent comedy of the sort that \n",
       "Charlie Chaplin and Buster Keaton used to make</span>. \n",
       "\n",
       "All Things Considered, June 27, 2008  The camera descends, at the start of Wall-E, from \n",
       "outer space to a landscape that <span class=\"lx-highlight\" data-idx=\"3\" style=\"background-color:#C8E6C9;\">looks eerily familiar  and sort of not.</span> The sun filters \n",
       "down through a brownish haze. What seem at first like skyscrapers turn out to be neatly \n",
       "stacked mountains of trash. <span class=\"lx-highlight\" data-idx=\"4\" style=\"background-color:#C8E6C9;\">Stillness is everywhere</span>, broken only by the unlikely sound of \n",
       "a song from Hello, Dolly!  and a solitary figure zipping around a junk-strewn \n",
       "cityscape.  \n",
       "Apparently, humans never changed course on pollution and consumerism, and sometime \n",
       "in the 22nd century they were forced to leave a planet they had turned into a giant \n",
       "garbage dump. But they left without turning off a robot they&#x27;d left behind. He&#x27;s basically \n",
       "a trash compactor on treads  a Waste Allocation Load-Lifter: Earth Class, or WALL-E \n",
       " who has, over the course of 700 years, <span class=\"lx-highlight\" data-idx=\"5\" style=\"background-color:#C8E6C9;\">developed a personality.</span>\n",
       "&quot;&quot;&quot;\n",
       "\n",
       "**Page 2**\n",
       "&quot;&quot;&quot;\n",
       "He tries to puzzle out what mankind&#x27;s detritus was for (a Rubik&#x27;s cube, a spork, a fire \n",
       "extinguisher), and he saves a few items  an alarmingly fresh 700-year-old Twinkie, \n",
       "say, for his pet cockroach.  \n",
       "But most of the trash he compacts and stacks, in a routine that is interrupted only when he \n",
       "falls head-over-treads for a sleek robot from the stars: EVE (for Extra-terrestrial \n",
       "Vegetation Evaluator), whom he watches from afar so he won&#x27;t be incinerated.  \n",
       "Eve has an itchy trigger-finger, it turns out. \n",
       "The first hour of Wall-E is <span class=\"lx-highlight\" data-idx=\"6\" style=\"background-color:#C8E6C9;\">a crazily inventive, deliriously engaging and almost wordless \n",
       "silent comedy</span> of the sort that Charlie Chaplin and Buster Keaton used to make. Things \n",
       "turn <span class=\"lx-highlight\" data-idx=\"7\" style=\"background-color:#C8E6C9;\">more conventional</span> in the last half hour, when pudgy, machine-dependent humans \n",
       "make an appearance, but <span class=\"lx-highlight\" data-idx=\"8\" style=\"background-color:#D2E3FC;\">the glow of that first part will carry you through</span>.  \n",
       "That and the majesty of the filmmaking: Wall-E&#x27;s world, in all its epic decay, <span class=\"lx-highlight\" data-idx=\"9\" style=\"background-color:#C8E6C9;\">looks real</span>. \n",
       "<span class=\"lx-highlight\" data-idx=\"10\" style=\"background-color:#D2E3FC;\">You can almost taste the dust</span>. And it&#x27;s <span class=\"lx-highlight\" data-idx=\"11\" style=\"background-color:#C8E6C9;\">emotionally real</span> too  enough so that <span class=\"lx-highlight\" data-idx=\"12\" style=\"background-color:#C8E6C9;\">a \n",
       "cautionary tale about the environment, and about big corporations that don&#x27;t take care of \n",
       "it, and about getting so caught up in our gadgetry that we forget to look at the stars all \n",
       "take a back seat to romance</span>.  \n",
       "So do some specifically cinematic subtexts. Director Andrew Stanton and his animators \n",
       "have slipped in <span class=\"lx-highlight\" data-idx=\"13\" style=\"background-color:#C8E6C9;\">nods not just to Hello, Dolly!, but to Star Wars and Blade Runner, An \n",
       "Inconvenient Truth and the comedies of Chaplin and Jacques Tati</span>. More than just a nod \n",
       "to Chaplin, actually: Wall-E, with his workaholic scruffiness and his yearning for \n",
       "someone to hold hands with, <span class=\"lx-highlight\" data-idx=\"14\" style=\"background-color:#C8E6C9;\">might as well be Chaplin&#x27;s Little Tramp</span>. \n",
       "There&#x27;s actually a <span class=\"lx-highlight\" data-idx=\"15\" style=\"background-color:#C8E6C9;\">nice parallel</span> between this largely silent film and Chaplin&#x27;s first sound \n",
       "film, Modern Times. In that one, the <span class=\"lx-highlight\" data-idx=\"16\" style=\"background-color:#C8E6C9;\">silent clown used the soundtrack mostly for music \n",
       "and effects, not for speech</span>, just as Pixar does here. Chaplin only let you hear a human \n",
       "voice a couple of times, and only on some sort of mechanical contraption  say a closed-\n",
       "circuit TV screen  to emphasize its artificiality. It was his way of saying to the sound \n",
       "world, &quot;OK, everybody&#x27;s doing this talking thing now, but <span class=\"lx-highlight\" data-idx=\"17\" style=\"background-color:#C8E6C9;\">look how much more \n",
       "expressive our silent world is</span>.&quot;  \n",
       "For the first time in a Pixar movie, Wall-E&#x27;s filmmakers give a nod to the world of actual \n",
       "actors and cameras  and make them artificial in the same way: by only letting you see \n",
       "them on video screens, where they <span class=\"lx-highlight\" data-idx=\"18\" style=\"background-color:#C8E6C9;\">look flat and washed-out</span> compared to the digital \n",
       "world around them. \n",
       "But there&#x27;s one difference. Chaplin knew he had lost the battle: Silence was finished; \n",
       "sound had won. In today&#x27;s Hollywood, <span class=\"lx-highlight\" data-idx=\"19\" style=\"background-color:#C8E6C9;\">digital is what&#x27;s taking over</span>  in special effects, \n",
       "in green-screen work, in animation. And Pixar&#x27;s animators, bless them, are at the\n",
       "&quot;&quot;&quot;\n",
       "\n",
       "**Page 3**\n",
       "&quot;&quot;&quot;\n",
       "forefront, insisting that <span class=\"lx-highlight\" data-idx=\"20\" style=\"background-color:#C8E6C9;\">imagery created on computers doesn&#x27;t have to be soulless</span>. <span class=\"lx-highlight\" data-idx=\"21\" style=\"background-color:#C8E6C9;\">Wall-\n",
       "E&#x27;s images are filled with emotion</span>, just as silent film&#x27;s images were  even though its \n",
       "characters look like they&#x27;re made of metal and plastic, and can&#x27;t say a word.  \n",
       "Wall-E is being sold as a futuristic fantasy, of course. But I have to say I&#x27;m just as \n",
       "<span class=\"lx-highlight\" data-idx=\"22\" style=\"background-color:#C8E6C9;\"><span class=\"lx-highlight\" data-idx=\"23\" style=\"background-color:#C8E6C9;\">gratified by their look back 70 years to silent movies</span> as I am by their look forward 700 \n",
       "years to a silent planet</span>.\n",
       "&quot;&quot;&quot;\n",
       "\n",
       "\n",
       "      </div>\n",
       "      <div class=\"lx-controls\">\n",
       "        <div class=\"lx-button-row\">\n",
       "          <button class=\"lx-control-btn\" onclick=\"playPause()\"> Play</button>\n",
       "          <button class=\"lx-control-btn\" onclick=\"prevExtraction()\"> Previous</button>\n",
       "          <button class=\"lx-control-btn\" onclick=\"nextExtraction()\"> Next</button>\n",
       "        </div>\n",
       "        <div class=\"lx-progress-container\">\n",
       "          <input type=\"range\" id=\"progressSlider\" class=\"lx-progress-slider\"\n",
       "                 min=\"0\" max=\"23\" value=\"0\"\n",
       "                 onchange=\"jumpToExtraction(this.value)\">\n",
       "        </div>\n",
       "        <div class=\"lx-status-text\">\n",
       "          Entity <span id=\"entityInfo\">1/24</span> |\n",
       "          Pos <span id=\"posInfo\">[389-452]</span>\n",
       "        </div>\n",
       "      </div>\n",
       "    </div>\n",
       "\n",
       "    <script>\n",
       "      (function() {\n",
       "        const extractions = [{\"index\": 0, \"class\": \"opinion_statement\", \"text\": \"Big-hearted and full of wonder, but too smart to be saccharine.\", \"color\": \"#C8E6C9\", \"startPos\": 389, \"endPos\": 452, \"beforeText\": \"actor, but he&#x27;s learned how to look to the sky. Pixar \\nWall-E \\n\\u2022 \\nDirector: Andrew Stanton  \\n\\u2022 \\nGenre: Sci-Fi  \\n\\u2022 \\nRunning Time: 97 minutes \\nRated G: \", \"extractionText\": \"Big-hearted and full of wonder, but too smart to be saccharine.\", \"afterText\": \" \\n\\u201cThe first hour of Wall-E is a crazily inventive, deliriously engaging and almost wordless silent comedy of the sort that \\nCharlie Chaplin and Buste\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Rated G</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">Big-hearted and full of wonder, but too smart to be saccharine</span>}</div>\"}, {\"index\": 1, \"class\": \"opinion_statement\", \"text\": \"a crazily inventive, deliriously engaging and almost wordless silent comedy of the sort that Charlie Chaplin and Buster Keaton used to make.\", \"color\": \"#C8E6C9\", \"startPos\": 483, \"endPos\": 623, \"beforeText\": \" \\nGenre: Sci-Fi  \\n\\u2022 \\nRunning Time: 97 minutes \\nRated G: Big-hearted and full of wonder, but too smart to be saccharine. \\n\\u201cThe first hour of Wall-E is \", \"extractionText\": \"a crazily inventive, deliriously engaging and almost wordless silent comedy of the sort that \\nCharlie Chaplin and Buster Keaton used to make\", \"afterText\": \".\\u201d \\n \\nAll Things Considered, June 27, 2008 \\u00b7 The camera descends, at the start of Wall-E, from \\nouter space to a landscape that looks eerily familiar \", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The first hour of Wall-E</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">crazily inventive, deliriously engaging and almost wordless silent comedy</span>}</div>\"}, {\"index\": 2, \"class\": \"audience_impact\", \"text\": \"deliriously engaging\", \"color\": \"#D2E3FC\", \"startPos\": 504, \"endPos\": 524, \"beforeText\": \"Running Time: 97 minutes \\nRated G: Big-hearted and full of wonder, but too smart to be saccharine. \\n\\u201cThe first hour of Wall-E is a crazily inventive, \", \"extractionText\": \"deliriously engaging\", \"afterText\": \" and almost wordless silent comedy of the sort that \\nCharlie Chaplin and Buster Keaton used to make.\\u201d \\n \\nAll Things Considered, June 27, 2008 \\u00b7 The ca\", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">delight, captivation</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">the silent comedy style</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">the audience</span>}</div>\"}, {\"index\": 3, \"class\": \"opinion_statement\", \"text\": \"looks eerily familiar \\u2014 and sort of not.\", \"color\": \"#C8E6C9\", \"startPos\": 751, \"endPos\": 791, \"beforeText\": \"er Keaton used to make.\\u201d \\n \\nAll Things Considered, June 27, 2008 \\u00b7 The camera descends, at the start of Wall-E, from \\nouter space to a landscape that \", \"extractionText\": \"looks eerily familiar \\u2014 and sort of not.\", \"afterText\": \" The sun filters \\ndown through a brownish haze. What seem at first like skyscrapers turn out to be neatly \\nstacked mountains of trash. Stillness is ev\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">a landscape</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Neutral</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">looks eerily familiar \\u2014 and sort of not</span>}</div>\"}, {\"index\": 4, \"class\": \"opinion_statement\", \"text\": \"Stillness is everywhere\", \"color\": \"#C8E6C9\", \"startPos\": 926, \"endPos\": 949, \"beforeText\": \"nd sort of not. The sun filters \\ndown through a brownish haze. What seem at first like skyscrapers turn out to be neatly \\nstacked mountains of trash. \", \"extractionText\": \"Stillness is everywhere\", \"afterText\": \", broken only by the unlikely sound of \\na song from Hello, Dolly! \\u2014 and a solitary figure zipping around a junk-strewn \\ncityscape.  \\nApparently, human\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">the landscape</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Neutral</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">Stillness is everywhere</span>}</div>\"}, {\"index\": 5, \"class\": \"opinion_statement\", \"text\": \"developed a personality.\", \"color\": \"#C8E6C9\", \"startPos\": 1470, \"endPos\": 1494, \"beforeText\": \"ehind. He&#x27;s basically \\na trash compactor on treads \\u2014 a Waste Allocation Load-Lifter: Earth Class, or WALL-E \\n\\u2014 who has, over the course of 700 years, \", \"extractionText\": \"developed a personality.\", \"afterText\": \"\\n&quot;&quot;&quot;\\n\\n**Page 2**\\n&quot;&quot;&quot;\\nHe tries to puzzle out what mankind&#x27;s detritus was for (a Rubik&#x27;s cube, a spork, a fire \\nextinguisher), and he saves a few items \", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">He</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">developed a personality</span>}</div>\"}, {\"index\": 6, \"class\": \"opinion_statement\", \"text\": \"a crazily inventive, deliriously engaging and almost wordless silent comedy\", \"color\": \"#C8E6C9\", \"startPos\": 2052, \"endPos\": 2128, \"beforeText\": \"ation Evaluator), whom he watches from afar so he won&#x27;t be incinerated.  \\nEve has an itchy trigger-finger, it turns out. \\nThe first hour of Wall-E is \", \"extractionText\": \"a crazily inventive, deliriously engaging and almost wordless \\nsilent comedy\", \"afterText\": \" of the sort that Charlie Chaplin and Buster Keaton used to make. Things \\nturn more conventional in the last half hour, when pudgy, machine-dependent \", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The first hour of Wall-E</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">crazily inventive, deliriously engaging and almost wordless silent comedy</span>}</div>\"}, {\"index\": 7, \"class\": \"opinion_statement\", \"text\": \"more conventional\", \"color\": \"#C8E6C9\", \"startPos\": 2207, \"endPos\": 2224, \"beforeText\": \"zily inventive, deliriously engaging and almost wordless \\nsilent comedy of the sort that Charlie Chaplin and Buster Keaton used to make. Things \\nturn \", \"extractionText\": \"more conventional\", \"afterText\": \" in the last half hour, when pudgy, machine-dependent humans \\nmake an appearance, but the glow of that first part will carry you through.  \\nThat and t\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Things</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Negative</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">more conventional</span>}</div>\"}, {\"index\": 8, \"class\": \"audience_impact\", \"text\": \"the glow of that first part will carry you through\", \"color\": \"#D2E3FC\", \"startPos\": 2310, \"endPos\": 2360, \"beforeText\": \"n and Buster Keaton used to make. Things \\nturn more conventional in the last half hour, when pudgy, machine-dependent humans \\nmake an appearance, but \", \"extractionText\": \"the glow of that first part will carry you through\", \"afterText\": \".  \\nThat and the majesty of the filmmaking: Wall-E&#x27;s world, in all its epic decay, looks real. \\nYou can almost taste the dust. And it&#x27;s emotionally re\", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">sustained engagement, satisfaction</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">the glow of that first part</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">the audience</span>}</div>\"}, {\"index\": 9, \"class\": \"opinion_statement\", \"text\": \"looks real\", \"color\": \"#C8E6C9\", \"startPos\": 2443, \"endPos\": 2453, \"beforeText\": \" appearance, but the glow of that first part will carry you through.  \\nThat and the majesty of the filmmaking: Wall-E&#x27;s world, in all its epic decay, \", \"extractionText\": \"looks real\", \"afterText\": \". \\nYou can almost taste the dust. And it&#x27;s emotionally real too \\u2014 enough so that a \\ncautionary tale about the environment, and about big corporations \", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Wall-E&#x27;s world</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">looks real</span>}</div>\"}, {\"index\": 10, \"class\": \"audience_impact\", \"text\": \"You can almost taste the dust\", \"color\": \"#D2E3FC\", \"startPos\": 2456, \"endPos\": 2485, \"beforeText\": \"but the glow of that first part will carry you through.  \\nThat and the majesty of the filmmaking: Wall-E&#x27;s world, in all its epic decay, looks real. \\n\", \"extractionText\": \"You can almost taste the dust\", \"afterText\": \". And it&#x27;s emotionally real too \\u2014 enough so that a \\ncautionary tale about the environment, and about big corporations that don&#x27;t take care of \\nit, and\", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">immersion, sensory vividness</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">The dust</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">the reviewer</span>}</div>\"}, {\"index\": 11, \"class\": \"opinion_statement\", \"text\": \"emotionally real\", \"color\": \"#C8E6C9\", \"startPos\": 2496, \"endPos\": 2512, \"beforeText\": \"ry you through.  \\nThat and the majesty of the filmmaking: Wall-E&#x27;s world, in all its epic decay, looks real. \\nYou can almost taste the dust. And it&#x27;s \", \"extractionText\": \"emotionally real\", \"afterText\": \" too \\u2014 enough so that a \\ncautionary tale about the environment, and about big corporations that don&#x27;t take care of \\nit, and about getting so caught up\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">it</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">emotionally real</span>}</div>\"}, {\"index\": 12, \"class\": \"opinion_statement\", \"text\": \"a cautionary tale about the environment, and about big corporations that don't take care of it, and about getting so caught up in our gadgetry that we forget to look at the stars all take a back seat to romance\", \"color\": \"#C8E6C9\", \"startPos\": 2534, \"endPos\": 2747, \"beforeText\": \" of the filmmaking: Wall-E&#x27;s world, in all its epic decay, looks real. \\nYou can almost taste the dust. And it&#x27;s emotionally real too \\u2014 enough so that \", \"extractionText\": \"a \\ncautionary tale about the environment, and about big corporations that don&#x27;t take care of \\nit, and about getting so caught up in our gadgetry that we forget to look at the stars all \\ntake a back seat to romance\", \"afterText\": \".  \\nSo do some specifically cinematic subtexts. Director Andrew Stanton and his animators \\nhave slipped in nods not just to Hello, Dolly!, but to Star\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">cautionary tale</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Negative</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">take a back seat to romance</span>}</div>\"}, {\"index\": 13, \"class\": \"opinion_statement\", \"text\": \"nods not just to Hello, Dolly!, but to Star Wars and Blade Runner, An Inconvenient Truth and the comedies of Chaplin and Jacques Tati\", \"color\": \"#C8E6C9\", \"startPos\": 2854, \"endPos\": 2988, \"beforeText\": \" the stars all \\ntake a back seat to romance.  \\nSo do some specifically cinematic subtexts. Director Andrew Stanton and his animators \\nhave slipped in \", \"extractionText\": \"nods not just to Hello, Dolly!, but to Star Wars and Blade Runner, An \\nInconvenient Truth and the comedies of Chaplin and Jacques Tati\", \"afterText\": \". More than just a nod \\nto Chaplin, actually: Wall-E, with his workaholic scruffiness and his yearning for \\nsomeone to hold hands with, might as well \", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Director Andrew Stanton and his animators</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">slipped in nods</span>}</div>\"}, {\"index\": 14, \"class\": \"opinion_statement\", \"text\": \"might as well be Chaplin's Little Tramp\", \"color\": \"#C8E6C9\", \"startPos\": 3124, \"endPos\": 3163, \"beforeText\": \"d Jacques Tati. More than just a nod \\nto Chaplin, actually: Wall-E, with his workaholic scruffiness and his yearning for \\nsomeone to hold hands with, \", \"extractionText\": \"might as well be Chaplin&#x27;s Little Tramp\", \"afterText\": \". \\nThere&#x27;s actually a nice parallel between this largely silent film and Chaplin&#x27;s first sound \\nfilm, Modern Times. In that one, the silent clown used\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Wall-E</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">might as well be Chaplin&#x27;s Little Tramp</span>}</div>\"}, {\"index\": 15, \"class\": \"opinion_statement\", \"text\": \"nice parallel\", \"color\": \"#C8E6C9\", \"startPos\": 3185, \"endPos\": 3198, \"beforeText\": \"all-E, with his workaholic scruffiness and his yearning for \\nsomeone to hold hands with, might as well be Chaplin&#x27;s Little Tramp. \\nThere&#x27;s actually a \", \"extractionText\": \"nice parallel\", \"afterText\": \" between this largely silent film and Chaplin&#x27;s first sound \\nfilm, Modern Times. In that one, the silent clown used the soundtrack mostly for music \\na\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">this largely silent film and Chaplin&#x27;s first sound film, Modern Times</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">nice parallel</span>}</div>\"}, {\"index\": 16, \"class\": \"opinion_statement\", \"text\": \"silent clown used the soundtrack mostly for music and effects, not for speech\", \"color\": \"#C8E6C9\", \"startPos\": 3296, \"endPos\": 3374, \"beforeText\": \"in&#x27;s Little Tramp. \\nThere&#x27;s actually a nice parallel between this largely silent film and Chaplin&#x27;s first sound \\nfilm, Modern Times. In that one, the \", \"extractionText\": \"silent clown used the soundtrack mostly for music \\nand effects, not for speech\", \"afterText\": \", just as Pixar does here. Chaplin only let you hear a human \\nvoice a couple of times, and only on some sort of mechanical contraption \\u2014 say a closed-\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">the silent clown</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">used the soundtrack mostly for music and effects, not for speech</span>}</div>\"}, {\"index\": 17, \"class\": \"opinion_statement\", \"text\": \"look how much more expressive our silent world is\", \"color\": \"#C8E6C9\", \"startPos\": 3674, \"endPos\": 3724, \"beforeText\": \"\\ncircuit TV screen \\u2014 to emphasize its artificiality. It was his way of saying to the sound \\nworld, &quot;OK, everybody&#x27;s doing this talking thing now, but \", \"extractionText\": \"look how much more \\nexpressive our silent world is\", \"afterText\": \".&quot;  \\nFor the first time in a Pixar movie, Wall-E&#x27;s filmmakers give a nod to the world of actual \\nactors and cameras \\u2014 and make them artificial in the \", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">our silent world</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">more expressive</span>}</div>\"}, {\"index\": 18, \"class\": \"opinion_statement\", \"text\": \"look flat and washed-out\", \"color\": \"#C8E6C9\", \"startPos\": 3943, \"endPos\": 3967, \"beforeText\": \"nod to the world of actual \\nactors and cameras \\u2014 and make them artificial in the same way: by only letting you see \\nthem on video screens, where they \", \"extractionText\": \"look flat and washed-out\", \"afterText\": \" compared to the digital \\nworld around them. \\nBut there&#x27;s one difference. Chaplin knew he had lost the battle: Silence was finished; \\nsound had won. I\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">actual actors and cameras</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Negative</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">flat and washed-out</span>}</div>\"}, {\"index\": 19, \"class\": \"opinion_statement\", \"text\": \"digital is what's taking over\", \"color\": \"#C8E6C9\", \"startPos\": 4138, \"endPos\": 4167, \"beforeText\": \"tal \\nworld around them. \\nBut there&#x27;s one difference. Chaplin knew he had lost the battle: Silence was finished; \\nsound had won. In today&#x27;s Hollywood, \", \"extractionText\": \"digital is what&#x27;s taking over\", \"afterText\": \" \\u2014 in special effects, \\nin green-screen work, in animation. And Pixar&#x27;s animators, bless them, are at the\\n&quot;&quot;&quot;\\n\\n**Page 3**\\n&quot;&quot;&quot;\\nforefront, insisting tha\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">digital</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">taking over</span>}</div>\"}, {\"index\": 20, \"class\": \"opinion_statement\", \"text\": \"imagery created on computers doesn't have to be soulless\", \"color\": \"#C8E6C9\", \"startPos\": 4319, \"endPos\": 4375, \"beforeText\": \" in special effects, \\nin green-screen work, in animation. And Pixar&#x27;s animators, bless them, are at the\\n&quot;&quot;&quot;\\n\\n**Page 3**\\n&quot;&quot;&quot;\\nforefront, insisting that \", \"extractionText\": \"imagery created on computers doesn&#x27;t have to be soulless\", \"afterText\": \". Wall-\\nE&#x27;s images are filled with emotion, just as silent film&#x27;s images were \\u2014 even though its \\ncharacters look like they&#x27;re made of metal and plasti\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">imagery created on computers</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">doesn&#x27;t have to be soulless</span>}</div>\"}, {\"index\": 21, \"class\": \"opinion_statement\", \"text\": \"Wall-E's images are filled with emotion\", \"color\": \"#C8E6C9\", \"startPos\": 4377, \"endPos\": 4417, \"beforeText\": \"And Pixar&#x27;s animators, bless them, are at the\\n&quot;&quot;&quot;\\n\\n**Page 3**\\n&quot;&quot;&quot;\\nforefront, insisting that imagery created on computers doesn&#x27;t have to be soulless. \", \"extractionText\": \"Wall-\\nE&#x27;s images are filled with emotion\", \"afterText\": \", just as silent film&#x27;s images were \\u2014 even though its \\ncharacters look like they&#x27;re made of metal and plastic, and can&#x27;t say a word.  \\nWall-E is being\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Wall-E&#x27;s images</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">filled with emotion</span>}</div>\"}, {\"index\": 22, \"class\": \"opinion_statement\", \"text\": \"gratified by their look forward 700 years to a silent planet\", \"color\": \"#C8E6C9\", \"startPos\": 4640, \"endPos\": 4754, \"beforeText\": \"ke they&#x27;re made of metal and plastic, and can&#x27;t say a word.  \\nWall-E is being sold as a futuristic fantasy, of course. But I have to say I&#x27;m just as \\n\", \"extractionText\": \"gratified by their look back 70 years to silent movies as I am by their look forward 700 \\nyears to a silent planet\", \"afterText\": \".\\n&quot;&quot;&quot;\\n\\n\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">their look forward 700 years to a silent planet</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">gratified</span>}</div>\"}, {\"index\": 23, \"class\": \"opinion_statement\", \"text\": \"gratified by their look back 70 years to silent movies\", \"color\": \"#C8E6C9\", \"startPos\": 4640, \"endPos\": 4694, \"beforeText\": \"ke they&#x27;re made of metal and plastic, and can&#x27;t say a word.  \\nWall-E is being sold as a futuristic fantasy, of course. But I have to say I&#x27;m just as \\n\", \"extractionText\": \"gratified by their look back 70 years to silent movies\", \"afterText\": \" as I am by their look forward 700 \\nyears to a silent planet.\\n&quot;&quot;&quot;\\n\\n\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">their look back 70 years to silent movies</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">gratified</span>}</div>\"}];\n",
       "        let currentIndex = 0;\n",
       "        let isPlaying = false;\n",
       "        let animationInterval = null;\n",
       "        let animationSpeed = 1.0;\n",
       "\n",
       "        function updateDisplay() {\n",
       "          const extraction = extractions[currentIndex];\n",
       "          if (!extraction) return;\n",
       "\n",
       "          document.getElementById('attributesContainer').innerHTML = extraction.attributesHtml;\n",
       "          document.getElementById('entityInfo').textContent = (currentIndex + 1) + '/' + extractions.length;\n",
       "          document.getElementById('posInfo').textContent = '[' + extraction.startPos + '-' + extraction.endPos + ']';\n",
       "          document.getElementById('progressSlider').value = currentIndex;\n",
       "\n",
       "          const playBtn = document.querySelector('.lx-control-btn');\n",
       "          if (playBtn) playBtn.textContent = isPlaying ? ' Pause' : ' Play';\n",
       "\n",
       "          const prevHighlight = document.querySelector('.lx-text-window .lx-current-highlight');\n",
       "          if (prevHighlight) prevHighlight.classList.remove('lx-current-highlight');\n",
       "          const currentSpan = document.querySelector('.lx-text-window span[data-idx=\"' + currentIndex + '\"]');\n",
       "          if (currentSpan) {\n",
       "            currentSpan.classList.add('lx-current-highlight');\n",
       "            currentSpan.scrollIntoView({block: 'center', behavior: 'smooth'});\n",
       "          }\n",
       "        }\n",
       "\n",
       "        function nextExtraction() {\n",
       "          currentIndex = (currentIndex + 1) % extractions.length;\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function prevExtraction() {\n",
       "          currentIndex = (currentIndex - 1 + extractions.length) % extractions.length;\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function jumpToExtraction(index) {\n",
       "          currentIndex = parseInt(index);\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function playPause() {\n",
       "          if (isPlaying) {\n",
       "            clearInterval(animationInterval);\n",
       "            isPlaying = false;\n",
       "          } else {\n",
       "            animationInterval = setInterval(nextExtraction, animationSpeed * 1000);\n",
       "            isPlaying = true;\n",
       "          }\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        window.playPause = playPause;\n",
       "        window.nextExtraction = nextExtraction;\n",
       "        window.prevExtraction = prevExtraction;\n",
       "        window.jumpToExtraction = jumpToExtraction;\n",
       "\n",
       "        updateDisplay();\n",
       "      })();\n",
       "    </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **Disscusions**\n",
    "\n",
    "### **Results**\n",
    "\n",
    "Langextract successfully extracted multiple evaluative and emotionally expressive phrases from the Wall-E review, with grounding accurately highlighting each span in the original text. Expressions such as looks real and You can almost taste the dust were correctly categorized as critical opinions or audience impact, demonstrating that the model can reliably identify evaluative tone, viewing experience, and visual descriptions. Overall extraction quality is consistent and stable.\n",
    "\n",
    "### **Limitations**\n",
    "\n",
    "Some multi-adjective opinion phrases were only partially extracted, resulting in incomplete representation of the reviewers full description. Additionally, several emotionally charged or atmospheric expressions were not classified as audience impact, causing recall to drop. The model also displayed a bias toward positive sentiment, labeling terms like loneliness or emptiness as positive, indicating insufficient sensitivity in sentiment classification.\n",
    "\n",
    "### **Future works**\n",
    "\n",
    "Recall can be improved by increasing extraction_passes (e.g., to 23) and expanding max_char_buffer to provide more contextual continuity across batches. Adding more diverse few-shot examplesespecially those containing mixed emotions, negative imagery, and atmospheric descriptionscan reduce sentiment bias and help the model better interpret the tone of film criticism. Clearer prompt rules can also prevent partial extraction of long descriptive phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_8_'></a>[**2.4 Generating LLM Embeddings:**](#toc0_)\n",
    "\n",
    "LLM embeddings are dense numerical vectors that represent the semantic meaning of text. Generated by Large Language Models, they map words, phrases, or documents into a high-dimensional space where similar concepts are positioned closely together.\n",
    "\n",
    "Their key advantages are:\n",
    "\n",
    "*   **Contextual Understanding:** Unlike older methods, LLM embeddings are contextual. The vector for a word like **\"bank\"** will be different depending on whether it's used in the context of a \"river bank\" or a \"money bank,\" providing a more nuanced representation of language.\n",
    "\n",
    "*   **Versatility from Pre-training:** They are pre-trained on vast amounts of text data. This allows them to generalize effectively across various tasks, such as classification, clustering, and similarity detection. They do not require extensive retraining.\n",
    "\n",
    "<span style=\"color:green\">For the exercise in this section there is no need to re-run the cells, you can use the data that has been saved previously to the corresponding directory.</span>\n",
    "\n",
    "**Now let's generate some embeddings with Gemini for a sample of our dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import pandas as pd\n",
    "import time\n",
    "from google.api_core import exceptions\n",
    "\n",
    "# Let's define our function to get the embeddings with Gemini\n",
    "def get_gemini_embedding(text: str, model: str=\"gemini-embedding-001\"):\n",
    "    try:\n",
    "        result = client.models.embed_content(model=model, contents=[text])\n",
    "        # 100 requests per minute limit -> 60s / 100 = 0.6s per request\n",
    "        # buffer time to avoid rate limits\n",
    "        time.sleep(0.6)\n",
    "        return result.embeddings\n",
    "    except exceptions.ResourceExhausted as e:\n",
    "        print(f\"Rate limit exceeded. Waiting to retry... Error: {e}\")\n",
    "        time.sleep(5) # Wait for 5 seconds before the next attempt\n",
    "        return get_gemini_embedding(text, model) # Retry the request\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 160 rows from the training set...\n",
      "Sampling 40 rows from the test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lx/b868nzys5b9139jlvjxp7r800000gn/T/ipykernel_19178/2000596105.py:14: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df.groupby(stratify_col, group_keys=False).apply(\n",
      "/var/folders/lx/b868nzys5b9139jlvjxp7r800000gn/T/ipykernel_19178/2000596105.py:14: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df.groupby(stratify_col, group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "total_extractions = 200\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.2\n",
    "\n",
    "n_train_to_sample = int(total_extractions * train_ratio)\n",
    "n_test_to_sample = int(total_extractions * test_ratio)\n",
    "# We use the text column\n",
    "column_name = 'text'\n",
    "\n",
    "# This function is to get a stratified sample from our data, meaning to have the same distribution of labels as in the full dataset\n",
    "def stratified_sample(df: pd.DataFrame, n_samples: int, stratify_col: str = 'emotion') -> pd.DataFrame:\n",
    "    if n_samples >= len(df):\n",
    "        return df.copy() # Return a copy if requested sample is larger or equal\n",
    "    sampled_df = df.groupby(stratify_col, group_keys=False).apply(\n",
    "        lambda x: x.sample(n=max(0, int(round(len(x) / len(df) * n_samples))))\n",
    "    )\n",
    "\n",
    "    # Adjust for rounding errors to get the exact number of samples\n",
    "    current_samples = len(sampled_df)\n",
    "    if current_samples < n_samples:\n",
    "        remaining_indices = df.index.difference(sampled_df.index)\n",
    "        additional_samples = df.loc[remaining_indices].sample(n=n_samples - current_samples, random_state=42)\n",
    "        sampled_df = pd.concat([sampled_df, additional_samples])\n",
    "    elif current_samples > n_samples:\n",
    "        sampled_df = sampled_df.sample(n=n_samples, random_state=42)\n",
    "    return sampled_df\n",
    "\n",
    "print(f\"Sampling {n_train_to_sample} rows from the training set...\")\n",
    "train_df_new = stratified_sample(train_df, n_train_to_sample, 'emotion')\n",
    "\n",
    "print(f\"Sampling {n_test_to_sample} rows from the test set...\")\n",
    "test_df_new = stratified_sample(test_df, n_test_to_sample, 'emotion')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "fear       51\n",
       "anger      38\n",
       "joy        36\n",
       "sadness    35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_new[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "fear       13\n",
       "anger      10\n",
       "joy         9\n",
       "sadness     8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_new[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating embeddings for the new training set...\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to the specified column and store the result in a new column 'embeddings'\n",
    "print(\"\\nGenerating embeddings for the new training set...\")\n",
    "train_df_new['embeddings'] = train_df_new[column_name].apply(get_gemini_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating embeddings for the new test set...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGenerating embeddings for the new test set...\")\n",
    "test_df_new['embeddings'] = test_df_new[column_name].apply(get_gemini_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "\n",
    "# After getting the embeddings we need to convert the Gemini type ContentDict of the embeddings into a simple list with them\n",
    "train_df_new['embeddings_values'] = train_df_new[\"embeddings\"].apply(lambda row: list(types.ContentDict(row[0]).values())[0])\n",
    "test_df_new['embeddings_values'] = test_df_new[\"embeddings\"].apply(lambda row: list(types.ContentDict(row[0]).values())[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>embeddings_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>10734</td>\n",
       "      <td>Anger is cheap and politeness is expensive. Do...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.333</td>\n",
       "      <td>[values=[0.0016006274, -0.0016848164, 0.016976...</td>\n",
       "      <td>[0.0016006274, -0.0016848164, 0.016976196, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>10229</td>\n",
       "      <td>Absolutely raging at the changes to CAS, what ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.604</td>\n",
       "      <td>[values=[0.005950099, -0.010281919, -0.0187456...</td>\n",
       "      <td>[0.005950099, -0.010281919, -0.018745607, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>10523</td>\n",
       "      <td>The sun literally burning my skin</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.438</td>\n",
       "      <td>[values=[0.01564453, 0.008292213, 0.0072059603...</td>\n",
       "      <td>[0.01564453, 0.008292213, 0.0072059603, -0.048...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>10195</td>\n",
       "      <td>@RealBD_ @ReyesAverie 47 unarmed blacks killed...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.625</td>\n",
       "      <td>[values=[-0.013746275, 0.017981697, 0.01185801...</td>\n",
       "      <td>[-0.013746275, 0.017981697, 0.011858018, -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>10168</td>\n",
       "      <td>@bt_uk why does tracking show my equipment del...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.646</td>\n",
       "      <td>[values=[0.010148099, 0.003751405, -0.01473883...</td>\n",
       "      <td>[0.010148099, 0.003751405, -0.014738834, -0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3404</th>\n",
       "      <td>40577</td>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.354</td>\n",
       "      <td>[values=[-0.013485389, -0.015186936, 0.0217591...</td>\n",
       "      <td>[-0.013485389, -0.015186936, 0.021759143, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3563</th>\n",
       "      <td>40736</td>\n",
       "      <td>Unmatched Party Specialist /co @T3RevNeverEnd ...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.208</td>\n",
       "      <td>[values=[-0.019992732, 0.016387975, 0.00243796...</td>\n",
       "      <td>[-0.019992732, 0.016387975, 0.0024379664, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3033</th>\n",
       "      <td>40206</td>\n",
       "      <td>There's many things I don't care about, and ma...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.625</td>\n",
       "      <td>[values=[-0.0010715432, -0.006593417, -0.00167...</td>\n",
       "      <td>[-0.0010715432, -0.006593417, -0.0016708012, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2905</th>\n",
       "      <td>40078</td>\n",
       "      <td>If anybody needs me I'll be drowning my blues ...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.750</td>\n",
       "      <td>[values=[-0.012868422, -0.020207386, -0.024149...</td>\n",
       "      <td>[-0.012868422, -0.020207386, -0.02414981, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>40431</td>\n",
       "      <td>You don't know how to love me when you're sobe...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.458</td>\n",
       "      <td>[values=[-0.028080843, 0.0075661163, -0.019758...</td>\n",
       "      <td>[-0.028080843, 0.0075661163, -0.019758116, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  emotion  \\\n",
       "734   10734  Anger is cheap and politeness is expensive. Do...    anger   \n",
       "229   10229  Absolutely raging at the changes to CAS, what ...    anger   \n",
       "523   10523                  The sun literally burning my skin    anger   \n",
       "195   10195  @RealBD_ @ReyesAverie 47 unarmed blacks killed...    anger   \n",
       "168   10168  @bt_uk why does tracking show my equipment del...    anger   \n",
       "...     ...                                                ...      ...   \n",
       "3404  40577  Regret for the things we did can be tempered b...  sadness   \n",
       "3563  40736  Unmatched Party Specialist /co @T3RevNeverEnd ...  sadness   \n",
       "3033  40206  There's many things I don't care about, and ma...  sadness   \n",
       "2905  40078  If anybody needs me I'll be drowning my blues ...  sadness   \n",
       "3258  40431  You don't know how to love me when you're sobe...  sadness   \n",
       "\n",
       "      intensity                                         embeddings  \\\n",
       "734       0.333  [values=[0.0016006274, -0.0016848164, 0.016976...   \n",
       "229       0.604  [values=[0.005950099, -0.010281919, -0.0187456...   \n",
       "523       0.438  [values=[0.01564453, 0.008292213, 0.0072059603...   \n",
       "195       0.625  [values=[-0.013746275, 0.017981697, 0.01185801...   \n",
       "168       0.646  [values=[0.010148099, 0.003751405, -0.01473883...   \n",
       "...         ...                                                ...   \n",
       "3404      0.354  [values=[-0.013485389, -0.015186936, 0.0217591...   \n",
       "3563      0.208  [values=[-0.019992732, 0.016387975, 0.00243796...   \n",
       "3033      0.625  [values=[-0.0010715432, -0.006593417, -0.00167...   \n",
       "2905      0.750  [values=[-0.012868422, -0.020207386, -0.024149...   \n",
       "3258      0.458  [values=[-0.028080843, 0.0075661163, -0.019758...   \n",
       "\n",
       "                                      embeddings_values  \n",
       "734   [0.0016006274, -0.0016848164, 0.016976196, -0....  \n",
       "229   [0.005950099, -0.010281919, -0.018745607, -0.0...  \n",
       "523   [0.01564453, 0.008292213, 0.0072059603, -0.048...  \n",
       "195   [-0.013746275, 0.017981697, 0.011858018, -0.04...  \n",
       "168   [0.010148099, 0.003751405, -0.014738834, -0.06...  \n",
       "...                                                 ...  \n",
       "3404  [-0.013485389, -0.015186936, 0.021759143, -0.0...  \n",
       "3563  [-0.019992732, 0.016387975, 0.0024379664, -0.0...  \n",
       "3033  [-0.0010715432, -0.006593417, -0.0016708012, -...  \n",
       "2905  [-0.012868422, -0.020207386, -0.02414981, -0.0...  \n",
       "3258  [-0.028080843, 0.0075661163, -0.019758116, -0....  \n",
       "\n",
       "[160 rows x 6 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_new #We can see the new column with the embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>embeddings_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>30872</td>\n",
       "      <td>@hesham786 that's the spirit</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.354</td>\n",
       "      <td>[values=[-0.0031169527, -0.001907086, -0.01123...</td>\n",
       "      <td>[-0.0031169527, -0.001907086, -0.011237554, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>21203</td>\n",
       "      <td>Whatt a trailerrrr !!! @karanjohar @AnushkaSha...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.354</td>\n",
       "      <td>[values=[-0.004179722, -0.0064758337, 0.007653...</td>\n",
       "      <td>[-0.004179722, -0.0064758337, 0.0076531176, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10870</td>\n",
       "      <td>Sorry guys I have absolutely no idea what time...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.417</td>\n",
       "      <td>[values=[-0.014735025, 0.01645179, -0.02368603...</td>\n",
       "      <td>[-0.014735025, 0.01645179, -0.023686036, -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>30824</td>\n",
       "      <td>Nawaz Sharif is getting more funnier than @kap...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.700</td>\n",
       "      <td>[values=[-0.029558752, 0.020164862, 0.02368624...</td>\n",
       "      <td>[-0.029558752, 0.020164862, 0.023686247, -0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10872</td>\n",
       "      <td>Is it me, or is Ding wearing the look of a man...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.557</td>\n",
       "      <td>[values=[-0.015632482, -0.0027931707, -0.01666...</td>\n",
       "      <td>[-0.015632482, -0.0027931707, -0.016667966, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>40789</td>\n",
       "      <td>Stars, when you shine,\\nYou know how I feel.\\n...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.292</td>\n",
       "      <td>[values=[0.011783604, 0.007787306, 0.008415056...</td>\n",
       "      <td>[0.011783604, 0.007787306, 0.008415056, -0.080...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>21221</td>\n",
       "      <td>Thanks for ripping me off again #Luthansa 400...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.521</td>\n",
       "      <td>[values=[-0.0027418581, -0.026277944, -0.01922...</td>\n",
       "      <td>[-0.0027418581, -0.026277944, -0.019228248, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>40844</td>\n",
       "      <td>yesterday i finished watching penny dreadful a...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.312</td>\n",
       "      <td>[values=[-0.019259144, -0.021168273, 0.0303008...</td>\n",
       "      <td>[-0.019259144, -0.021168273, 0.030300863, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>30868</td>\n",
       "      <td>@bruins_514 @gorddownie @thehipdotcom It would...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.519</td>\n",
       "      <td>[values=[-0.0036713977, -0.010136703, -0.01086...</td>\n",
       "      <td>[-0.0036713977, -0.010136703, -0.010862582, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>10905</td>\n",
       "      <td>Ok scrubbed hands 5 times before trying to put...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.604</td>\n",
       "      <td>[values=[-0.010922581, -0.010670915, -0.001972...</td>\n",
       "      <td>[-0.010922581, -0.010670915, -0.0019729831, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>30835</td>\n",
       "      <td>@Gronnhair @buryprofs @DittoBistro it was inde...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.646</td>\n",
       "      <td>[values=[-0.011633852, -0.009310706, -0.011479...</td>\n",
       "      <td>[-0.011633852, -0.009310706, -0.011479081, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>21230</td>\n",
       "      <td>It really is amazing the money they give to so...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.246</td>\n",
       "      <td>[values=[-0.04023646, -0.0033757573, -0.015112...</td>\n",
       "      <td>[-0.04023646, -0.0033757573, -0.015112562, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>21238</td>\n",
       "      <td>#twitter #users Tweeting on twitter is like pl...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.521</td>\n",
       "      <td>[values=[-0.024715586, -0.01256246, -0.0125413...</td>\n",
       "      <td>[-0.024715586, -0.01256246, -0.0125413975, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10873</td>\n",
       "      <td>Is it me, or is Ding wearing the look of a man...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[values=[-0.009913362, -0.003055955, -0.015127...</td>\n",
       "      <td>[-0.009913362, -0.003055955, -0.015127845, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>21253</td>\n",
       "      <td>Staff on @ryainair FR1005. Asked for info and ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.271</td>\n",
       "      <td>[values=[-0.024835743, 0.00060396525, 0.009073...</td>\n",
       "      <td>[-0.024835743, 0.00060396525, 0.009073344, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>40813</td>\n",
       "      <td>This shit hurting my heart  that's how seriou...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.875</td>\n",
       "      <td>[values=[-0.0069135656, -0.0037595944, -0.0228...</td>\n",
       "      <td>[-0.0069135656, -0.0037595944, -0.022816306, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>21176</td>\n",
       "      <td>@soozclifford Sure have... Sydney are too toug...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.340</td>\n",
       "      <td>[values=[-0.02130687, -0.016090302, 0.01576546...</td>\n",
       "      <td>[-0.02130687, -0.016090302, 0.015765466, -0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>40833</td>\n",
       "      <td>@Barcabhoy1 Of course not. Didn't sink his stu...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.396</td>\n",
       "      <td>[values=[0.011736909, 0.018727152, -0.00540291...</td>\n",
       "      <td>[0.011736909, 0.018727152, -0.005402915, -0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>40802</td>\n",
       "      <td>[ @HedgehogDylan ] *she would frown a bit, fol...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.562</td>\n",
       "      <td>[values=[-0.015942886, 0.0062166224, -0.009731...</td>\n",
       "      <td>[-0.015942886, 0.0062166224, -0.009731274, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10858</td>\n",
       "      <td>@ArcticFantasy I would have almost took offens...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.458</td>\n",
       "      <td>[values=[2.788781e-05, -0.009843583, -0.016139...</td>\n",
       "      <td>[2.788781e-05, -0.009843583, -0.016139457, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>30864</td>\n",
       "      <td>@diehimbeertonis She developed her 'forced smi...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.208</td>\n",
       "      <td>[values=[0.0023312648, 0.019491544, -0.0150602...</td>\n",
       "      <td>[0.0023312648, 0.019491544, -0.015060243, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>10901</td>\n",
       "      <td>You're so thirsty for the chance to disagree w...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[values=[-0.0054591983, 0.010110117, -0.017452...</td>\n",
       "      <td>[-0.0054591983, 0.010110117, -0.017452167, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>21241</td>\n",
       "      <td>Tweeting from the sporadic wifi on the tube</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.292</td>\n",
       "      <td>[values=[-0.0066989562, 0.0057921065, -0.01125...</td>\n",
       "      <td>[-0.0066989562, 0.0057921065, -0.011250335, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>10910</td>\n",
       "      <td>Having a baby born too soon is #lifechanging 6...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.375</td>\n",
       "      <td>[values=[-0.025528934, -0.0049635707, -0.01072...</td>\n",
       "      <td>[-0.025528934, -0.0049635707, -0.010728385, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>30875</td>\n",
       "      <td>@harrietemmett great minds think alike.</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.479</td>\n",
       "      <td>[values=[0.0049384963, -0.0004102937, -0.02083...</td>\n",
       "      <td>[0.0049384963, -0.0004102937, -0.020839296, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>21163</td>\n",
       "      <td>We can easily #forgive a #child who is #afrai...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.375</td>\n",
       "      <td>[values=[-0.020354087, -0.010737755, -0.006649...</td>\n",
       "      <td>[-0.020354087, -0.010737755, -0.0066496436, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>10894</td>\n",
       "      <td>i live and die for mchanzo honeymoon crashing ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.479</td>\n",
       "      <td>[values=[-0.0010682619, 0.018157829, -0.005871...</td>\n",
       "      <td>[-0.0010682619, 0.018157829, -0.005871065, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>30845</td>\n",
       "      <td>A cheerful heart is good medicine, but a broke...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.292</td>\n",
       "      <td>[values=[-0.010979394, 0.0126972, -0.029265268...</td>\n",
       "      <td>[-0.010979394, 0.0126972, -0.029265268, -0.051...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>40856</td>\n",
       "      <td>I'd rather laugh with the rarest genius, in be...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.688</td>\n",
       "      <td>[values=[-0.0016530727, 0.0044874516, -0.00701...</td>\n",
       "      <td>[-0.0016530727, 0.0044874516, -0.0070126606, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>10920</td>\n",
       "      <td>Why to have vanity sizes?Now sizes S,XS(evenXX...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.518</td>\n",
       "      <td>[values=[-0.0028998374, -0.02078183, 0.0164787...</td>\n",
       "      <td>[-0.0028998374, -0.02078183, 0.016478756, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>40807</td>\n",
       "      <td>@pmo100 @5liveSport .....I heard talk somethin...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.458</td>\n",
       "      <td>[values=[-0.0058687045, 0.016114332, -0.014483...</td>\n",
       "      <td>[-0.0058687045, 0.016114332, -0.01448304, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>30879</td>\n",
       "      <td>@Bridget_Jones was joyous. Worried I would be ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.680</td>\n",
       "      <td>[values=[-0.019118113, -0.017402798, -0.030459...</td>\n",
       "      <td>[-0.019118113, -0.017402798, -0.030459225, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>40834</td>\n",
       "      <td>Soooo badly want to dye my hair dark but have ...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[values=[-0.006563008, -0.01716611, 0.00851160...</td>\n",
       "      <td>[-0.006563008, -0.01716611, 0.008511609, -0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>21229</td>\n",
       "      <td>It really is amazing the money they give to so...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.300</td>\n",
       "      <td>[values=[-0.043868568, 4.1717867e-05, -0.01727...</td>\n",
       "      <td>[-0.043868568, 4.1717867e-05, -0.017276116, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>21205</td>\n",
       "      <td>@stephenfhayes Mustard gas = hostile work envi...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.708</td>\n",
       "      <td>[values=[0.0034173268, 0.014688194, 0.00708017...</td>\n",
       "      <td>[0.0034173268, 0.014688194, 0.0070801787, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>21166</td>\n",
       "      <td>Having a terrific Tuesday? Crush it today with...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.250</td>\n",
       "      <td>[values=[-0.027871776, 0.015271844, 0.01538157...</td>\n",
       "      <td>[-0.027871776, 0.015271844, 0.0153815765, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>21156</td>\n",
       "      <td>There goes the butterflies in my stomach. #ner...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.812</td>\n",
       "      <td>[values=[0.0047239466, -0.0126334075, -0.00560...</td>\n",
       "      <td>[0.0047239466, -0.0126334075, -0.0056003057, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10884</td>\n",
       "      <td>@RevTrevK @Wolfman93011 @Daraidernation @EROCK...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.586</td>\n",
       "      <td>[values=[-0.013165958, -0.038608503, -0.008693...</td>\n",
       "      <td>[-0.013165958, -0.038608503, -0.008693953, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>21243</td>\n",
       "      <td>If i start growing out my mustache now, I can ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.250</td>\n",
       "      <td>[values=[-0.013611719, -0.008574327, 0.0092285...</td>\n",
       "      <td>[-0.013611719, -0.008574327, 0.009228598, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>30857</td>\n",
       "      <td>If you don't respond to an email within 7 fays...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.180</td>\n",
       "      <td>[values=[-0.009656984, 0.028854532, 0.00265956...</td>\n",
       "      <td>[-0.009656984, 0.028854532, 0.0026595625, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  emotion  \\\n",
       "243  30872                      @hesham786 that's the spirit       joy   \n",
       "140  21203  Whatt a trailerrrr !!! @karanjohar @AnushkaSha...     fear   \n",
       "13   10870  Sorry guys I have absolutely no idea what time...    anger   \n",
       "195  30824  Nawaz Sharif is getting more funnier than @kap...      joy   \n",
       "15   10872  Is it me, or is Ding wearing the look of a man...    anger   \n",
       "276  40789  Stars, when you shine,\\nYou know how I feel.\\n...  sadness   \n",
       "158  21221  Thanks for ripping me off again #Luthansa 400...     fear   \n",
       "331  40844  yesterday i finished watching penny dreadful a...  sadness   \n",
       "239  30868  @bruins_514 @gorddownie @thehipdotcom It would...      joy   \n",
       "48   10905  Ok scrubbed hands 5 times before trying to put...    anger   \n",
       "206  30835  @Gronnhair @buryprofs @DittoBistro it was inde...      joy   \n",
       "167  21230  It really is amazing the money they give to so...     fear   \n",
       "175  21238  #twitter #users Tweeting on twitter is like pl...     fear   \n",
       "16   10873  Is it me, or is Ding wearing the look of a man...    anger   \n",
       "190  21253  Staff on @ryainair FR1005. Asked for info and ...     fear   \n",
       "300  40813  This shit hurting my heart  that's how seriou...  sadness   \n",
       "113  21176  @soozclifford Sure have... Sydney are too toug...     fear   \n",
       "320  40833  @Barcabhoy1 Of course not. Didn't sink his stu...  sadness   \n",
       "289  40802  [ @HedgehogDylan ] *she would frown a bit, fol...  sadness   \n",
       "1    10858  @ArcticFantasy I would have almost took offens...    anger   \n",
       "235  30864  @diehimbeertonis She developed her 'forced smi...      joy   \n",
       "44   10901  You're so thirsty for the chance to disagree w...    anger   \n",
       "178  21241       Tweeting from the sporadic wifi on the tube      fear   \n",
       "53   10910  Having a baby born too soon is #lifechanging 6...    anger   \n",
       "246  30875           @harrietemmett great minds think alike.       joy   \n",
       "100  21163  We can easily #forgive a #child who is #afrai...     fear   \n",
       "37   10894  i live and die for mchanzo honeymoon crashing ...    anger   \n",
       "216  30845  A cheerful heart is good medicine, but a broke...      joy   \n",
       "343  40856  I'd rather laugh with the rarest genius, in be...  sadness   \n",
       "63   10920  Why to have vanity sizes?Now sizes S,XS(evenXX...    anger   \n",
       "294  40807  @pmo100 @5liveSport .....I heard talk somethin...  sadness   \n",
       "250  30879  @Bridget_Jones was joyous. Worried I would be ...      joy   \n",
       "321  40834  Soooo badly want to dye my hair dark but have ...  sadness   \n",
       "166  21229  It really is amazing the money they give to so...     fear   \n",
       "142  21205  @stephenfhayes Mustard gas = hostile work envi...     fear   \n",
       "103  21166  Having a terrific Tuesday? Crush it today with...     fear   \n",
       "93   21156  There goes the butterflies in my stomach. #ner...     fear   \n",
       "27   10884  @RevTrevK @Wolfman93011 @Daraidernation @EROCK...    anger   \n",
       "180  21243  If i start growing out my mustache now, I can ...     fear   \n",
       "228  30857  If you don't respond to an email within 7 fays...      joy   \n",
       "\n",
       "     intensity                                         embeddings  \\\n",
       "243      0.354  [values=[-0.0031169527, -0.001907086, -0.01123...   \n",
       "140      0.354  [values=[-0.004179722, -0.0064758337, 0.007653...   \n",
       "13       0.417  [values=[-0.014735025, 0.01645179, -0.02368603...   \n",
       "195      0.700  [values=[-0.029558752, 0.020164862, 0.02368624...   \n",
       "15       0.557  [values=[-0.015632482, -0.0027931707, -0.01666...   \n",
       "276      0.292  [values=[0.011783604, 0.007787306, 0.008415056...   \n",
       "158      0.521  [values=[-0.0027418581, -0.026277944, -0.01922...   \n",
       "331      0.312  [values=[-0.019259144, -0.021168273, 0.0303008...   \n",
       "239      0.519  [values=[-0.0036713977, -0.010136703, -0.01086...   \n",
       "48       0.604  [values=[-0.010922581, -0.010670915, -0.001972...   \n",
       "206      0.646  [values=[-0.011633852, -0.009310706, -0.011479...   \n",
       "167      0.246  [values=[-0.04023646, -0.0033757573, -0.015112...   \n",
       "175      0.521  [values=[-0.024715586, -0.01256246, -0.0125413...   \n",
       "16       0.500  [values=[-0.009913362, -0.003055955, -0.015127...   \n",
       "190      0.271  [values=[-0.024835743, 0.00060396525, 0.009073...   \n",
       "300      0.875  [values=[-0.0069135656, -0.0037595944, -0.0228...   \n",
       "113      0.340  [values=[-0.02130687, -0.016090302, 0.01576546...   \n",
       "320      0.396  [values=[0.011736909, 0.018727152, -0.00540291...   \n",
       "289      0.562  [values=[-0.015942886, 0.0062166224, -0.009731...   \n",
       "1        0.458  [values=[2.788781e-05, -0.009843583, -0.016139...   \n",
       "235      0.208  [values=[0.0023312648, 0.019491544, -0.0150602...   \n",
       "44       0.500  [values=[-0.0054591983, 0.010110117, -0.017452...   \n",
       "178      0.292  [values=[-0.0066989562, 0.0057921065, -0.01125...   \n",
       "53       0.375  [values=[-0.025528934, -0.0049635707, -0.01072...   \n",
       "246      0.479  [values=[0.0049384963, -0.0004102937, -0.02083...   \n",
       "100      0.375  [values=[-0.020354087, -0.010737755, -0.006649...   \n",
       "37       0.479  [values=[-0.0010682619, 0.018157829, -0.005871...   \n",
       "216      0.292  [values=[-0.010979394, 0.0126972, -0.029265268...   \n",
       "343      0.688  [values=[-0.0016530727, 0.0044874516, -0.00701...   \n",
       "63       0.518  [values=[-0.0028998374, -0.02078183, 0.0164787...   \n",
       "294      0.458  [values=[-0.0058687045, 0.016114332, -0.014483...   \n",
       "250      0.680  [values=[-0.019118113, -0.017402798, -0.030459...   \n",
       "321      0.500  [values=[-0.006563008, -0.01716611, 0.00851160...   \n",
       "166      0.300  [values=[-0.043868568, 4.1717867e-05, -0.01727...   \n",
       "142      0.708  [values=[0.0034173268, 0.014688194, 0.00708017...   \n",
       "103      0.250  [values=[-0.027871776, 0.015271844, 0.01538157...   \n",
       "93       0.812  [values=[0.0047239466, -0.0126334075, -0.00560...   \n",
       "27       0.586  [values=[-0.013165958, -0.038608503, -0.008693...   \n",
       "180      0.250  [values=[-0.013611719, -0.008574327, 0.0092285...   \n",
       "228      0.180  [values=[-0.009656984, 0.028854532, 0.00265956...   \n",
       "\n",
       "                                     embeddings_values  \n",
       "243  [-0.0031169527, -0.001907086, -0.011237554, -0...  \n",
       "140  [-0.004179722, -0.0064758337, 0.0076531176, -0...  \n",
       "13   [-0.014735025, 0.01645179, -0.023686036, -0.04...  \n",
       "195  [-0.029558752, 0.020164862, 0.023686247, -0.08...  \n",
       "15   [-0.015632482, -0.0027931707, -0.016667966, -0...  \n",
       "276  [0.011783604, 0.007787306, 0.008415056, -0.080...  \n",
       "158  [-0.0027418581, -0.026277944, -0.019228248, -0...  \n",
       "331  [-0.019259144, -0.021168273, 0.030300863, -0.0...  \n",
       "239  [-0.0036713977, -0.010136703, -0.010862582, -0...  \n",
       "48   [-0.010922581, -0.010670915, -0.0019729831, -0...  \n",
       "206  [-0.011633852, -0.009310706, -0.011479081, -0....  \n",
       "167  [-0.04023646, -0.0033757573, -0.015112562, -0....  \n",
       "175  [-0.024715586, -0.01256246, -0.0125413975, -0....  \n",
       "16   [-0.009913362, -0.003055955, -0.015127845, -0....  \n",
       "190  [-0.024835743, 0.00060396525, 0.009073344, -0....  \n",
       "300  [-0.0069135656, -0.0037595944, -0.022816306, -...  \n",
       "113  [-0.02130687, -0.016090302, 0.015765466, -0.05...  \n",
       "320  [0.011736909, 0.018727152, -0.005402915, -0.06...  \n",
       "289  [-0.015942886, 0.0062166224, -0.009731274, -0....  \n",
       "1    [2.788781e-05, -0.009843583, -0.016139457, -0....  \n",
       "235  [0.0023312648, 0.019491544, -0.015060243, -0.0...  \n",
       "44   [-0.0054591983, 0.010110117, -0.017452167, -0....  \n",
       "178  [-0.0066989562, 0.0057921065, -0.011250335, -0...  \n",
       "53   [-0.025528934, -0.0049635707, -0.010728385, -0...  \n",
       "246  [0.0049384963, -0.0004102937, -0.020839296, -0...  \n",
       "100  [-0.020354087, -0.010737755, -0.0066496436, -0...  \n",
       "37   [-0.0010682619, 0.018157829, -0.005871065, -0....  \n",
       "216  [-0.010979394, 0.0126972, -0.029265268, -0.051...  \n",
       "343  [-0.0016530727, 0.0044874516, -0.0070126606, -...  \n",
       "63   [-0.0028998374, -0.02078183, 0.016478756, -0.0...  \n",
       "294  [-0.0058687045, 0.016114332, -0.01448304, -0.0...  \n",
       "250  [-0.019118113, -0.017402798, -0.030459225, -0....  \n",
       "321  [-0.006563008, -0.01716611, 0.008511609, -0.06...  \n",
       "166  [-0.043868568, 4.1717867e-05, -0.017276116, -0...  \n",
       "142  [0.0034173268, 0.014688194, 0.0070801787, -0.0...  \n",
       "103  [-0.027871776, 0.015271844, 0.0153815765, -0.0...  \n",
       "93   [0.0047239466, -0.0126334075, -0.0056003057, -...  \n",
       "27   [-0.013165958, -0.038608503, -0.008693953, -0....  \n",
       "180  [-0.013611719, -0.008574327, 0.009228598, -0.0...  \n",
       "228  [-0.009656984, 0.028854532, 0.0026595625, -0.0...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_new #We can see the new column with the embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save them to pickle files\n",
    "train_df_new.to_pickle(\"./data/train_df_sample_embeddings.pkl\") \n",
    "test_df_new.to_pickle(\"./data/test_df_sample_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# load the pickle files\n",
    "train_df_new = pd.read_pickle(\"./data/train_df_sample_embeddings.pkl\")\n",
    "test_df_new = pd.read_pickle(\"./data/test_df_sample_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df_new.iloc[0][\"embeddings_values\"]) # Gemini embedding dimension is 3072 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kuojouhsiang/Documents/DM2025-Lab2-Exercise/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/kuojouhsiang/Documents/DM2025-Lab2-Exercise/.venv/lib/python3.11/site-packages/umap/umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "Anger is cheap and politeness is expensive. Don't expect everybody to be polite. #ThoughtfulThursday  #politeness",
           0.333
          ],
          [
           "Absolutely raging at the changes to CAS, what a joke",
           0.604
          ],
          [
           "The sun literally burning my skin",
           0.438
          ],
          [
           "@RealBD_ @ReyesAverie 47 unarmed blacks killed by white cops in 2015. That many die every month in Chicago wheres the ",
           0.625
          ],
          [
           "@bt_uk why does tracking show my equipment delivered, when it wasn't? Why is my service suddenly delayed? We've already 3 weeks. ",
           0.646
          ],
          [
           "@kateracculia @themathofyou It's true! I reverse-engineered the drink. It's a scientific method. I hear it's all the rage.",
           0.333
          ],
          [
           "@marthalyssa yep. LOL #bitter",
           0.417
          ],
          [
           "@ChronAVT ummm, the blog says 'with Simon Stehr faking 7th'...I'll expect an investigation forthwith. This is an #outrage",
           0.688
          ],
          [
           "#Taurus will react angrily when she can't take being provoked any longer.",
           0.438
          ],
          [
           "Don't get #bitter get #BETTER",
           0.312
          ],
          [
           "@CrayonToCrayon @SueScoby \\nIt's always fun to anger 'All the Old Dudes.' with Rock N' Roll :))",
           0.354
          ],
          [
           "@cburt43 turn that frown upside down",
           0.125
          ],
          [
           "@OstinOng YUUUHH  plus clin ep and prevmed ugghhh hahaha ",
           0.438
          ],
          [
           "@sarah_urbina why do you even beef Sara you let the anger get the best of you, you and Sagin been friends for how long?",
           0.479
          ],
          [
           "@thatomahapa the best revenge is to get yourself a good woman and move on. Leave her and her hairline to figure themselves out alone",
           0.438
          ],
          [
           "@DeltaDomain @SawDraze @qurions dis dat nigga from fume right?",
           0.417
          ],
          [
           "What the fuck am I supposed to do with no lunch, no dinner, no money and I'm off to work #furious #hangry #day5",
           0.729
          ],
          [
           "@firstleeds not only are your buses unreliable your e ticket app is too unable to get on two buses and late for work #fuming #useless reply",
           0.864
          ],
          [
           "Your twitter picture just makes me fume.",
           0.729
          ],
          [
           "Worst juror ever? Michelle. You were Nicole's biggest threat.  #bb18",
           0.562
          ],
          [
           "@Lexual__ @jdspielman10 RIP to the 100s of black men,, women,CHILDREN killed in Chicago. Where is the outrage?",
           0.562
          ],
          [
           "testing #angry",
           0.667
          ],
          [
           "I believe women are more fiery because once a month they go through struggle and struggle is what develops a strong character.",
           0.417
          ],
          [
           "@Casper10666 I assure you there is no laughter, but increasing anger at the costs, and arrogance of Westminster.",
           0.604
          ],
          [
           "@dcexaminer Democrats and their voters have zero tolerance for honesty. They associate honesty with anger and hate.",
           0.667
          ],
          [
           "@snowangel415 @cjwalters66 Maybe also being attacked by Tom's rabid fans to whom he &amp; his clothes were always perfect also put me off him...",
           0.646
          ],
          [
           "Cheap pout my brodcast",
           0.232
          ],
          [
           "@LynneGarrison yeah, I've only seen that floated online as a theory, it was probably made up by a bitter stan. I ignore pets v vets crap too",
           0.562
          ],
          [
           "@VodafoneUKhelp @VodafoneUK wow!! My bill is 44.77 and hav a text from u to prove that and you have taken 148!!!!! #swines  #con!",
           0.646
          ],
          [
           "Did we miss the fact that #BurkeRamsey swung &amp;hit his sister #JonBenet in the face with a golf club previously out of a fit of #anger?",
           0.598
          ],
          [
           "Some moving clips on youtube tonight of the vigil held at Tulsa Metropolitan Baptist church for #TerenceCruther #justice  #sadness",
           0.438
          ],
          [
           "I wish the next madden has a story mode too. Just like Fifa 17 #madden",
           0.312
          ],
          [
           "@cineworld 'Congratulations your Free 1 month has been activated' Then charges 34.80 the same month. Absolutely furious ",
           0.667
          ],
          [
           "srry my feelings offend u ",
           0.354
          ],
          [
           "@xandraaa5 @amayaallyn6 shut up hashtags are cool ",
           0.438
          ],
          [
           "Taking a break from the #wedding to #rage at the general #stupidity of certain #people on the #internet.",
           0.625
          ],
          [
           "@TheDTSB @trubble1127 @nflnetwork I agree but our offense was ass after the second half td score on the first drive",
           0.417
          ],
          [
           "@TheOneSoleShoe that is one thing but attacking and hating is worse - that makes us just like the angry vengeful behavior we detest",
           0.583
          ],
          [
           "Sorry guys I have absolutely no idea what time i'll be on cam tomorrow but will keep you posted. #fuming",
           0.417
          ],
          [
           "Is it me, or is Ding wearing the look of a man who's just found his arch enemy in bed with his missus? #angryman ",
           0.557
          ],
          [
           "Ok scrubbed hands 5 times before trying to put them in.\\nEyeballs #burning \\n#EvenMoreBlind accidentally scared the #cat whilst #screeching",
           0.604
          ],
          [
           "Is it me, or is Ding wearing the look of a man who's just found his arch enemy in bed with his missus? #angryman #scowl",
           0.5
          ],
          [
           "@ArcticFantasy I would have almost took offense to this if I actually snapped you",
           0.458
          ],
          [
           "You're so thirsty for the chance to disagree w/ the left, that you don't even realize when something is an affront to your bigoted platform.",
           0.5
          ],
          [
           "Having a baby born too soon is #lifechanging 6 years on and it feels like only yesterday #sad #happy #angry #emotionalrollercoaster",
           0.375
          ],
          [
           "i live and die for mchanzo honeymoon crashing and burning the second they move in together",
           0.479
          ],
          [
           "Why to have vanity sizes?Now sizes S,XS(evenXXS sometimes) are too big, WTF?! Dear corporate jerks, Lithuania didn't need this. #rant ",
           0.518
          ],
          [
           "@RevTrevK @Wolfman93011 @Daraidernation @EROCKhd Take 2k out of it the numbers on madden are low and have dropped and people are unhappy",
           0.586
          ]
         ],
         "hovertemplate": "emotion=anger<br>UMAP1=%{x}<br>UMAP2=%{y}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "anger",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "anger",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "vFKfP5i3qD/h1GZAOrJ2QJZ62T8z2BtAYFEFQG5U1T/pm5Q/st/AP8Bduj8UXvg/HhhDQMLkBEA8690/pTYAQEcnhD//HaU/lhjYP2WVJUDhO2pAFrevP/PtZz8yodY/zFwFQAe/EEDOpeU+p3ALQKhhtT9qOSxAtbxoQFHQOEAQiKw/NgAZQBhfsT89jp0/YAwsQHGsAkCxAOw/Q0TPP9DJbEDsz70/i88NQIikZ0BiNFRApocGQLiyhj+hGzdA",
          "dtype": "f4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "OAomQcjWLkFzcwtBl98zQcjDNkH5hO5AH30YQdf/LUHlXSFBbjwXQQNtIEFsdfVA+HsQQV4NIEE8rhdBipwhQb+BH0Fw1jxBfIcgQdWWMEH7STdBzCkiQT9zG0G+lCpBCegqQfdkKEFU7AFBN/ceQe7QOkFcbiZBvWI3QdYyPEHdVjpBRmYWQcibG0Ez0ylBH1s6QW1ZJ0H5lhVBOt8mQYWYCEFuXCZB4V4XQb3KLEHyhuxAhUICQSi1LkFxcjtB",
          "dtype": "f4"
         },
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "I'm afraid she's the goat you libeling people?  #goat #libeling",
           0.562
          ],
          [
           "Nawaz Sharif's UN should start #__ as after all his #UNGA speech has awaken the world about their role in sponsoring #terrorism",
           0.685
          ],
          [
           "jesus ok an alarming percentage of my teachers ths year dont have a  s ingle thoughtful bone in their bodies . its gonna b an interesting yr",
           0.565
          ],
          [
           "@leeuwlion 'The furries are restless tonight'.",
           0.438
          ],
          [
           "@StephenKing\\n\\nStephen King never once spoke out about how the Left crushes #FreeSpeech in publishing world.\\n\\n#Trump #horror #scifi #ccot #p2",
           0.542
          ],
          [
           "Follow this amazing Australian author @KristyBerridge #fiction #horror #zombies #angels #demons #vampires #werewolves #follow #authorlove",
           0.396
          ],
          [
           "After Nawaz Sharif's speech on terrorism, Kejriwal is expected to talk on Governance.",
           0.28
          ],
          [
           "Some questions you get on Twitter make you want to despair. We've been so battered. We complain but aren't convinced things could be better.",
           0.66
          ],
          [
           "#Charlotte's #young &amp; #restless; I applaud ur fire bt always b respectful of authority, police, elders, parents. Violence, not the way ",
           0.438
          ],
          [
           "Now #India is #afraid of #bad .",
           0.562
          ],
          [
           "@mikebairdMP @AndrewConstance @nswtaxi how many sex cases u need before u guys learn UBER is shocking to the consumer unregulated",
           0.646
          ],
          [
           "@tchop__StL @YouTube \\nI get sick to my stomach everytime I see this video &amp; for the helicopter crew to make such comments is revolting.",
           0.875
          ],
          [
           "@DiscordianKitty He has charisma? I guess, if you like people who looked coked out and speak as if they're a school bully?",
           0.458
          ],
          [
           "@DemPhillyEagles @StonedPhillyFan @CraigfromCincy don't ever compare those scrubs to ben..he'll shake off your whole DL and throw a td #7",
           0.188
          ],
          [
           "Thought I left that part of life behind me\\nIt's back to haunt every girl that loves me",
           0.521
          ],
          [
           "... in the same speech.  However he did mention foreign hand and funding in terrorism in the country. \\n#ProudOfYouPrimeMinister",
           0.417
          ],
          [
           "Anyyyyone wanna go to fright fest with me on Friday night? ",
           0.354
          ],
          [
           "#COINCIDENCE??? When you turn on the TV, etc.&amp; listen &amp; watch, the objective is to #CaptureYourMind with #fear &amp; #depression. #FindGODNow!!!",
           0.542
          ],
          [
           "@Gibberman10 @ScottHoward42 any of y'all remember when MLB tried a futuristic jersey those were all ",
           0.24
          ],
          [
           "Sounds like Donald Trump has spent today just making extra, extra sure he'd get those frightened white, conservative, racist votes.",
           0.625
          ],
          [
           "Rojo is a terrible defender",
           0.375
          ],
          [
           "@SherriEShepherd because #whitepeople are #afraid of large #blackmen?",
           0.646
          ],
          [
           "@Tik115 Issue with that is, will the effort involved get back the amount I put into it? That's what I'm fearful of.",
           0.708
          ],
          [
           "I start work tmrw yall, i'm nervous lol",
           0.854
          ],
          [
           "Howl at the moon with @HorrorSociety at @FatCatChicago next Wednesday the 28th for a FREE double feature of SILVER BULLET and CURSED #horror",
           0.333
          ],
          [
           "That old lady is cray cray #scared #BellaIsSoCute #awe #Empire",
           0.574
          ],
          [
           "@datboyJuniorE lool soon as man start loosing weight.  Its panic",
           0.604
          ],
          [
           "#panic Panic attack from fear of starting new medication",
           0.917
          ],
          [
           "Not setting an alarm to nap &gt;&gt;",
           0.16
          ],
          [
           "@1NatalieMaines Can you imagine being the person who has to spray tan him? #shudder",
           0.491
          ],
          [
           "@AOLUK @JamesHayr @TheDrum Anychance of addressing the communication I sent to you yesterday??? I still haven't had any contact ",
           0.312
          ],
          [
           "Tired of people pretending Islam isn't one of the most misogynistic religions, it's no coincidence Muslim countries are terrible for women.",
           0.66
          ],
          [
           "@BossUpJaee but your pussy was weak from what I heard so stfu up to me bitch . You got to threaten him that your pregnant .",
           0.396
          ],
          [
           "81' Goal scorer Vidar Kjartansson comes off in favor of Dor Micha! Another terrific performance by @Vidarkjartans #YallaMaccabi",
           0.229
          ],
          [
           "@CBCNews Canada should be a driving force of democracy freedom rights - instead we help #dictator #misogyny #Sharia #Islam  #polygamy",
           0.625
          ],
          [
           "@eclecticbrotha Thanks, big bro. It's shake and bake and you helped.",
           0.184
          ],
          [
           "@AHSFX thanks Ryan &amp; Brad for scary the shit out of us in the first episode. Don't think my heart will make it through the s6 #horrific",
           0.875
          ],
          [
           "That last minute was like watching a horror show #GBBO ",
           0.5
          ],
          [
           "Can't believe how nervous I feel tonight...who feels the same #mufc",
           0.812
          ],
          [
           "@Greener105th so you are astounded that I respect blacks to vote like any other human? u talk so down towards them. What bigotry on display!",
           0.521
          ],
          [
           "Huns are like a box of coffee revels ",
           0.229
          ],
          [
           "@Policy_Exchange A plus point, she won't have to queue for the loos. Any more plus points? Nope, can't think of any  #sexism",
           0.438
          ],
          [
           "This week's Massacre Theatre pert by @LarsenOnFilm is the first one I can think of that requires subtitles. ",
           0.245
          ],
          [
           "not only was that the worst @EGX that's I've attended but worth one of the worst cons I've been to in the last 5 years #terrible",
           0.583
          ],
          [
           "How is that in 2016, a 757 airplane does not have WiFi...ridiculous. #AmericanAirlines #americanairlinessucks #AATeam ",
           0.292
          ],
          [
           "#Trump is #afraid of the big, bad #Hillary. #election #PresidentialDebate #PresidentialElection2016 #orangehitler #skip #hide #coward #fear",
           0.531
          ],
          [
           "And here we go again  #restless",
           0.667
          ],
          [
           "How can America be so openly embracing racism. #dismayed",
           0.604
          ],
          [
           "#BB18 Michelle crying  again #shocking #bitter He's  just not that into you #TeamNicole",
           0.521
          ],
          [
           "@iSmashFizzle that's me all the time. I carry ginger candy, peppermint oil and sea-bands at all times ",
           0.354
          ],
          [
           "Your boy' is having a nightmare @VivaLaSergio",
           0.646
          ],
          [
           "Whatt a trailerrrr !!! @karanjohar @AnushkaSharma #RanbirKapoor #AishwaryaRaiBachchan i am COMPLETELY BLOWN !!  #longingformore",
           0.354
          ],
          [
           "Thanks for ripping me off again #Luthansa 400 not enough for a one way flight to man from Frk then 30 for a bag then free at gate #awful",
           0.521
          ],
          [
           "It really is amazing the money they give to some of these QB's #nfl #texans #brock #terrible",
           0.246
          ],
          [
           "#twitter #users Tweeting on twitter is like playing a game against the computer. Where's the life, Everyone too #afraid to say something?",
           0.521
          ],
          [
           "Staff on @ryainair FR1005. Asked for info and told to look online. You get what you pay for. #Ryanair @STN_Airport #Compensation #awful",
           0.271
          ],
          [
           "@soozclifford Sure have... Sydney are too tough, too quick and their 'team' pressure is too much for the Cats to handle. Motlop/Cowan #timid",
           0.34
          ],
          [
           "Tweeting from the sporadic wifi on the tube ",
           0.292
          ],
          [
           "We can easily #forgive a #child who is #afraid of the #dark; the real #tragedy of #life is when #men are #afraid of the #light.Plato",
           0.375
          ],
          [
           "It really is amazing the money they give to some of these QB's #nfl #texans #brock ",
           0.3
          ],
          [
           "@stephenfhayes Mustard gas = hostile work environment, not #terrorism; call #OSHA not #military",
           0.708
          ],
          [
           "Having a terrific Tuesday? Crush it today with the Power of 4. Treat your internet like Pizza =D \\n#PowerOf4",
           0.25
          ],
          [
           "There goes the butterflies in my stomach. #nervous #anxietyproblems",
           0.812
          ],
          [
           "If i start growing out my mustache now, I can be Pablo Escobar for Halloween!!!",
           0.25
          ]
         ],
         "hovertemplate": "emotion=fear<br>UMAP1=%{x}<br>UMAP2=%{y}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "fear",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "fear",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "v9aYQMwhiEDcNXZAaNUlQL7JdkAt23o/2PmKQPICUUBuZnBAbumWQLtf9T+ST19Au8kTQAvvKUBo305AaLaEQElzhEDkSoJAs54uQMfBe0Cw5BNAXVCUQGlFbkBXBYxAw7SKQMW3lkDJUYVAlhyUQMS3PkCGVYlAFnDIP6BqaUA1ljlA22EaQGLDekDMiCBAazaXQNowlECyi5ZAV+9oQF3sKkBpk1pAIJ1BQDgdyD/Kb5I/Fv2cQMaAZUBhS3VA+ZouQFWDSUCLDX9Ao+MrQOlGoD9UiCRAC7dwQGUqsT8OdmpAIEFDQH88mkB/BiRAC8WOQJUS+z9xk5dASNqEQA==",
          "dtype": "f4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "8vodQdX9JEG9eQxBmgIdQUdQKEGA9/5A5BMkQapnH0G36DhBHLUeQWIGPUFDjTdBnhIiQaQmPkF0twxBJeolQWtr/0BejRxBq5w4QcnaL0HOTjJBeGQnQSw7BkETXAhBB1ICQVjSFUGHDg9Br1YMQaz0B0Eu+BZBRFo3QadDK0Et3jJBJ2rOQNPhKUHzjuhAWHsSQZYwFEHaiA5BPDgwQUaL+UAFhiZBD44fQYfZO0HNjjlBbIshQRgvD0GsujFBvpEuQSPF/kBcZhVB377SQHKCPEEl2T5Bo2QeQTAGPkFhaR1BbiAiQTInI0HGGEBBj9YoQaqY2ED0Vw5BLLL1QA==",
          "dtype": "f4"
         },
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "@smoothkobra after such a heavy 2 days this has given much needed levity. Thanks bro",
           0.438
          ],
          [
           "Good morning joyful people. Choose happiness to have a great day today #morning #joyful #happiness #grandmercurejktkemayoran",
           0.833
          ],
          [
           "Oh dear an evening of absolute hilarity I don't think I have laughed so much in a long time! ",
           0.958
          ],
          [
           "@CazuaL_WeaR @ScottInSC looks like a book shaped like a gun to me #optimism #itsagunalright",
           0.408
          ],
          [
           "Knowing how to cook is invaluable, what's even better is that even in a 400 sq ft place, I have wide and hearty homestyle egg noodles.",
           0.562
          ],
          [
           "Thinking about trying some comedy on youtube. Always been fond of it. Time to nut up. #laughter #comedy #maybeoneday #hopefullyfunny #LOL",
           0.646
          ],
          [
           "It's the #FirstDayofFall and I'm so happy. Sipping my #PumpkinSpice flavored coffee and #smiling! Happy Fall everyone! #amwriting",
           0.86
          ],
          [
           "Lmboo , using my nephew for meme #hilarious",
           0.654
          ],
          [
           "#hate going to the doctor on so many levels but least I can go sleep with a #smile just watched #Dwight on live nation",
           0.34
          ],
          [
           "myself that despite the absolute delight my children and I would feel having a kitten in our home, the misery my husband would feel is more.",
           0.327
          ],
          [
           "15 minutes of yoga to your breakfast routine will change your day #preparation #sunriseyoga #bodyawareness #health #yoga  #stretch",
           0.521
          ],
          [
           "Watch this amazing live.ly broadcast by @rosannahill #lively #musically",
           0.56
          ],
          [
           "Today's realisation that it was the last time I watch swimming lesson cos I go back to work next week lead to a joyous bedtime. #worstoneyet",
           0.34
          ],
          [
           "I would like to congratulate the people of Saudi Arabia a happy and a joyous national day. May you all have a great time! #_",
           0.771
          ],
          [
           "She gave a playful wink, taking the goggles off her head, swinging them around her finger. 'I would never~' @VerminEngineer",
           0.534
          ],
          [
           "Twitter is a font of endless hilarity.",
           0.42
          ],
          [
           "@TheSandraGal Glad to see that you're having fun in the sun. Water sports are always fun, challenging, and exhilarating. #happiness #beauty",
           0.796
          ],
          [
           "Wishing a very Happy Birthday to our awesome dancer, Ruthann!!! We hope your day is magical! #bday #happy #eatcake",
           0.75
          ],
          [
           "Watch this amazing live.ly broadcast by @matt.boss #lively #musicallyjh",
           0.479
          ],
          [
           "@DorH84607784 Oh FANTASTIC, I bet it was super exhilarating  ",
           0.84
          ],
          [
           "@Blancalanka96 thought it'd be fun and it is not fun but on the bright side I don't have to fight for parking",
           0.34
          ],
          [
           "her fingers slide along your thighs, caressing the skin before she's leaning down, down, down and the first lick is teasing n playful.",
           0.54
          ],
          [
           "Watch this amazing live.ly broadcast by @hannah..mccloud #lively #musically",
           0.562
          ],
          [
           "When you wake up from a dream laughing at something stupid, and that makes you laugh more #hilarious",
           0.875
          ],
          [
           "@NebulaJoker No, they aren't. Episodes are animated during the week before they air.",
           0.231
          ],
          [
           "@alphavenger all chuck seasons, she had that one bright spot with dan, where she was allowed to be smart and kind //and// fashionable",
           0.189
          ],
          [
           "Watch this amazing live.ly broadcast by @brooke_bridges #lively #musically",
           0.5
          ],
          [
           "@EducatedNPetty white pricks that were laughing at your use of language won't be crying over your coffin but rejoicing that you're another",
           0.25
          ],
          [
           "Do what makes you successful and #happy now and forever",
           0.562
          ],
          [
           "Go follow #beautiful #Snowgang @Amynicolehill12  #Princess #fitness #bodyposi #haircut #smile #Whitegirlwednesday",
           0.604
          ],
          [
           "@MerenthaProphet - the Hunter in this way, content and joyous in simple, domestic bliss? I cannot wait for word of who you truly are to -",
           0.349
          ],
          [
           "It's not that the man did not know how to juggle, he just didn't have the balls to do it. \\n#funny #pun #punny #lol #hilarious",
           0.519
          ],
          [
           "@KWAYNTjoia it's exhilarating",
           0.583
          ],
          [
           "Morning all! Of course it is sunny on this Monday morning to cheerfully welcome us back to work.:)",
           0.863
          ],
          [
           "@FlannelJedi This is why I drink and watch You're the Worst as a way to cheer myself up.",
           0.292
          ],
          [
           "If you have the ability to make someone happy or to make someone #smile, do it! The world needs more of that right about now. #CreateLove ",
           0.66
          ],
          [
           "@hesham786 that's the spirit ",
           0.354
          ],
          [
           "Nawaz Sharif is getting more funnier than @kapilsharmak9 day by day. #laughter #challenge #kashmir #baloch",
           0.7
          ],
          [
           "@bruins_514 @gorddownie @thehipdotcom It would be #TragicallyHip if they can #help @TOYSFORASMILE make #hospitalized  #sick #kids #smile ",
           0.519
          ],
          [
           "@Gronnhair @buryprofs @DittoBistro it was indeed lovely and the team were incredibly attentive and on the ball. Cheese was a lively gesture!",
           0.646
          ],
          [
           "@diehimbeertonis She developed her 'forced smile'. I can force myself to describe it 'a little hearty maybe, sanki biraz':)",
           0.208
          ],
          [
           "@harrietemmett great minds think alike. ",
           0.479
          ],
          [
           "A cheerful heart is good medicine, but a broken spirit saps a person's strength.' {Proverbs 17:22} #WednesdayWisdom",
           0.292
          ],
          [
           "@Bridget_Jones was joyous. Worried I would be disappointed. Most definitely was not. #chickflick #giggles #comethefuckonbridget",
           0.68
          ],
          [
           "If you don't respond to an email within 7 fays, you wifl be killed by an animated gif of the girl from The Ring.",
           0.18
          ]
         ],
         "hovertemplate": "emotion=joy<br>UMAP1=%{x}<br>UMAP2=%{y}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "joy",
         "marker": {
          "color": "#00cc96",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "joy",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "6BE2QOZTvD8wWUpAAtExQHYR8j/i/HVA6nzDP1/EY0CxRVZAJsU8QFsAvj8mHRU/68dMQBVp0T+cRA1ARE5aQJoryT/fmsQ/LwS8PlMVGEDCS1VAY7EAQFl/Aj/XWmNA2u31P2ghAkAVOAQ/7vlZQFP/3j+qn4s/7PgLQIQxckDclRFAwHS1P7RlHEBtlsE/JpQfQPtCgEAtsyBAwYUzQFELB0DwVjRAZn7dP7ZiQ0BM3plA",
          "dtype": "f4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "J9TkQKur2ECbcNdAnKbxQF3q1kBgDedAQVLSQBk33UD44/hAkHsGQUOU1kBOBPpA+h7tQDsg2EAg1AxBdabfQBKw4EDYmdxAzsUAQcW40kB+PgRBFaoHQQem/kC5adxAcscUQa43A0FJNQBBBbAxQTOk4kDZVvFAmwUAQRcg4EA/qN9A2YDVQKxd/EAfHeZALLfoQLcq3kCd8gtBqIjYQO/JCEHSZ/FA4ljyQMgj0kAhqRhB",
          "dtype": "f4"
         },
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "Marcus Roho is dreadful",
           0.521
          ],
          [
           "@A_RockasThe U.S. has added years to the Syrian conflict by arming the 'rebel' army. You would think that Iraq had sunk in with Kerry.",
           0.417
          ],
          [
           "My nephew sees that i have a frown on my face and he tells me 'you're  beautiful '!",
           0.542
          ],
          [
           "@ticcikasie1 With a frown, she let's out a distraught 'Gardevoir' saying that she wishes she had a trainer",
           0.479
          ],
          [
           "Just put the winter duvet on  #serious",
           0.312
          ],
          [
           "One step forward, two steps backward, the link to RogerFedererShop doesnt work. I am losing hope about Roger Federer new Website #sadness",
           0.583
          ],
          [
           "@LondonMidland #dobetter only two carriages on 14:49 Birmingham to Hereford no room to stand anymore Friday commute #unhappy",
           0.542
          ],
          [
           "@StarklyDark 'Come here. Come on. Into my arms. I'm not going anywhere, Tony, I swear.' Steve told him, quiet and solemn.",
           0.5
          ],
          [
           "Damn gud #premiere #LethalWeapon...#funny and ",
           0.229
          ],
          [
           "@msfang they say you attract what you see, maybe I shouldn't be a pessimist but I don't wanna take any chances lol can't wait to relocate",
           0.333
          ],
          [
           "And there is despair underneath each and every action \\nEach and every attempt to pierce the armour of numbness ' -Mgla",
           0.583
          ],
          [
           "@xBFDR yeah I'm sure it will, it's just so depressing having to talk to my parents over the phone instead of talking to them downstairs",
           0.833
          ],
          [
           "I'll just have to #eat my way to #sobriety. This'll be a hell of a journey back to #sober",
           0.625
          ],
          [
           "Shoutout to the drunk man on the bus who pissed in a bottle and on the seats ",
           0.436
          ],
          [
           "@TDYLN sadly not :(",
           0.667
          ],
          [
           "@VivYau is it all doom and gloom? I only want to hear lovely things about airbnb!",
           0.458
          ],
          [
           "Im kind of confused.  The one thing i do right now has a great future, but on the other hand so does the new thing .  #needhelp",
           0.521
          ],
          [
           "@ImpugnValkyrie *I frown and cup your cheeks in my hands after you step aside.* Angela I care about you. And I don't know how else I can -",
           0.604
          ],
          [
           "Good morning chirpy #SpringEquinox and your pensive sister #AutumnEquinox A perfect day however it is expressed  #theBeautyofBalance",
           0.167
          ],
          [
           "I got a short fuse when im sober.",
           0.312
          ],
          [
           "The Sorrow is grim reminder of how bad I can be at video games and how I could get a bit too trigger happy at times. RIP #MGS3",
           0.604
          ],
          [
           "@wabermes The @RavalliRepublic had a good one but then the reporter quit. #sad",
           0.708
          ],
          [
           "I keep feeling the heaviness on my left hand and look down and I am in awe every single time  #notusedtoit #imafiance #wut",
           0.208
          ],
          [
           "Sky news still pushing the Brexit gloom line, managing to ignore the fact it's simply not happening. 'But in the future.....'",
           0.396
          ],
          [
           "I don't know why everyone is pretending to be sad about angelina and brad, everyone knows his dumb ass should've stayed with jennifer.",
           0.354
          ],
          [
           "@10carley what a sulky pants!",
           0.396
          ],
          [
           "I miss when social media was a place to get laughs off and jump in DMs lol..... shit is depressing now ",
           0.792
          ],
          [
           "-- used as a pawn in this red woman's game] For now, try not to fret and act as if nothing is amiss. This is a royal -- @TheLadyOfGlenco",
           0.354
          ],
          [
           "@SkyNews err I wasnt gloomy.  17.2 mio people were not gloomy only #remain were #Brexit",
           0.458
          ],
          [
           "@Courteoussoul @MattyMcDee I'm at 349 and just decoded 20 or more blues and not one was over 340, where you getting your blues?",
           0.333
          ],
          [
           "Regret for the things we did can be tempered by time; it is regret for the things we did not do that is inconsolable. - Sydney J. Harris",
           0.354
          ],
          [
           "Unmatched Party Specialist /co @T3RevNeverEnd #serious #job #titles",
           0.208
          ],
          [
           "There's many things I don't care about, and many things I do that I don't speak on because it's such a heaviness even when released...",
           0.625
          ],
          [
           "If anybody needs me I'll be drowning my blues in a sea of whiskey ",
           0.75
          ],
          [
           "You don't know how to love me when you're sober #sober #selenagomez #revival",
           0.458
          ],
          [
           "Stars, when you shine,\\nYou know how I feel.\\nScent of the pine, \\nYou know how I feel.\\nFreedom is mine,\\nI know how I feel.\\nI'm feelin' good.",
           0.292
          ],
          [
           "yesterday i finished watching penny dreadful and from all the beautiful things i saw one question remains: were the writers HIM's fans?",
           0.312
          ],
          [
           "This shit hurting my heart  that's how serious it is .",
           0.875
          ],
          [
           "@Barcabhoy1 Of course not. Didn't sink his studs into a knee like Forrester",
           0.396
          ],
          [
           "[ @HedgehogDylan ] *she would frown a bit, folding her arms* 'why is it that every time I'm in need of assistance someone expects a lil **",
           0.562
          ],
          [
           "I'd rather laugh with the rarest genius, in beautiful alliance with his own being, where he kept his sadness. #melancholy",
           0.688
          ],
          [
           "@pmo100 @5liveSport .....I heard talk something is a miss. He looks weary.",
           0.458
          ],
          [
           "Soooo badly want to dye my hair dark but have never been dark before soooo torn ",
           0.5
          ]
         ],
         "hovertemplate": "emotion=sadness<br>UMAP1=%{x}<br>UMAP2=%{y}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "sadness",
         "marker": {
          "color": "#ab63fa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "sadness",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "2moKQECbhUCUOANAmK8XQJHTS0CfnkNATgq5P6G7C0CV7EtAf41gQNc8Q0DipEpAMByhPzxYOUC7FjlAxvwnQC2ydUBk9wNAQCuoP2t9nD8PCi1AyVRMQACnGUC5CE5AkgwmQGLK+j96hWBAbpjyP7RfVUAjyCxAgogoQIZeOUCfA1NAWekoQK3Epz+N1fM/OtuNQMWXaUD3BCBAb/UKQBN+LUB1ZUxAGfyBQA==",
          "dtype": "f4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "NYkzQTF/JkFkae5AB9sOQe6FA0FL7RRBxBc/QQwuC0HbidRAfvr/QJ6rFEFxeRFBNg4TQQ9FK0Ex8Q5BQ6LUQCX4BEHBCwxBODvRQGBtGUEFHxhBLI4WQXTo4UCtGidBxT4tQYJtIUGH5RVBod4PQSfCJkGMCwhBvE0YQTzk+0CfdQtBp0wHQWqLEUFpkdRABL0SQaE/EUEWoCdBlLIOQa71CUF5pB5BypgFQQ==",
          "dtype": "f4"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "emotion"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "2D UMAP Projection of Text Embeddings"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "UMAP1"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "UMAP2"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import umap\n",
    "import plotly.express as px\n",
    "\n",
    "# Concatenate the training and test data\n",
    "combined_df = pd.concat([train_df_new, test_df_new], ignore_index=True)\n",
    "\n",
    "# Prepare the embeddings for UMAP\n",
    "# Convert the list of embeddings into a 2D numpy array\n",
    "X_embeddings = np.array(combined_df['embeddings_values'].tolist())\n",
    "\n",
    "# Apply UMAP for dimensionality reduction\n",
    "reducer = umap.UMAP(n_components=2, metric='cosine', random_state=28) \n",
    "embedding_2d = reducer.fit_transform(X_embeddings)\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "df_plot = pd.DataFrame(embedding_2d, columns=['UMAP1', 'UMAP2'])\n",
    "df_plot['emotion'] = combined_df['emotion']\n",
    "df_plot['intensity'] = combined_df['intensity']\n",
    "df_plot['text'] = combined_df['text']\n",
    "\n",
    "\n",
    "# Visualize the embeddings with Plotly\n",
    "fig = px.scatter(\n",
    "    df_plot,\n",
    "    x='UMAP1',\n",
    "    y='UMAP2',\n",
    "    color='emotion',  # Color points by the 'emotion' column\n",
    "    hover_data=['text', 'intensity'],  # Show text and intensity on hover\n",
    "    title='2D UMAP Projection of Text Embeddings'\n",
    ")\n",
    "\n",
    "fig.write_image(\"results/umap2d.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![2D UMAP](results/umap2d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that even with Gemini's embeddings there doesn't seem to be a clear 2D separation of clusters with our data classes. It could be because emotions are often not discrete. Texts can contain mixed feelings (e.g., \"bittersweet\") or use similar language to express different emotions, causing their embeddings to be naturally close in semantic space. And also the process of projecting high-dimensional embeddings down to a 2D visualization inevitably loses some information, which can make distinct clusters appear to overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_8_1_1_'></a>[**>>> Exercise 4 (Take home):**](#toc0_)\n",
    "\n",
    "Apply UMAP to the same embeddings to reduce the dimensionality to 3D vectors and plot the 3D graph, discuss the differences and similarities with the 2D graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kuojouhsiang/Documents/DM2025-Lab2-Exercise/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:132: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/kuojouhsiang/Documents/DM2025-Lab2-Exercise/.venv/lib/python3.11/site-packages/umap/umap_.py:1945: UserWarning:\n",
      "\n",
      "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\n",
      "I0000 00:00:1763795856.136332 3379215 fork_posix.cc:71] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "Anger is cheap and politeness is expensive. Don't expect everybody to be polite. #ThoughtfulThursday  #politeness",
           0.333
          ],
          [
           "Absolutely raging at the changes to CAS, what a joke",
           0.604
          ],
          [
           "The sun literally burning my skin",
           0.438
          ],
          [
           "@RealBD_ @ReyesAverie 47 unarmed blacks killed by white cops in 2015. That many die every month in Chicago wheres the ",
           0.625
          ],
          [
           "@bt_uk why does tracking show my equipment delivered, when it wasn't? Why is my service suddenly delayed? We've already 3 weeks. ",
           0.646
          ],
          [
           "@kateracculia @themathofyou It's true! I reverse-engineered the drink. It's a scientific method. I hear it's all the rage.",
           0.333
          ],
          [
           "@marthalyssa yep. LOL #bitter",
           0.417
          ],
          [
           "@ChronAVT ummm, the blog says 'with Simon Stehr faking 7th'...I'll expect an investigation forthwith. This is an #outrage",
           0.688
          ],
          [
           "#Taurus will react angrily when she can't take being provoked any longer.",
           0.438
          ],
          [
           "Don't get #bitter get #BETTER",
           0.312
          ],
          [
           "@CrayonToCrayon @SueScoby \\nIt's always fun to anger 'All the Old Dudes.' with Rock N' Roll :))",
           0.354
          ],
          [
           "@cburt43 turn that frown upside down",
           0.125
          ],
          [
           "@OstinOng YUUUHH  plus clin ep and prevmed ugghhh hahaha ",
           0.438
          ],
          [
           "@sarah_urbina why do you even beef Sara you let the anger get the best of you, you and Sagin been friends for how long?",
           0.479
          ],
          [
           "@thatomahapa the best revenge is to get yourself a good woman and move on. Leave her and her hairline to figure themselves out alone",
           0.438
          ],
          [
           "@DeltaDomain @SawDraze @qurions dis dat nigga from fume right?",
           0.417
          ],
          [
           "What the fuck am I supposed to do with no lunch, no dinner, no money and I'm off to work #furious #hangry #day5",
           0.729
          ],
          [
           "@firstleeds not only are your buses unreliable your e ticket app is too unable to get on two buses and late for work #fuming #useless reply",
           0.864
          ],
          [
           "Your twitter picture just makes me fume.",
           0.729
          ],
          [
           "Worst juror ever? Michelle. You were Nicole's biggest threat.  #bb18",
           0.562
          ],
          [
           "@Lexual__ @jdspielman10 RIP to the 100s of black men,, women,CHILDREN killed in Chicago. Where is the outrage?",
           0.562
          ],
          [
           "testing #angry",
           0.667
          ],
          [
           "I believe women are more fiery because once a month they go through struggle and struggle is what develops a strong character.",
           0.417
          ],
          [
           "@Casper10666 I assure you there is no laughter, but increasing anger at the costs, and arrogance of Westminster.",
           0.604
          ],
          [
           "@dcexaminer Democrats and their voters have zero tolerance for honesty. They associate honesty with anger and hate.",
           0.667
          ],
          [
           "@snowangel415 @cjwalters66 Maybe also being attacked by Tom's rabid fans to whom he &amp; his clothes were always perfect also put me off him...",
           0.646
          ],
          [
           "Cheap pout my brodcast",
           0.232
          ],
          [
           "@LynneGarrison yeah, I've only seen that floated online as a theory, it was probably made up by a bitter stan. I ignore pets v vets crap too",
           0.562
          ],
          [
           "@VodafoneUKhelp @VodafoneUK wow!! My bill is 44.77 and hav a text from u to prove that and you have taken 148!!!!! #swines  #con!",
           0.646
          ],
          [
           "Did we miss the fact that #BurkeRamsey swung &amp;hit his sister #JonBenet in the face with a golf club previously out of a fit of #anger?",
           0.598
          ],
          [
           "Some moving clips on youtube tonight of the vigil held at Tulsa Metropolitan Baptist church for #TerenceCruther #justice  #sadness",
           0.438
          ],
          [
           "I wish the next madden has a story mode too. Just like Fifa 17 #madden",
           0.312
          ],
          [
           "@cineworld 'Congratulations your Free 1 month has been activated' Then charges 34.80 the same month. Absolutely furious ",
           0.667
          ],
          [
           "srry my feelings offend u ",
           0.354
          ],
          [
           "@xandraaa5 @amayaallyn6 shut up hashtags are cool ",
           0.438
          ],
          [
           "Taking a break from the #wedding to #rage at the general #stupidity of certain #people on the #internet.",
           0.625
          ],
          [
           "@TheDTSB @trubble1127 @nflnetwork I agree but our offense was ass after the second half td score on the first drive",
           0.417
          ],
          [
           "@TheOneSoleShoe that is one thing but attacking and hating is worse - that makes us just like the angry vengeful behavior we detest",
           0.583
          ],
          [
           "Sorry guys I have absolutely no idea what time i'll be on cam tomorrow but will keep you posted. #fuming",
           0.417
          ],
          [
           "Is it me, or is Ding wearing the look of a man who's just found his arch enemy in bed with his missus? #angryman ",
           0.557
          ],
          [
           "Ok scrubbed hands 5 times before trying to put them in.\\nEyeballs #burning \\n#EvenMoreBlind accidentally scared the #cat whilst #screeching",
           0.604
          ],
          [
           "Is it me, or is Ding wearing the look of a man who's just found his arch enemy in bed with his missus? #angryman #scowl",
           0.5
          ],
          [
           "@ArcticFantasy I would have almost took offense to this if I actually snapped you",
           0.458
          ],
          [
           "You're so thirsty for the chance to disagree w/ the left, that you don't even realize when something is an affront to your bigoted platform.",
           0.5
          ],
          [
           "Having a baby born too soon is #lifechanging 6 years on and it feels like only yesterday #sad #happy #angry #emotionalrollercoaster",
           0.375
          ],
          [
           "i live and die for mchanzo honeymoon crashing and burning the second they move in together",
           0.479
          ],
          [
           "Why to have vanity sizes?Now sizes S,XS(evenXXS sometimes) are too big, WTF?! Dear corporate jerks, Lithuania didn't need this. #rant ",
           0.518
          ],
          [
           "@RevTrevK @Wolfman93011 @Daraidernation @EROCKhd Take 2k out of it the numbers on madden are low and have dropped and people are unhappy",
           0.586
          ]
         ],
         "hovertemplate": "emotion=anger<br>UMAP1=%{x}<br>UMAP2=%{y}<br>UMAP3=%{z}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "anger",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "anger",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": {
          "bdata": "Egw9Pxx1DT6cf0k/KDuwvikcZr2CNwRAae9cP8LBDj6bJGg/Ti+QP9p1jD+/jxVAvAlfP5STxD4DgI8/KuEMPz4WUD+5R7m+Blg6P212Zr4/hc2+fHxJPyxCgD8sgAc/KwsOPylE+z3U4BxA5AQCP7Bshb6/T5Y9iRMLv6vjQ7/hNF6+TDbwPvsauz9HDK8+yak1v6j50D4/glI/e/vVPhTcmz9QM/0+BuUZPxqHiD4RMgZAHH/KP+vu5D1WnEK/",
          "dtype": "f4"
         },
         "y": {
          "bdata": "3fsaQU0kIUFcwt1AUoETQTw5KUE/EQNBn5gDQYCDHUGDDxlBBvYGQcmyGUG5AwBBQSntQMojCEE1hQFBJdYNQRbJFUHYuSZB91ERQeFwDEGn6xNBMBIZQRvmFkEIBx9BcUwYQZ4YCkGp2BRBpQMIQdNzJ0FTaQ9B1gANQUSXBkH3hSdBj2n4QM6XFkH0iBpB21wOQeEEFUEhOwxB7hoVQZ3v4kCX7xJB8oj9QEsRGUGTOe5A9HP4QGqtIEEcIwlB",
          "dtype": "f4"
         },
         "z": {
          "bdata": "dBkCQednAkEswBBBaH8bQfgbCUHJJgdBrmMFQX0kBkFRGPtAuEP7QLPH/0DfDgFB4i0KQUGx80Aro/JAV6H3QPoG9ECPWwhBWj8CQaRVDUE4IhpBcuj3QNTc+0BlswVBA0UJQXLfAUHjcvdAjDMDQXhXB0GhXQBBTiwYQahRBkGyhgRBVYb4QJof+UAZuv1An/sJQZ/cBEH49vFA+9H0QHKJEUHXevhAYMD5QPTlFEEMUBFB+NX/QC9B/0DZyQlB",
          "dtype": "f4"
         }
        },
        {
         "customdata": [
          [
           "I'm afraid she's the goat you libeling people?  #goat #libeling",
           0.562
          ],
          [
           "Nawaz Sharif's UN should start #__ as after all his #UNGA speech has awaken the world about their role in sponsoring #terrorism",
           0.685
          ],
          [
           "jesus ok an alarming percentage of my teachers ths year dont have a  s ingle thoughtful bone in their bodies . its gonna b an interesting yr",
           0.565
          ],
          [
           "@leeuwlion 'The furries are restless tonight'.",
           0.438
          ],
          [
           "@StephenKing\\n\\nStephen King never once spoke out about how the Left crushes #FreeSpeech in publishing world.\\n\\n#Trump #horror #scifi #ccot #p2",
           0.542
          ],
          [
           "Follow this amazing Australian author @KristyBerridge #fiction #horror #zombies #angels #demons #vampires #werewolves #follow #authorlove",
           0.396
          ],
          [
           "After Nawaz Sharif's speech on terrorism, Kejriwal is expected to talk on Governance.",
           0.28
          ],
          [
           "Some questions you get on Twitter make you want to despair. We've been so battered. We complain but aren't convinced things could be better.",
           0.66
          ],
          [
           "#Charlotte's #young &amp; #restless; I applaud ur fire bt always b respectful of authority, police, elders, parents. Violence, not the way ",
           0.438
          ],
          [
           "Now #India is #afraid of #bad .",
           0.562
          ],
          [
           "@mikebairdMP @AndrewConstance @nswtaxi how many sex cases u need before u guys learn UBER is shocking to the consumer unregulated",
           0.646
          ],
          [
           "@tchop__StL @YouTube \\nI get sick to my stomach everytime I see this video &amp; for the helicopter crew to make such comments is revolting.",
           0.875
          ],
          [
           "@DiscordianKitty He has charisma? I guess, if you like people who looked coked out and speak as if they're a school bully?",
           0.458
          ],
          [
           "@DemPhillyEagles @StonedPhillyFan @CraigfromCincy don't ever compare those scrubs to ben..he'll shake off your whole DL and throw a td #7",
           0.188
          ],
          [
           "Thought I left that part of life behind me\\nIt's back to haunt every girl that loves me",
           0.521
          ],
          [
           "... in the same speech.  However he did mention foreign hand and funding in terrorism in the country. \\n#ProudOfYouPrimeMinister",
           0.417
          ],
          [
           "Anyyyyone wanna go to fright fest with me on Friday night? ",
           0.354
          ],
          [
           "#COINCIDENCE??? When you turn on the TV, etc.&amp; listen &amp; watch, the objective is to #CaptureYourMind with #fear &amp; #depression. #FindGODNow!!!",
           0.542
          ],
          [
           "@Gibberman10 @ScottHoward42 any of y'all remember when MLB tried a futuristic jersey those were all ",
           0.24
          ],
          [
           "Sounds like Donald Trump has spent today just making extra, extra sure he'd get those frightened white, conservative, racist votes.",
           0.625
          ],
          [
           "Rojo is a terrible defender",
           0.375
          ],
          [
           "@SherriEShepherd because #whitepeople are #afraid of large #blackmen?",
           0.646
          ],
          [
           "@Tik115 Issue with that is, will the effort involved get back the amount I put into it? That's what I'm fearful of.",
           0.708
          ],
          [
           "I start work tmrw yall, i'm nervous lol",
           0.854
          ],
          [
           "Howl at the moon with @HorrorSociety at @FatCatChicago next Wednesday the 28th for a FREE double feature of SILVER BULLET and CURSED #horror",
           0.333
          ],
          [
           "That old lady is cray cray #scared #BellaIsSoCute #awe #Empire",
           0.574
          ],
          [
           "@datboyJuniorE lool soon as man start loosing weight.  Its panic",
           0.604
          ],
          [
           "#panic Panic attack from fear of starting new medication",
           0.917
          ],
          [
           "Not setting an alarm to nap &gt;&gt;",
           0.16
          ],
          [
           "@1NatalieMaines Can you imagine being the person who has to spray tan him? #shudder",
           0.491
          ],
          [
           "@AOLUK @JamesHayr @TheDrum Anychance of addressing the communication I sent to you yesterday??? I still haven't had any contact ",
           0.312
          ],
          [
           "Tired of people pretending Islam isn't one of the most misogynistic religions, it's no coincidence Muslim countries are terrible for women.",
           0.66
          ],
          [
           "@BossUpJaee but your pussy was weak from what I heard so stfu up to me bitch . You got to threaten him that your pregnant .",
           0.396
          ],
          [
           "81' Goal scorer Vidar Kjartansson comes off in favor of Dor Micha! Another terrific performance by @Vidarkjartans #YallaMaccabi",
           0.229
          ],
          [
           "@CBCNews Canada should be a driving force of democracy freedom rights - instead we help #dictator #misogyny #Sharia #Islam  #polygamy",
           0.625
          ],
          [
           "@eclecticbrotha Thanks, big bro. It's shake and bake and you helped.",
           0.184
          ],
          [
           "@AHSFX thanks Ryan &amp; Brad for scary the shit out of us in the first episode. Don't think my heart will make it through the s6 #horrific",
           0.875
          ],
          [
           "That last minute was like watching a horror show #GBBO ",
           0.5
          ],
          [
           "Can't believe how nervous I feel tonight...who feels the same #mufc",
           0.812
          ],
          [
           "@Greener105th so you are astounded that I respect blacks to vote like any other human? u talk so down towards them. What bigotry on display!",
           0.521
          ],
          [
           "Huns are like a box of coffee revels ",
           0.229
          ],
          [
           "@Policy_Exchange A plus point, she won't have to queue for the loos. Any more plus points? Nope, can't think of any  #sexism",
           0.438
          ],
          [
           "This week's Massacre Theatre pert by @LarsenOnFilm is the first one I can think of that requires subtitles. ",
           0.245
          ],
          [
           "not only was that the worst @EGX that's I've attended but worth one of the worst cons I've been to in the last 5 years #terrible",
           0.583
          ],
          [
           "How is that in 2016, a 757 airplane does not have WiFi...ridiculous. #AmericanAirlines #americanairlinessucks #AATeam ",
           0.292
          ],
          [
           "#Trump is #afraid of the big, bad #Hillary. #election #PresidentialDebate #PresidentialElection2016 #orangehitler #skip #hide #coward #fear",
           0.531
          ],
          [
           "And here we go again  #restless",
           0.667
          ],
          [
           "How can America be so openly embracing racism. #dismayed",
           0.604
          ],
          [
           "#BB18 Michelle crying  again #shocking #bitter He's  just not that into you #TeamNicole",
           0.521
          ],
          [
           "@iSmashFizzle that's me all the time. I carry ginger candy, peppermint oil and sea-bands at all times ",
           0.354
          ],
          [
           "Your boy' is having a nightmare @VivaLaSergio",
           0.646
          ],
          [
           "Whatt a trailerrrr !!! @karanjohar @AnushkaSharma #RanbirKapoor #AishwaryaRaiBachchan i am COMPLETELY BLOWN !!  #longingformore",
           0.354
          ],
          [
           "Thanks for ripping me off again #Luthansa 400 not enough for a one way flight to man from Frk then 30 for a bag then free at gate #awful",
           0.521
          ],
          [
           "It really is amazing the money they give to some of these QB's #nfl #texans #brock #terrible",
           0.246
          ],
          [
           "#twitter #users Tweeting on twitter is like playing a game against the computer. Where's the life, Everyone too #afraid to say something?",
           0.521
          ],
          [
           "Staff on @ryainair FR1005. Asked for info and told to look online. You get what you pay for. #Ryanair @STN_Airport #Compensation #awful",
           0.271
          ],
          [
           "@soozclifford Sure have... Sydney are too tough, too quick and their 'team' pressure is too much for the Cats to handle. Motlop/Cowan #timid",
           0.34
          ],
          [
           "Tweeting from the sporadic wifi on the tube ",
           0.292
          ],
          [
           "We can easily #forgive a #child who is #afraid of the #dark; the real #tragedy of #life is when #men are #afraid of the #light.Plato",
           0.375
          ],
          [
           "It really is amazing the money they give to some of these QB's #nfl #texans #brock ",
           0.3
          ],
          [
           "@stephenfhayes Mustard gas = hostile work environment, not #terrorism; call #OSHA not #military",
           0.708
          ],
          [
           "Having a terrific Tuesday? Crush it today with the Power of 4. Treat your internet like Pizza =D \\n#PowerOf4",
           0.25
          ],
          [
           "There goes the butterflies in my stomach. #nervous #anxietyproblems",
           0.812
          ],
          [
           "If i start growing out my mustache now, I can be Pablo Escobar for Halloween!!!",
           0.25
          ]
         ],
         "hovertemplate": "emotion=fear<br>UMAP1=%{x}<br>UMAP2=%{y}<br>UMAP3=%{z}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "fear",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "fear",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": {
          "bdata": "qAmRPvsLqz+U2SQ/YGSEP3IvMz+QBSNA+BSoP6oZwT6jIwa/3wFZPpUdkD2aKQ2/aad6Pvc2Sr9ANUE/tGWdP5w6rz+CQQ8/1+Anv+0PA73AkBa/7v8oPTiUaz95nRU/8eGdP0qPZj5hmJ0+ldyoPv5KsD/UbEK+sbcgvjttgT4cp4K95jYYQFn4Jj8ZzhFAh/Z4Pm1vhj3gEZg+bfoqvfu8rz9LJhM/m2yIPw4gD78m8PW+QgZOPt9G6D5om++7A2IFvkUttD86fhe9teM8QISX8r7GPXS/oGzIPnlK7L7QCno+HKM9P6RbzDxizma/N9EzP30OQkB4+78+a5HKPw==",
          "dtype": "f4"
         },
         "y": {
          "bdata": "PE8JQanAFkHpq+RAXjMIQUwTF0HJeg5Bd38WQe+ZA0HV8RBBTjYMQRdFIkHrew5B5ywIQZt5DkF7leJAulwYQXK8/EBoUwpBVo8HQY6uFkG+kBVBPx0QQVeJ50D5AOlA2FMEQcfjAEEJ5/JAeizvQB2b2EBnlf9AsW4nQQF9HUHFvhNB6cYKQQK0HUEmqQNBnjT8QIkc+kDM1e9AWtcXQVEPDEFAhR5B0+QMQSb2IkH7SyVBK2gOQZzC40DdyRdBRaoGQS6e/UAP8vdAT/sAQUSiJUFylBBBGfoIQSusJ0F7JAVB+EoNQe8iDUFPrQ1BshgWQXWxAUEzY+1Ai/3/QA==",
          "dtype": "f4"
         },
         "z": {
          "bdata": "aTUhQZu6HUGslBZBOwMIQf7BFkFTBPxA2igeQeLRCkFnthpBQsojQYy7EUEBfBVBGTMBQTAiCEEyCQpB4+4bQYx+GEFoEhpBNVAFQUlrG0HAlgVBjEwfQXv/FEHcTR5BEj8ZQVh2IEGpXxdBybsfQXuMCUHHHxlBeeYJQdP6F0FZzQ1BY/gJQVvDGUHmlQdBmawgQdUsH0Ge+R9BPzwYQVuwBkFzABVBFUINQV/bBUEliwlBNfEiQbOnDUFuOh1B11YMQZ9ED0E/DBhB84YKQQeDBkFcIwhBoHwVQdy2CEEpShNBq6gQQai4JEGTQQdBgLkZQbQSAkF0jh5BNUwbQQ==",
          "dtype": "f4"
         }
        },
        {
         "customdata": [
          [
           "@smoothkobra after such a heavy 2 days this has given much needed levity. Thanks bro",
           0.438
          ],
          [
           "Good morning joyful people. Choose happiness to have a great day today #morning #joyful #happiness #grandmercurejktkemayoran",
           0.833
          ],
          [
           "Oh dear an evening of absolute hilarity I don't think I have laughed so much in a long time! ",
           0.958
          ],
          [
           "@CazuaL_WeaR @ScottInSC looks like a book shaped like a gun to me #optimism #itsagunalright",
           0.408
          ],
          [
           "Knowing how to cook is invaluable, what's even better is that even in a 400 sq ft place, I have wide and hearty homestyle egg noodles.",
           0.562
          ],
          [
           "Thinking about trying some comedy on youtube. Always been fond of it. Time to nut up. #laughter #comedy #maybeoneday #hopefullyfunny #LOL",
           0.646
          ],
          [
           "It's the #FirstDayofFall and I'm so happy. Sipping my #PumpkinSpice flavored coffee and #smiling! Happy Fall everyone! #amwriting",
           0.86
          ],
          [
           "Lmboo , using my nephew for meme #hilarious",
           0.654
          ],
          [
           "#hate going to the doctor on so many levels but least I can go sleep with a #smile just watched #Dwight on live nation",
           0.34
          ],
          [
           "myself that despite the absolute delight my children and I would feel having a kitten in our home, the misery my husband would feel is more.",
           0.327
          ],
          [
           "15 minutes of yoga to your breakfast routine will change your day #preparation #sunriseyoga #bodyawareness #health #yoga  #stretch",
           0.521
          ],
          [
           "Watch this amazing live.ly broadcast by @rosannahill #lively #musically",
           0.56
          ],
          [
           "Today's realisation that it was the last time I watch swimming lesson cos I go back to work next week lead to a joyous bedtime. #worstoneyet",
           0.34
          ],
          [
           "I would like to congratulate the people of Saudi Arabia a happy and a joyous national day. May you all have a great time! #_",
           0.771
          ],
          [
           "She gave a playful wink, taking the goggles off her head, swinging them around her finger. 'I would never~' @VerminEngineer",
           0.534
          ],
          [
           "Twitter is a font of endless hilarity.",
           0.42
          ],
          [
           "@TheSandraGal Glad to see that you're having fun in the sun. Water sports are always fun, challenging, and exhilarating. #happiness #beauty",
           0.796
          ],
          [
           "Wishing a very Happy Birthday to our awesome dancer, Ruthann!!! We hope your day is magical! #bday #happy #eatcake",
           0.75
          ],
          [
           "Watch this amazing live.ly broadcast by @matt.boss #lively #musicallyjh",
           0.479
          ],
          [
           "@DorH84607784 Oh FANTASTIC, I bet it was super exhilarating  ",
           0.84
          ],
          [
           "@Blancalanka96 thought it'd be fun and it is not fun but on the bright side I don't have to fight for parking",
           0.34
          ],
          [
           "her fingers slide along your thighs, caressing the skin before she's leaning down, down, down and the first lick is teasing n playful.",
           0.54
          ],
          [
           "Watch this amazing live.ly broadcast by @hannah..mccloud #lively #musically",
           0.562
          ],
          [
           "When you wake up from a dream laughing at something stupid, and that makes you laugh more #hilarious",
           0.875
          ],
          [
           "@NebulaJoker No, they aren't. Episodes are animated during the week before they air.",
           0.231
          ],
          [
           "@alphavenger all chuck seasons, she had that one bright spot with dan, where she was allowed to be smart and kind //and// fashionable",
           0.189
          ],
          [
           "Watch this amazing live.ly broadcast by @brooke_bridges #lively #musically",
           0.5
          ],
          [
           "@EducatedNPetty white pricks that were laughing at your use of language won't be crying over your coffin but rejoicing that you're another",
           0.25
          ],
          [
           "Do what makes you successful and #happy now and forever",
           0.562
          ],
          [
           "Go follow #beautiful #Snowgang @Amynicolehill12  #Princess #fitness #bodyposi #haircut #smile #Whitegirlwednesday",
           0.604
          ],
          [
           "@MerenthaProphet - the Hunter in this way, content and joyous in simple, domestic bliss? I cannot wait for word of who you truly are to -",
           0.349
          ],
          [
           "It's not that the man did not know how to juggle, he just didn't have the balls to do it. \\n#funny #pun #punny #lol #hilarious",
           0.519
          ],
          [
           "@KWAYNTjoia it's exhilarating",
           0.583
          ],
          [
           "Morning all! Of course it is sunny on this Monday morning to cheerfully welcome us back to work.:)",
           0.863
          ],
          [
           "@FlannelJedi This is why I drink and watch You're the Worst as a way to cheer myself up.",
           0.292
          ],
          [
           "If you have the ability to make someone happy or to make someone #smile, do it! The world needs more of that right about now. #CreateLove ",
           0.66
          ],
          [
           "@hesham786 that's the spirit ",
           0.354
          ],
          [
           "Nawaz Sharif is getting more funnier than @kapilsharmak9 day by day. #laughter #challenge #kashmir #baloch",
           0.7
          ],
          [
           "@bruins_514 @gorddownie @thehipdotcom It would be #TragicallyHip if they can #help @TOYSFORASMILE make #hospitalized  #sick #kids #smile ",
           0.519
          ],
          [
           "@Gronnhair @buryprofs @DittoBistro it was indeed lovely and the team were incredibly attentive and on the ball. Cheese was a lively gesture!",
           0.646
          ],
          [
           "@diehimbeertonis She developed her 'forced smile'. I can force myself to describe it 'a little hearty maybe, sanki biraz':)",
           0.208
          ],
          [
           "@harrietemmett great minds think alike. ",
           0.479
          ],
          [
           "A cheerful heart is good medicine, but a broken spirit saps a person's strength.' {Proverbs 17:22} #WednesdayWisdom",
           0.292
          ],
          [
           "@Bridget_Jones was joyous. Worried I would be disappointed. Most definitely was not. #chickflick #giggles #comethefuckonbridget",
           0.68
          ],
          [
           "If you don't respond to an email within 7 fays, you wifl be killed by an animated gif of the girl from The Ring.",
           0.18
          ]
         ],
         "hovertemplate": "emotion=joy<br>UMAP1=%{x}<br>UMAP2=%{y}<br>UMAP3=%{z}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "joy",
         "marker": {
          "color": "#00cc96",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "joy",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": {
          "bdata": "YMgZQIJxTUA9kiZAMAvqP04lPEDM/wNAW1RTQIOwFkCCxfA/wQWwP9+YTkD7iTFASjgJQNo0UEA1x7Q/hPANQOuFTEA7Pk9AfrYoQDUpPUBkga4/O2HOP/mDL0ALmRRALQQ4P1bk8z+luCdAIXctvGwWPkBR9DNACa3rP8pnBUBo9C9ArGRaQE8T3T9y1TBAdxYVQEsn4z+Ry2Y/Keg6QKetpz+e2QFACgsdQEJ2NUA4UiI/",
          "dtype": "f4"
         },
         "y": {
          "bdata": "6OcCQdhG+UAatAJByFIHQaU190BUrgNBa5rzQLm8BEEt0PpAsmnbQByb70CbnBNBlVXvQMQj/EAf8ORA2ZoGQWNpAEFD8gFBr5kUQU4GA0GSSepAowbiQLCsFEGtyANBO/QGQTcn/0CHjhVBeC8VQXEQ/UCj7QpB8LzuQNUwBkHBGftAqoX0QJPP+kCpoPhAsiEEQb7OEUFB9+FAwVwDQTTH30ABfAVBjZj6QELYAUFi0QVB",
          "dtype": "f4"
         },
         "z": {
          "bdata": "gmkNQY3H9UCaDRRBEE8KQVW+AkHZkBtBGmz8QE4QGUHvnA1BhHQJQSjD9kAkS/VAqc4QQad890AmV+5Aci4XQfEr90BQUfZAG+r3QPxLCUHA1w5BIJbvQM1X90DQFBpBVZH7QP+k+EBWt/VAro8TQSUm+kDgqPZA4gT4QP73HUGEmQZB1lj3QHBlBUGqS/ZAHsgHQXwdHUHOOf5A03UNQU2B+UAReglBwRv3QD5hEkFqrB9B",
          "dtype": "f4"
         }
        },
        {
         "customdata": [
          [
           "Marcus Roho is dreadful",
           0.521
          ],
          [
           "@A_RockasThe U.S. has added years to the Syrian conflict by arming the 'rebel' army. You would think that Iraq had sunk in with Kerry.",
           0.417
          ],
          [
           "My nephew sees that i have a frown on my face and he tells me 'you're  beautiful '!",
           0.542
          ],
          [
           "@ticcikasie1 With a frown, she let's out a distraught 'Gardevoir' saying that she wishes she had a trainer",
           0.479
          ],
          [
           "Just put the winter duvet on  #serious",
           0.312
          ],
          [
           "One step forward, two steps backward, the link to RogerFedererShop doesnt work. I am losing hope about Roger Federer new Website #sadness",
           0.583
          ],
          [
           "@LondonMidland #dobetter only two carriages on 14:49 Birmingham to Hereford no room to stand anymore Friday commute #unhappy",
           0.542
          ],
          [
           "@StarklyDark 'Come here. Come on. Into my arms. I'm not going anywhere, Tony, I swear.' Steve told him, quiet and solemn.",
           0.5
          ],
          [
           "Damn gud #premiere #LethalWeapon...#funny and ",
           0.229
          ],
          [
           "@msfang they say you attract what you see, maybe I shouldn't be a pessimist but I don't wanna take any chances lol can't wait to relocate",
           0.333
          ],
          [
           "And there is despair underneath each and every action \\nEach and every attempt to pierce the armour of numbness ' -Mgla",
           0.583
          ],
          [
           "@xBFDR yeah I'm sure it will, it's just so depressing having to talk to my parents over the phone instead of talking to them downstairs",
           0.833
          ],
          [
           "I'll just have to #eat my way to #sobriety. This'll be a hell of a journey back to #sober",
           0.625
          ],
          [
           "Shoutout to the drunk man on the bus who pissed in a bottle and on the seats ",
           0.436
          ],
          [
           "@TDYLN sadly not :(",
           0.667
          ],
          [
           "@VivYau is it all doom and gloom? I only want to hear lovely things about airbnb!",
           0.458
          ],
          [
           "Im kind of confused.  The one thing i do right now has a great future, but on the other hand so does the new thing .  #needhelp",
           0.521
          ],
          [
           "@ImpugnValkyrie *I frown and cup your cheeks in my hands after you step aside.* Angela I care about you. And I don't know how else I can -",
           0.604
          ],
          [
           "Good morning chirpy #SpringEquinox and your pensive sister #AutumnEquinox A perfect day however it is expressed  #theBeautyofBalance",
           0.167
          ],
          [
           "I got a short fuse when im sober.",
           0.312
          ],
          [
           "The Sorrow is grim reminder of how bad I can be at video games and how I could get a bit too trigger happy at times. RIP #MGS3",
           0.604
          ],
          [
           "@wabermes The @RavalliRepublic had a good one but then the reporter quit. #sad",
           0.708
          ],
          [
           "I keep feeling the heaviness on my left hand and look down and I am in awe every single time  #notusedtoit #imafiance #wut",
           0.208
          ],
          [
           "Sky news still pushing the Brexit gloom line, managing to ignore the fact it's simply not happening. 'But in the future.....'",
           0.396
          ],
          [
           "I don't know why everyone is pretending to be sad about angelina and brad, everyone knows his dumb ass should've stayed with jennifer.",
           0.354
          ],
          [
           "@10carley what a sulky pants!",
           0.396
          ],
          [
           "I miss when social media was a place to get laughs off and jump in DMs lol..... shit is depressing now ",
           0.792
          ],
          [
           "-- used as a pawn in this red woman's game] For now, try not to fret and act as if nothing is amiss. This is a royal -- @TheLadyOfGlenco",
           0.354
          ],
          [
           "@SkyNews err I wasnt gloomy.  17.2 mio people were not gloomy only #remain were #Brexit",
           0.458
          ],
          [
           "@Courteoussoul @MattyMcDee I'm at 349 and just decoded 20 or more blues and not one was over 340, where you getting your blues?",
           0.333
          ],
          [
           "Regret for the things we did can be tempered by time; it is regret for the things we did not do that is inconsolable. - Sydney J. Harris",
           0.354
          ],
          [
           "Unmatched Party Specialist /co @T3RevNeverEnd #serious #job #titles",
           0.208
          ],
          [
           "There's many things I don't care about, and many things I do that I don't speak on because it's such a heaviness even when released...",
           0.625
          ],
          [
           "If anybody needs me I'll be drowning my blues in a sea of whiskey ",
           0.75
          ],
          [
           "You don't know how to love me when you're sober #sober #selenagomez #revival",
           0.458
          ],
          [
           "Stars, when you shine,\\nYou know how I feel.\\nScent of the pine, \\nYou know how I feel.\\nFreedom is mine,\\nI know how I feel.\\nI'm feelin' good.",
           0.292
          ],
          [
           "yesterday i finished watching penny dreadful and from all the beautiful things i saw one question remains: were the writers HIM's fans?",
           0.312
          ],
          [
           "This shit hurting my heart  that's how serious it is .",
           0.875
          ],
          [
           "@Barcabhoy1 Of course not. Didn't sink his studs into a knee like Forrester",
           0.396
          ],
          [
           "[ @HedgehogDylan ] *she would frown a bit, folding her arms* 'why is it that every time I'm in need of assistance someone expects a lil **",
           0.562
          ],
          [
           "I'd rather laugh with the rarest genius, in beautiful alliance with his own being, where he kept his sadness. #melancholy",
           0.688
          ],
          [
           "@pmo100 @5liveSport .....I heard talk something is a miss. He looks weary.",
           0.458
          ],
          [
           "Soooo badly want to dye my hair dark but have never been dark before soooo torn ",
           0.5
          ]
         ],
         "hovertemplate": "emotion=sadness<br>UMAP1=%{x}<br>UMAP2=%{y}<br>UMAP3=%{z}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "sadness",
         "marker": {
          "color": "#ab63fa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "sadness",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": {
          "bdata": "xy4ov/DWhz9xihtAlyWFP0S82j8o75s+2n/BvrFKrD91ASdAVjDJP20KNz9EBhE/gkKoPxjzAT+Jsj0/cytAQJo7gj/VO6g/Qt1VQOmCgT+XVpI+/gqHPgRiH0CP1Tk/PrFCPldGDz+3MxM/gPypPzEDWT8aQGI/grmAPhuH+T+M2Vk/2FSdP9EHqz/twkFA/ywUP3kEAD/vfiQ9lOaSP96nnj8/Doo96WxmPw==",
          "dtype": "f4"
         },
         "y": {
          "bdata": "IQoWQRcWG0HhQOtAn0vfQDEu4UARQutA/KUoQfAT6EBT0QJBCXn2QHqL4UDKW/BA0c8GQdDYEUHQb+dAB+oDQVhM40BBkuVAt+XuQGXtD0G1OOxAYrrvQNoP70BRPCFBmCwVQcsdDkF0S/VAz+zsQGYoH0E4ufRAQ/bwQDp27UD4h9lABA72QLDeBkG1LfZAWCsBQQPK3kCDxg9BuVTjQBaS2kDvFAFByUPlQA==",
          "dtype": "f4"
         },
         "z": {
          "bdata": "KRsGQWEAGkH8zQVB0jr3QAMpC0GzkwVBjfkLQTev9kA6HBVBkjYRQY3NBEHfDgZB85j9QD0uDUEC1wNBtSkJQfgIGkH9gu9Ak3f5QLUG9EDqrfxAQPIGQV9mCUGKNBBBhSoIQXqRAUGsxQ1BpQ/sQFy0EEEhCgVBTCz8QKPmCEGxlwhBGZwFQTf++UA9qQJBCAscQYljD0GwLwJBsejvQGOVBkHW4ghBkZgaQQ==",
          "dtype": "f4"
         }
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "emotion"
         },
         "tracegroupgap": 0
        },
        "scene": {
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "xaxis": {
          "title": {
           "text": "UMAP1"
          }
         },
         "yaxis": {
          "title": {
           "text": "UMAP2"
          }
         },
         "zaxis": {
          "title": {
           "text": "UMAP3"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "3D UMAP Projection of Text Embeddings"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Answer here\n",
    "reducer_3d = umap.UMAP(n_components=3, metric='cosine', random_state=28)\n",
    "embedding_3d = reducer_3d.fit_transform(X_embeddings)\n",
    "\n",
    "df_plot_3d = pd.DataFrame(embedding_3d, columns=['UMAP1', 'UMAP2', 'UMAP3'])\n",
    "df_plot_3d['emotion'] = combined_df['emotion']\n",
    "df_plot_3d['intensity'] = combined_df['intensity']\n",
    "df_plot_3d['text'] = combined_df['text']\n",
    "\n",
    "fig_3d = px.scatter_3d(\n",
    "    df_plot_3d,\n",
    "    x='UMAP1',\n",
    "    y='UMAP2',\n",
    "    z='UMAP3',\n",
    "    color='emotion',\n",
    "    hover_data=['text', 'intensity'],\n",
    "    title='3D UMAP Projection of Text Embeddings'\n",
    ")\n",
    "\n",
    "fig_3d.write_image(\"results/umap3d.png\")\n",
    "fig_3d.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Umap3D](results/umap3d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Similarities**\n",
    "\n",
    "Both the 2D and 3D UMAP projections are computed from the same set of embeddings, so the overall cluster structure remains similar, points with the same emotion tend to group together, and the relative positions between different emotion clusters are broadly preserved.\n",
    "\n",
    "### **Differences**\n",
    "\n",
    "3D making certain boundaries between emotions clearer. This happens because 3D preserves slightly more of the original high-dimensional structure.\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "Both the 2D and 3D UMAP projections preserve the main clustering structure of the original embeddings, so emotion categories remain grouped in similar patterns across both views. However, points that overlap or appear compressed in 2D often become more separable along the third axis in 3D, revealing clearer boundaries between some emotions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_9_'></a>[**2.5 Retrieval-Augmented Generation (RAG)**](#toc0_)\n",
    "\n",
    "`NOTE: This whole section including the exercise is now considered a bonus section, not counted for the main grade.`\n",
    "\n",
    "RAG (Retrieval-Augmented Generation) is a technique where a language model combines document retrieval with text generation. In RAG, a retrieval system first finds relevant documents or text chunks, and then the language model uses this retrieved information to generate a more informed and accurate response. This method enhances the model's ability to answer questions by grounding its responses in real, external data.\n",
    "\n",
    "In the following code, we will load a webpage as a document, which allows us to retrieve text from a URL. After loading the content, we will split the document into smaller, manageable chunks, making it easier for our model to process. Then, we'll generate embeddings for these chunks with a specified LLM model (Gemini Embedding Model). These embeddings will be stored in a vector database, which enables us to perform similarity searches. By setting up this retrieval system, we can use a RAG chain to answer questions. The retriever finds relevant text chunks from the document based on a query, and the LLM generates a response by incorporating this retrieved information, making the answers more grounded and accurate.\n",
    "\n",
    "In this example we use the library langchain, for documentation on more functions of the library you can check the following link: [LangChain Tutorials](https://python.langchain.com/docs/tutorials/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "# Function to load, split, and retrieve documents\n",
    "def load_and_retrieve_docs(url):\n",
    "    loader = WebBaseLoader(\n",
    "        web_paths=(url,),\n",
    "        bs_kwargs=dict() \n",
    "    ) \n",
    "    docs = loader.load() #We will load the URL that will serve as our data source\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150) #We will divide the URL in chunks of text for easier comparison in the vector space\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    #print(splits) #You can print this to see how the chunks in the url where split\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
    "    vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings) #Our vector space for comparison\n",
    "    return vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs) #Format the retrieved docs in an orderly manner for prompting\n",
    "\n",
    "# Define the Gemini LLM function\n",
    "def gemini_llm(question, context):\n",
    "    system_prompt = \"You are a RAG Agent that needs to provide a well structured answer based on the provided question and context.\"\n",
    "    formatted_prompt = f\"Question: {question}\\n\\nContext: {context}\"\n",
    "    response, logs = prompt_gemini(input_prompt = formatted_prompt, system_instruction = system_prompt, with_tokens_info = True)\n",
    "    print(f\"logs: \\n{logs}\")\n",
    "    # print(f\"Retrieved context: \\n{context}\\n\\n\") # You can print this to observe the retrieved context\n",
    "    return response\n",
    "\n",
    "\n",
    "# Define the RAG chain\n",
    "def rag_chain(question, retriever):\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    formatted_context = format_docs(retrieved_docs)\n",
    "    return gemini_llm(question, formatted_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs: \n",
      "{'model': 'gemini-2.5-flash-lite', 'input_tokens': 726, 'output_tokens': 190}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The key challenges in realizing AGI's full potential stem from its fundamental requirements and the ethical considerations surrounding its development. These include:\n",
       "\n",
       "*   **Learning from Diverse Data:** Unlike narrow AI, which is trained on structured data, AGI needs to learn from a wide variety of unstructured data sources.\n",
       "*   **Computational Power:** The sheer amount of computational resources needed to process and learn from these vast and diverse datasets presents a significant hurdle.\n",
       "*   **Ethical Concerns:** Developing AGI responsibly requires addressing critical ethical issues such as:\n",
       "    *   **Bias and Fairness:** Ensuring algorithms are unbiased and treat everyone equally by training on diverse datasets and continuously monitoring performance.\n",
       "    *   **Privacy:** Prioritizing user data protection through robust privacy measures and transparent data usage policies.\n",
       "    *   **Accountability:** Establishing clear guidelines and legal frameworks to determine responsibility for decisions made by AGI systems and address any harm caused."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url=\"https://qbotica.com/understanding-artificial-general-intelligence-agi-an-in-depth-overview/\"\n",
    "# Create the retriever\n",
    "retriever = load_and_retrieve_docs(url)\n",
    "\n",
    "# Use the RAG chain\n",
    "result = rag_chain(question=\"What are the Key Challenges in Realizing AGIs Full Potential\", retriever=retriever)\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### <a id='toc1_5_9_1_1_'></a>[**Actual answer in the URL:**](#toc0_)\n",
    "\n",
    "![pic11.png](pics/pic11.png)\n",
    "\n",
    "##### <a id='toc1_5_9_1_2_'></a>[**Content in the URL that might get into the generated answer because of similar semantic meaning:**](#toc0_)\n",
    "\n",
    "![pic12.png](pics/pic12.png)\n",
    "\n",
    "source: https://qbotica.com/understanding-artificial-general-intelligence-agi-an-in-depth-overview/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_9_1_3_'></a>[**>>> Bonus Exercise 5 (Take home):**](#toc0_)\n",
    "\n",
    "`NOTE: This exercise is now considered a bonus one, not counted for the main grade, only as extra points.`\n",
    "\n",
    "Your task is to test the RAG system with your own chosen URL and analyze its performance.\n",
    "\n",
    "1. Find a URL of a webpage with interesting text content to test the RAG pipeline.\n",
    "2. Make a question about the content in the webpage you chose.\n",
    "3. Discuss how good the question was answered by the model, if the model missed important information related to your question.\n",
    "4. Display a screenshot of the real answer in the webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs: \n",
      "{'model': 'gemini-2.5-flash-lite', 'input_tokens': 828, 'output_tokens': 69}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The provided text does not contain information about NYCU relocating its earlier campus to the Guangfu site in Hsinchu. It states that the Guangfu Campus is NYCU's main campus and official address, and that the university operates with a dual main campus system, with Guangfu Campus in Hsinchu and Yangming Campus in Taipei."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Answer here\n",
    "url=\"https://en.wikipedia.org/wiki/National_Yang_Ming_Chiao_Tung_University\"\n",
    "# Create the retriever\n",
    "retriever = load_and_retrieve_docs(url)\n",
    "\n",
    "# Use the RAG chain\n",
    "result = rag_chain(question=\"Why did NYCU decide to relocate its earlier campus to the Guangfu site in Hsinchu?\", retriever=retriever)\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Results**\n",
    "\n",
    "The model responded that the document did not mention any information about NYCU relocating its earlier campus to the Guangfu site. However, the source text clearly includes a detailed description of the universitys relocation historyfrom the original Boai Campus, to the consideration of Chengcing Lake in Kaohsiung, and finally to the Weiwuying military base, which later became the Guangfu Campus. The models answer was incorrect, the RAG system failed to retrieve the paragraph containing the relocation history.\n",
    "\n",
    "The likely reason the retriever failed to retrieve the relocation passage is the lack of direct keyword alignment. The question explicitly used the term relocated, but the document never used this word. Instead, the relocation history was described narratively, mentioning Boai Campus, the consideration of Chengcing Lake, and the militarys offer of the Weiwuying site, without explicitly using terms such as relocation, move, or transfer. Because embedding-based retrieval still relies heavily on semantic similarity, the absence of these direct keywords reduced the match score, causing the retriever to overlook the relevant chunk despite the information being present.\n",
    "\n",
    "\n",
    "#### **Actual answer in wiki:**\n",
    "![screenshot](<pics/screenshot.png>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_10_'></a>[**2.6 Few-Shot Prompting Classification:**](#toc0_)\n",
    "\n",
    "Few-shot prompting is a technique where a Large Language Model (LLM) is given a small number of labeled examples within a prompt to guide its classification. This allows the model to perform a new task with minimal data, avoiding the need for extensive fine-tuning.\n",
    "\n",
    "In this lab, we will use the Gemini API to perform zero-shot, 1-shot, and 5-shot emotion classification:\n",
    "\n",
    "*   **Zero-shot:** The model classifies text without any prior examples.\n",
    "*   **1-shot:** The model is given one example for each emotion before classifying.\n",
    "*   **5-shot:** The model is given five examples per emotion for better context.\n",
    "\n",
    "To make our implementation robust and efficient, we are incorporating two key features:\n",
    "\n",
    "1.  **Structured Output:** We provide the Gemini model with a specific output schema (`Emotions` class). This instructs the model to return *only* a valid emotion label (e.g., `joy`), which makes the output predictable and reliable, minimizing errors.\n",
    "2.  **API Rate Handling:** The code includes a function to manage the requests-per-minute limit of the Gemini API.\n",
    "\n",
    "We will test the model's performance on a small sample of 20 texts per emotion to ensure the process runs quickly. If the model provides an invalid response, the code will automatically retry the request until a valid classification is received.\n",
    "\n",
    "**Prompt Structure:**\n",
    "`System Instruction -> Task Description -> Examples (if not zero-shot) -> Text to Classify`\n",
    "\n",
    "\n",
    "<span style=\"color:green\">For the exercises in this section there is no need to re-run the cells, you can use the data that has been saved previously to the corresponding directory.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciton for visualizing confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix',\n",
    "                          cmap=sns.cubehelix_palette(as_cmap=True)):\n",
    "    \"\"\"\n",
    "    This function is modified from: \n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \"\"\"\n",
    "    classes.sort()\n",
    "    tick_marks = np.arange(len(classes))    \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels = classes,\n",
    "           yticklabels = classes,\n",
    "           title = title,\n",
    "           xlabel = 'Predicted label',\n",
    "           ylabel = 'True label')\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    ylim_top = len(classes) - 0.5\n",
    "    plt.ylim([ylim_top, -.5])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import enum\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import time\n",
    "# Define the emotion labels\n",
    "emotions = ['anger', 'fear', 'joy', 'sadness']\n",
    "# Define the model to use for few-shot prompting\n",
    "\n",
    "# Schema for the output, the type enum can be used to make a pool of options if what we want is to classify our text selecting only one of them\n",
    "class Emotions(enum.StrEnum):\n",
    "    ANGER = 'anger'\n",
    "    FEAR = 'fear'\n",
    "    JOY = 'joy'\n",
    "    SADNESS = 'sadness'\n",
    "\n",
    "\n",
    "# Function to handle the rate limits of gemini models\n",
    "def handle_rate_limit(request_count, first_request_time, max_calls_per_min):\n",
    "    current_time = time.time()\n",
    "\n",
    "    # Initialize timer on the first request of a new window\n",
    "    if request_count == 0:\n",
    "        first_request_time = current_time\n",
    "\n",
    "    request_count += 1\n",
    "\n",
    "    # If the rate limit is reached\n",
    "    if request_count > max_calls_per_min:\n",
    "        elapsed_time = current_time - first_request_time\n",
    "        if elapsed_time < 60:\n",
    "            wait_time = 60 - elapsed_time\n",
    "            print(f\"Rate limit of {max_calls_per_min} requests per minute reached. Waiting for {wait_time:.2f} seconds.\")\n",
    "            time.sleep(wait_time)\n",
    "\n",
    "        # Reset for the new window\n",
    "        request_count = 1\n",
    "        first_request_time = time.time()\n",
    "    \n",
    "    return request_count, first_request_time, max_calls_per_min\n",
    "\n",
    "# Function to sample examples per emotion category\n",
    "def sample_few_shots(df, emotions, num_samples=5):\n",
    "    few_shot_examples = {}\n",
    "    for emotion in emotions:\n",
    "        few_shot_examples[emotion] = df[df['emotion'] == emotion].sample(n=num_samples, random_state=42)\n",
    "    return few_shot_examples\n",
    "\n",
    "# Function to build the prompt based on the number of examples (few-shot, 1-shot, zero-shot)\n",
    "def build_prompt(examples, emotions, num_shots=5):\n",
    "    classification_instructions = \"\"\"\n",
    "You will be given a text extracted from social media and your task is to classify the text into one of the following emotion categories: \n",
    "\"anger\" | \"fear\" | \"joy\" | \"sadness\"\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = classification_instructions + \"\\n\\n\"\n",
    "    \n",
    "    if num_shots > 0:\n",
    "        prompt += f\"Examples: \\n\"\n",
    "        for emotion in emotions:\n",
    "            for _, row in examples[emotion].iterrows():\n",
    "                prompt += f\"Text: {row['text']}\\nClass: {emotion}\\n\\n\" #Show the examples in the same format it will be shown for the classification text\n",
    "                if num_shots == 1:  # If 1-shot, break after the first example for each emotion\n",
    "                    break\n",
    "    return prompt\n",
    "\n",
    "# Function to classify using the LLM with retry for incorrect responses\n",
    "def classify_with_llm(test_text, prompt_base, system_prompt, classes, schema):\n",
    "    response = None\n",
    "    while not response or response not in classes:\n",
    "        full_prompt = f\"{prompt_base}\\nClassification:\\nText: {test_text}\\nClass: \" #The classification text will leave the emotion label to be filled in by the LLM\n",
    "        try:\n",
    "            result = prompt_gemini(input_prompt = [full_prompt], schema = schema, system_instruction = system_prompt)\n",
    "            # print(f\"result: {result} \\n\")\n",
    "            # print(f\"type: {type(result)}\")\n",
    "            if not result:\n",
    "                # In case of giving empty responses with temperature 0.0, we set a higher temperature to seek for different responses\n",
    "                result = prompt_gemini(input_prompt = [full_prompt], schema = schema, system_instruction = system_prompt, temperature=1.0)\n",
    "\n",
    "            try:\n",
    "                # If the result is in the correct format it can be parsed using json\n",
    "                response = json.load(result)\n",
    "            except:\n",
    "                # In case it's not in a json friendly format\n",
    "                # Deleting characters \" and ' in case they appear in our response with the class of the text \n",
    "                response = result.replace('\"', '')    \n",
    "                response = response.replace(\"'\", \"\")  \n",
    "\n",
    "                \n",
    "        # except exceptions.ResourceExhausted as e:\n",
    "        except Exception as e:\n",
    "            print(f\"Waiting to retry... Error: {e}\")\n",
    "            time.sleep(15)\n",
    "            print(f\"test_text: {test_text}\")\n",
    "            return classify_with_llm(test_text, prompt_base, system_prompt, classes, schema) # Retry the request\n",
    "\n",
    "\n",
    "        if response not in classes:  # Retry if not a valid response\n",
    "            print(f\"Invalid response: {response}. Asking for reclassification.\")\n",
    "    return response\n",
    "\n",
    "# Main function to run the experiment with the option for zero-shot, 1-shot, or 5-shot prompting\n",
    "def run_experiment(df_train, df_test, num_test_samples=5, num_shots=5):\n",
    "    # Sample examples for few-shot prompting based on num_shots\n",
    "    if num_shots > 0:\n",
    "        few_shot_examples = sample_few_shots(df_train, emotions, num_samples=num_shots) \n",
    "        prompt_base = build_prompt(few_shot_examples, emotions, num_shots=num_shots)\n",
    "    else:\n",
    "        prompt_base = build_prompt(None, emotions, num_shots=0)  # Zero-shot has no examples\n",
    "\n",
    "    # System prompt for our classification model:\n",
    "    system_prompt = \"You are an emotion classification model for text data. Do not give empty responses, classify according to the list of possible classes.\"\n",
    "\n",
    "    # Prepare to classify the test set\n",
    "    results_data = []\n",
    "\n",
    "    print(prompt_base)\n",
    "    # Sample 20 examples per emotion for the test set to classify\n",
    "    test_samples = sample_few_shots(df_test, emotions, num_samples=num_test_samples)\n",
    "\n",
    "    # Variables to handle rate limit of gemini\n",
    "    request_count = 0\n",
    "    max_calls_per_min = 15 # Gemini 2.5 Flash Lite has this maximum set in the documentation\n",
    "    first_request_time = None\n",
    "\n",
    "    # Classify 20 test examples (5 from each category) and save predictions\n",
    "    for emotion in emotions:\n",
    "        for _, test_row in tqdm(test_samples[emotion].iterrows(), desc=f\"Processing samples for emotion: {emotion}...\", total=num_test_samples):\n",
    "            test_text = test_row['text']\n",
    "            request_count, first_request_time, max_calls_per_min = handle_rate_limit(request_count, first_request_time, max_calls_per_min)  # Check and handle rate limit before each API call\n",
    "            predicted_emotion = classify_with_llm(test_text = test_text, prompt_base = prompt_base, system_prompt = system_prompt, classes = emotions, schema = Emotions)\n",
    "            # Append the results data:\n",
    "            results_data.append({\n",
    "                    'text': test_text,\n",
    "                    'true_emotion': emotion,\n",
    "                    'predicted_emotion': predicted_emotion\n",
    "                })\n",
    "\n",
    "    # Create dataframe to save the results data\n",
    "    results_df = pd.DataFrame(results_data)\n",
    "    \n",
    "    # Extract just the true and predicted labels for metrics calculations\n",
    "    true_labels = results_df['true_emotion']\n",
    "    predictions = results_df['predicted_emotion']\n",
    "\n",
    "    output_dir = \"./results/llm_classification_results\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # Save the results\n",
    "    filename = f\"{output_dir}/results_samples_{num_test_samples}_shots_{num_shots}.csv\"\n",
    "    \n",
    "    # Save the DataFrame to CSV\n",
    "    results_df.to_csv(filename, index=False)\n",
    "    print(f\"\\nResults saved to {filename}\")\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(classification_report(y_true=true_labels, y_pred=predictions))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(y_true=true_labels, y_pred=predictions) \n",
    "    my_tags = ['anger', 'fear', 'joy', 'sadness']\n",
    "    plot_confusion_matrix(cm, classes=my_tags, title=f'Confusion matrix for classification with \\n{num_shots}-shot prompting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important: The next part should take around 16 minutes to finish running due to API Rate Limits**\n",
    "\n",
    "**Note:** You might see an `429 RESOURCE_EXHAUSTED` error when running the following code all at once, this is because the `current API Rate Limit handling cannot reliably find out how many requests we have left per minute` from cell to cell, there is no Gemini feature created for it to get the information from their servers. So, `if you don't want to see the error you can just wait 1 minute` after one cell finished processing. But `even if there is an error showing it is fine`, internally in the code `there is a retry that happens every 15 seconds` until we finish processing our sampled data. `The lab is designed to never reach the total rate limit per day quota.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You will be given a text extracted from social media and your task is to classify the text into one of the following emotion categories: \n",
      "\"anger\" | \"fear\" | \"joy\" | \"sadness\"\n",
      "    \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:   5%|         | 1/20 [00:00<00:10,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: [ @HedgehogDylan ] *she would frown a bit, folding her arms* 'why is it that every time I'm in need of assistance someone expects a lil **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:  75%|  | 15/20 [00:25<00:03,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 34.29 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...: 100%|| 20/20 [01:03<00:00,  3.17s/it]\n",
      "Processing samples for emotion: fear...:  40%|      | 8/20 [00:05<00:09,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 11.382914007s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '11s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 11.34385627s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '11s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: If my concerns &amp; anxiety don't matter to you then I shall return the favor. #EyeMatter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: fear...:  50%|     | 10/20 [00:22<00:40,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 34.17 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: fear...: 100%|| 20/20 [01:03<00:00,  3.18s/it]\n",
      "Processing samples for emotion: joy...:  20%|        | 4/20 [00:02<00:10,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 11.08058662s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '11s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 11.043573332s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '11s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Sioux Valley wins home competitive #cheer invite with a score of 158. ...Dell Rapids second at 138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...:  25%|       | 5/20 [00:18<01:31,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 34.68 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...: 100%|| 20/20 [01:03<00:00,  3.17s/it]\n",
      "Processing samples for emotion: sadness...:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 49.59 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...:  75%|  | 15/20 [01:01<00:04,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 47.76 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...: 100%|| 20/20 [01:53<00:00,  5.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to ./results/llm_classification_results/results_samples_20_shots_0.csv\n",
      "Accuracy: 48.75%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.40      0.70      0.51        20\n",
      "        fear       0.67      0.10      0.17        20\n",
      "         joy       0.55      0.80      0.65        20\n",
      "     sadness       0.54      0.35      0.42        20\n",
      "\n",
      "    accuracy                           0.49        80\n",
      "   macro avg       0.54      0.49      0.44        80\n",
      "weighted avg       0.54      0.49      0.44        80\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If you see '429 RESOURCE_EXHAUSTED' errors it's fine, wait until the data gets processed, it will keep retrying until it finishes\n",
    "\n",
    "# Example of running the experiment with zero-shot prompting\n",
    "run_experiment(train_df, test_df, num_test_samples=20, num_shots=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You will be given a text extracted from social media and your task is to classify the text into one of the following emotion categories: \n",
      "\"anger\" | \"fear\" | \"joy\" | \"sadness\"\n",
      "    \n",
      "\n",
      "Examples: \n",
      "Text: British humour should offend and challenge mainstream views. Hat off to Clarkeson. The ultra left should go and kneel before Allah!!\n",
      "Class: anger\n",
      "\n",
      "Text: I get soooo nervous when an actually attractive guy tries to talk to me in person. Like 9/10 I turn him down just from habit \n",
      "Class: fear\n",
      "\n",
      "Text: Had a coworker look at her phone and say, cheerfully, 'oh look, Kap's getting death threats now.' . Then she goes to say the 49ers are\n",
      "Class: joy\n",
      "\n",
      "Text: Season 3 of penny dreadful is on Netflix...well my afternoon is filled\n",
      "Class: sadness\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:  55%|    | 11/20 [00:07<00:06,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 8.369056202s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 8.332942245s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: It's the most magical time of the year......Xmas party announced and the #outrage commences. Gotta love Silicon Valley millennials.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:  75%|  | 15/20 [00:25<00:11,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 34.03 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...: 100%|| 20/20 [01:04<00:00,  3.23s/it]\n",
      "Processing samples for emotion: fear...:  30%|       | 6/20 [00:04<00:10,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 7.492109177s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '7s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 7.41120025s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '7s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: also i had an awful nightmare involving being sick where worms were involved i was so disgusted when i woke up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: fear...:  50%|     | 10/20 [00:22<00:24,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 32.54 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: fear...: 100%|| 20/20 [01:03<00:00,  3.18s/it]\n",
      "Processing samples for emotion: joy...:   5%|         | 1/20 [00:00<00:17,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 7.305273912s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '7s'}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...:  10%|         | 2/20 [00:01<00:16,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 6.3556143s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '6s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 6.324217109s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '6s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: @HunterDean_ [he gives a gleeful squeak and wraps around you] All mine!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...:  25%|       | 5/20 [00:19<00:53,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 32.53 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...:  90%| | 18/20 [01:02<00:02,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 5.85462942s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '5s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 5.807990549s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '5s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: @GameGrumps THANK YOU SO MUCH FOR COMING TO DETROIT I'm going to sob joyful rainbows now brb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...: 100%|| 20/20 [01:18<00:00,  3.95s/it]\n",
      "Processing samples for emotion: sadness...:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 32.92 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...:  75%|  | 15/20 [00:43<00:03,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 49.19 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...: 100%|| 20/20 [01:37<00:00,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to ./results/llm_classification_results/results_samples_20_shots_1.csv\n",
      "Accuracy: 56.25%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.48      0.75      0.59        20\n",
      "        fear       0.71      0.25      0.37        20\n",
      "         joy       0.64      0.80      0.71        20\n",
      "     sadness       0.53      0.45      0.49        20\n",
      "\n",
      "    accuracy                           0.56        80\n",
      "   macro avg       0.59      0.56      0.54        80\n",
      "weighted avg       0.59      0.56      0.54        80\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If you see '429 RESOURCE_EXHAUSTED' errors it's fine, wait until the data gets processed, it will keep retrying until it finishes\n",
    "\n",
    "# Example of running the experiment with 1-shot prompting\n",
    "run_experiment(train_df, test_df, num_test_samples=20, num_shots=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You will be given a text extracted from social media and your task is to classify the text into one of the following emotion categories: \n",
      "\"anger\" | \"fear\" | \"joy\" | \"sadness\"\n",
      "    \n",
      "\n",
      "Examples: \n",
      "Text: British humour should offend and challenge mainstream views. Hat off to Clarkeson. The ultra left should go and kneel before Allah!!\n",
      "Class: anger\n",
      "\n",
      "Text: @mdivincenzo9 he's stupid, I hate him lol \n",
      "Class: anger\n",
      "\n",
      "Text: I'll happily be rude to people who personally insult me unprovoked, they deserve it  Just as good people deserve respect\n",
      "Class: anger\n",
      "\n",
      "Text: @everycolorbot more like every color looks the same #triggered #colorblind #offended\n",
      "Class: anger\n",
      "\n",
      "Text: #firsttweetever sippin #hotchocolate wondering #why I finally gave in &lt;3 haha #hellloooootwitter - ...its because #facebookisforfamily \n",
      "Class: anger\n",
      "\n",
      "Text: I get soooo nervous when an actually attractive guy tries to talk to me in person. Like 9/10 I turn him down just from habit \n",
      "Class: fear\n",
      "\n",
      "Text: Still salty about that fire alarm at 2am this morning.\n",
      "Class: fear\n",
      "\n",
      "Text: Lets start there\n",
      "Class: fear\n",
      "\n",
      "Text: Confiaejce comes not from always being right but from not fearing to be wrong.-Peter T. Mcintyre\n",
      "Class: fear\n",
      "\n",
      "Text: Just had to reverse half way up the woods to collect the dog n I've never even reverse parked in my life  #nightmare\n",
      "Class: fear\n",
      "\n",
      "Text: Had a coworker look at her phone and say, cheerfully, 'oh look, Kap's getting death threats now.' . Then she goes to say the 49ers are\n",
      "Class: joy\n",
      "\n",
      "Text: noah fence but i want a harley quinn or blake lively layout\n",
      "Class: joy\n",
      "\n",
      "Text: Another joyful encounter in Tribez &amp; Castlez! I just met Mouchole, Ogre Cook! Do you want to know who that is? Download the game and find...\n",
      "Class: joy\n",
      "\n",
      "Text: Currently listening to @ScottFoxonair &amp; @KatCallaghan @Z1035Toronto podcasts!! Can you guys please move to #yvr ?  #missyou\n",
      "Class: joy\n",
      "\n",
      "Text: Evening all. Don't forget it's #RobinHoodHour TONIGHT \\n\\n #bizitalk #bizhour #southyorkshire #MansfieldHour  #sheffieldHour #NottsHour\n",
      "Class: joy\n",
      "\n",
      "Text: Season 3 of penny dreadful is on Netflix...well my afternoon is filled\n",
      "Class: sadness\n",
      "\n",
      "Text: @everton_de_leon @sterushton Genuinely grim stuff. Over a century of history sold off by some porn baron twats for a minty new stadium. Urgh\n",
      "Class: sadness\n",
      "\n",
      "Text: My friends tell me I'm pretty. Trigger tells my I'm ugly. I first was confused but then realised I'm both. Pretty ugly. #tru  #tumblr\n",
      "Class: sadness\n",
      "\n",
      "Text: @cardiff_blues @CardiffBluesSC Italy another round lets not drop our play and take it to them with a big result out there guys #blues\n",
      "Class: sadness\n",
      "\n",
      "Text: Y'all tune into Snapchat for Beans funereal\n",
      "Class: sadness\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:  50%|     | 10/20 [00:07<00:07,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 4.517672145s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '4s'}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:  60%|    | 12/20 [00:09<00:06,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 2.742699682s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '2s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 2.703261656s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '2s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just seeing Alex revells face gets me angry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:  75%|  | 15/20 [00:26<00:15,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 33.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...: 100%|| 20/20 [01:04<00:00,  3.21s/it]\n",
      "Processing samples for emotion: fear...:  40%|      | 8/20 [00:06<00:10,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 1.132675908s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '1s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 1.094376345s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '1s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: If my concerns &amp; anxiety don't matter to you then I shall return the favor. #EyeMatter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: fear...:  50%|     | 10/20 [00:23<00:40,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 32.47 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: fear...: 100%|| 20/20 [01:04<00:00,  3.22s/it]\n",
      "Processing samples for emotion: joy...:  10%|         | 2/20 [00:01<00:11,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 2.171048184s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '2s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 2.136899129s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '2s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: @HunterDean_ [he gives a gleeful squeak and wraps around you] All mine!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...:  25%|       | 5/20 [00:19<00:53,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 32.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...:  80%|  | 16/20 [01:00<00:04,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 3.451841502s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '3s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 3.418096901s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '3s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: I love my family so much #lucky #grateful #smartassfamily #hilarious #love\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...: 100%|| 20/20 [01:17<00:00,  3.90s/it]\n",
      "Processing samples for emotion: sadness...:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 33.43 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...:  70%|   | 14/20 [00:44<00:05,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 1.402950317s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '1s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 1.364521828s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '1s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: A .500 season is all I'm looking for at this point. #depressing #royals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...:  75%|  | 15/20 [00:59<00:26,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 33.57 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...: 100%|| 20/20 [01:37<00:00,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to ./results/llm_classification_results/results_samples_20_shots_5.csv\n",
      "Accuracy: 58.75%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.54      0.70      0.61        20\n",
      "        fear       0.62      0.25      0.36        20\n",
      "         joy       0.65      0.75      0.70        20\n",
      "     sadness       0.57      0.65      0.60        20\n",
      "\n",
      "    accuracy                           0.59        80\n",
      "   macro avg       0.60      0.59      0.57        80\n",
      "weighted avg       0.60      0.59      0.57        80\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If you see '429 RESOURCE_EXHAUSTED' errors it's fine, wait until the data gets processed, it will keep retrying until it finishes\n",
    "\n",
    "# Example of running the experiment with 5-shot prompting\n",
    "run_experiment(train_df, test_df, num_test_samples=20, num_shots=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_10_1_1_'></a>[**>>> Exercise 6 (Take home):**](#toc0_)\n",
    "\n",
    "Compare and discuss the overall results of the zero-shot, 1-shot and 5-shot classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "# Answer below using markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comparison and Discussion of Zero-Shot, 1-Shot, and 5-Shot Classification Results**\n",
    "\n",
    "#### **1. Overall Performance Trend**\n",
    "\n",
    "Across the three settings, the performance improves as the number of shots increases.\n",
    "As seen from the results: more shots  the model better understands the classification logic  more accurate predictions.\n",
    "\n",
    "* Zero-shot: Most unstable, the model relies purely on its pretrained knowledge.\n",
    "\n",
    "* 1-shot: Adding one example per emotion noticeably improves predictions for fear and anger.\n",
    "\n",
    "* 5-shot: The most stable overall, with significant improvement especially in the anger category.\n",
    "\n",
    "#### **2. Problems**\n",
    "\n",
    "The fear category remains the most difficult emotion overall, with frequent confusion between anger and joy. The model still shows a tendency to collapse multiple negative emotions into similar predictions, suggesting that semantic boundaries between negative emotional expressions are not fully captured. Moreover, even with 5-shot prompting, sadness continues to be partially confused with anger due to shared wording patterns in social-media style texts. These limitations indicate that prompt examples alone cannot fully resolve category overlap.\n",
    "\n",
    "#### **3. Improvement**\n",
    "\n",
    "* Providing higher-quality few-shot examples, especially those that highlight the distinction between fear vs. anger, could strengthen category boundaries.\n",
    "\n",
    "* Incorporating longer context windows or emotion-specific linguistic cues into prompts may help the model better understand subtle sentiment differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_10_1_2_'></a>[**>>> Exercise 7 (Take home):**](#toc0_)\n",
    "\n",
    "**Case Study:** Check the results' files inside the `results/llm_classification_results` directory and find cases where the **text classification improves with more examples** (pred emotion is right with examples), **cases where it does not improve** (pred emotion always wrong) and **cases where the classification got worse with more examples** (pred emotion goes from right to wrong with examples). For this you need to load the results with pandas and handle the data using its dataframe functions. Discuss about the findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text true_emotion   pred_0  \\\n",
      "6                  Eat my ass' is no longer an insult        anger      joy   \n",
      "19   @LeonWobYP b***er off. NCFC is a grudge match :)        anger      joy   \n",
      "26  also i had an awful nightmare involving being ...         fear  sadness   \n",
      "28  If my concerns &amp; anxiety don't matter to y...         fear    anger   \n",
      "35  The moment you bring her to meet your best fri...         fear      joy   \n",
      "\n",
      "   pred_1 pred_5  \n",
      "6   anger  anger  \n",
      "19  anger  anger  \n",
      "26   fear   fear  \n",
      "28   fear   fear  \n",
      "35   fear   fear   \n",
      "\n",
      "                                                 text true_emotion   pred_0  \\\n",
      "2   I think @Sam_Canaday &amp; @KYLEJDOWSON must a...        anger  sadness   \n",
      "3   @LaureEve I am sitting here wrapped in a fluff...        anger      joy   \n",
      "8      @__NETFLIXNCHILL I fuck with madden way harder        anger      joy   \n",
      "14  I miss my gran singing Rawhide, in her deep ba...        anger  sadness   \n",
      "21  Nothing worse than an uber driver that can't d...         fear    anger   \n",
      "\n",
      "     pred_1   pred_5  \n",
      "2   sadness  sadness  \n",
      "3       joy      joy  \n",
      "8       joy      joy  \n",
      "14  sadness  sadness  \n",
      "21    anger    anger   \n",
      "\n",
      "                                                 text true_emotion pred_0  \\\n",
      "1   [ @HedgehogDylan ] *she would frown a bit, fol...        anger  anger   \n",
      "5   @IllinoisLoyalty that Rutgers game was an abom...        anger  anger   \n",
      "41  @diehimbeertonis She developed her 'forced smi...          joy    joy   \n",
      "\n",
      "     pred_1   pred_5  \n",
      "1      fear     fear  \n",
      "5     anger  sadness  \n",
      "41  sadness  sadness   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Answer here\n",
    "base_dir = \"./results/llm_classification_results\"\n",
    "\n",
    "# load csv\n",
    "df_0 = pd.read_csv(os.path.join(base_dir, \"results_samples_20_shots_0.csv\"))\n",
    "df_1 = pd.read_csv(os.path.join(base_dir, \"results_samples_20_shots_1.csv\"))\n",
    "df_5 = pd.read_csv(os.path.join(base_dir, \"results_samples_20_shots_5.csv\"))\n",
    "\n",
    "# rename prediction emotion label \n",
    "df_0 = df_0.rename(columns={\"predicted_emotion\": \"pred_0\"})\n",
    "df_1 = df_1.rename(columns={\"predicted_emotion\": \"pred_1\"})\n",
    "df_5 = df_5.rename(columns={\"predicted_emotion\": \"pred_5\"})\n",
    "\n",
    "# align outputs (text + emotions)\n",
    "df_merged = (\n",
    "df_0[[\"text\", \"true_emotion\", \"pred_0\"]]\n",
    ".merge(df_1[[\"text\", \"true_emotion\", \"pred_1\"]], on=[\"text\", \"true_emotion\"])\n",
    ".merge(df_5[[\"text\", \"true_emotion\", \"pred_5\"]], on=[\"text\", \"true_emotion\"])\n",
    ")\n",
    "\n",
    "# Improved case\n",
    "improved_mask = ((df_merged[\"pred_0\"] != df_merged[\"true_emotion\"]) & ((df_merged[\"pred_1\"] == df_merged[\"true_emotion\"]) | (df_merged[\"pred_5\"] == df_merged[\"true_emotion\"])))\n",
    "df_improved = df_merged[improved_mask]\n",
    "\n",
    "# Never improved case\n",
    "no_improve_mask = ((df_merged[\"pred_0\"] != df_merged[\"true_emotion\"]) & (df_merged[\"pred_1\"] != df_merged[\"true_emotion\"]) & (df_merged[\"pred_5\"] != df_merged[\"true_emotion\"]))\n",
    "df_no_improve = df_merged[no_improve_mask]\n",
    "\n",
    "# Got worsed case\n",
    "worse_mask = ((df_merged[\"pred_0\"] == df_merged[\"true_emotion\"]) &((df_merged[\"pred_1\"] != df_merged[\"true_emotion\"]) | (df_merged[\"pred_5\"] != df_merged[\"true_emotion\"])))\n",
    "df_worse = df_merged[worse_mask]\n",
    "\n",
    "# Print results\n",
    "print(df_improved.head(), \"\\n\")\n",
    "print(df_no_improve.head(), \"\\n\")\n",
    "print(df_worse.head(), \"\\n\")\n",
    "\n",
    "# Save as CSV\n",
    "df_improved.to_csv(os.path.join(base_dir, \"cases_improved.csv\"), index=False)\n",
    "df_no_improve.to_csv(os.path.join(base_dir, \"cases_no_improve.csv\"), index=False)\n",
    "df_worse.to_csv(os.path.join(base_dir, \"cases_worse.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Findings**\n",
    "\n",
    "#### 1. Improved Cases  Examples Provide Useful Semantic Framing\n",
    "\n",
    "This improvement occurs because the examples help the LLM better recognize emotion-specific linguistic patterns. Demonstrations clarify category boundaries, especially between semantically similar emotions such as anger vs. sadness or fear vs. sadness. Thus, few-shot prompting provides an effective semantic scaffold that guides the model toward the correct label.\n",
    "\n",
    "#### 2. No Improvement  Examples Do Not Address the Models Semantic Gaps\n",
    "\n",
    "These failures commonly appear in the anger category, suggesting that the examples may not sufficiently cover the full diversity of how anger is expressed. Texts with implicit emotion, sarcasm, weak cues, or ambiguous context remain difficult for the model, and few-shot prompting cannot compensate when the examples lack coverage or the texts emotional signal is too subtle. In these cases, model errors persist due to intrinsic ambiguity or insufficient representativeness in the examples.\n",
    "\n",
    "#### 3. Worse Cases  Examples Introduce Bias or Misleading Patterns\n",
    "\n",
    "This happens when the LLM overfits the linguistic style of the examples, causing it to prioritize example, like phrasing over the actual input. If the examples disproportionately emphasize certain emotional cues, the model may generalize incorrectly and shift ambiguous texts into the wrong category. This demonstrates a classic few-shot limitation: poor or overly narrow examples can misguide the model more than having no examples at all.\n",
    "\n",
    "#### 4. Conclusion\n",
    "\n",
    "The results show that few-shot prompting can improve classification when examples provide diverse and accurate semantic cues. However, when examples lack coverage or introduce stylistic or category biasthe model may fail to improve or even perform worse. \n",
    "\n",
    "**Ultimately, the quality and representativeness of examples matter far more than the number of examples.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_11_'></a>[**2.7 Extra LLM Related Materials:**](#toc0_)\n",
    "So this will be it for the lab, but here are some extra materials if you would like to explore:\n",
    "\n",
    "- **How to use OpenAI ChatGPT model's API (Not Free API):** [Basics Video](https://www.youtube.com/watch?v=e9P7FLi5Zy8), [Basics GitHub](https://github.com/gkamradt/langchain-tutorials/blob/main/chatapi/ChatAPI%20%2B%20LangChain%20Basics.ipynb), [RAG's Basics Video](https://www.youtube.com/watch?v=9AXP7tCI9PI&t=300s), [RAG's Basics GitHub](https://github.com/techleadhd/chatgpt-retrieval)\n",
    "\n",
    "- **Advanced topic - QLoRA (Quantized Low-Rank Adapter):** QLoRA is a method used to make fine-tuning large language models more efficient. It works by adding a small, trainable part (LoRA) to a pre-trained model, while keeping the rest of the model frozen. At the same time, it reduces the size of the models data using a process called quantization, which makes the model require less memory. This allows you to fine-tune large models without needing as much computational power, making it easier to adapt models for specific tasks. Materials: [Paper GitHub](https://github.com/artidoro/qlora?tab=readme-ov-file), [Llama 3 Application Video](https://www.youtube.com/watch?v=YJNbgusTSF0&t=512s),[Llama 3 Application GitHub](https://github.com/adidror005/youtube-videos/blob/main/LLAMA_3_Fine_Tuning_for_Sequence_Classification_Actual_Video.ipynb)\n",
    "\n",
    "- **How to Fine-tune and run local LLMs with the `unsloth` library:** [unsloth tutorials](https://docs.unsloth.ai/models/tutorials-how-to-fine-tune-and-run-llms)\n",
    "\n",
    "- **Google's Agent Development Kit Documentation:** [ADK](https://google.github.io/adk-docs/)\n",
    "\n",
    "- **Build AI agents with LangGraph:** [LangGraph Documentation](https://langchain-ai.github.io/langgraph/concepts/why-langgraph/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fF1woa8YTp5"
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "4e5eiVLOYTp5"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DM2025-Lab2-Exercise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 594.85,
   "position": {
    "height": "40px",
    "left": "723px",
    "right": "20px",
    "top": "80px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
