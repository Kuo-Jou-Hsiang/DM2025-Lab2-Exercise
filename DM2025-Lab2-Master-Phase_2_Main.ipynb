{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Data Mining Lab 2 - Phase 2](#toc1_)    \n",
    "  - [Before Starting](#toc1_1_)    \n",
    "  - [Introduction](#toc1_2_)    \n",
    "  - [**1. Data Preparation**](#toc1_3_)    \n",
    "  - [**1.1 Load data**](#toc1_4_)    \n",
    "    - [**1.2 Save data**](#toc1_4_1_)    \n",
    "  - [**2. Large Language Models (LLMs)**](#toc1_5_)    \n",
    "    - [Open-Source vs. Proprietary LLMs](#toc1_5_1_)    \n",
    "    - [Why Use Code (API) for Data Mining?](#toc1_5_2_)    \n",
    "    - [The Gemini API](#toc1_5_3_)    \n",
    "    - [Interacting with the Gemini API](#toc1_5_4_)    \n",
    "    - [**2.1 Text Prompting**](#toc1_5_5_)    \n",
    "        - [**>>> Exercise 1 (Take home):**](#toc1_5_5_1_1_)    \n",
    "    - [**2.2 Structured Output**](#toc1_5_6_)    \n",
    "        - [**>>> Exercise 2 (Take home):**](#toc1_5_6_1_1_)    \n",
    "    - [**2.3 Information Extraction and Grounding:**](#toc1_5_7_)    \n",
    "      - [**`langextract`: A Library for Grounded Extraction**](#toc1_5_7_1_)    \n",
    "        - [**2.3.1 Using PDF Documents:**](#toc1_5_7_1_1_)    \n",
    "        - [**>>> Bonus Exercise 3 (Take home):**](#toc1_5_7_1_2_)    \n",
    "    - [**2.4 Generating LLM Embeddings:**](#toc1_5_8_)    \n",
    "        - [**>>> Exercise 4 (Take home):**](#toc1_5_8_1_1_)    \n",
    "    - [**2.5 Retrieval-Augmented Generation (RAG)**](#toc1_5_9_)    \n",
    "        - [**Actual answer in the URL:**](#toc1_5_9_1_1_)    \n",
    "        - [**Content in the URL that might get into the generated answer because of similar semantic meaning:**](#toc1_5_9_1_2_)    \n",
    "        - [**>>> Bonus Exercise 5 (Take home):**](#toc1_5_9_1_3_)    \n",
    "    - [**2.6 Few-Shot Prompting Classification:**](#toc1_5_10_)    \n",
    "        - [**>>> Exercise 6 (Take home):**](#toc1_5_10_1_1_)    \n",
    "        - [**>>> Exercise 7 (Take home):**](#toc1_5_10_1_2_)    \n",
    "    - [**2.7 Extra LLM Related Materials:**](#toc1_5_11_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuutyCx4YTpX"
   },
   "source": [
    "# <a id='toc1_'></a>[Data Mining Lab 2 - Phase 2](#toc0_)\n",
    "In this lab's phase 2 session we will focus on exploring some basic LLMs' applications with data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Before Starting](#toc0_)\n",
    "\n",
    "**Make sure you have installed all the required libraries and you have the environment ready to run this lab.**\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIpAqCvMYTpX"
   },
   "source": [
    "---\n",
    "## <a id='toc1_2_'></a>[Introduction](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2paPeNbYTpX"
   },
   "source": [
    "**Dataset:** [SemEval 2017 Task](https://competitions.codalab.org/competitions/16380)\n",
    "\n",
    "**Task:** Classify text data into 4 different emotions using word embeddings and other deep information retrieval approaches.\n",
    "\n",
    "![pic0.png](./pics/pic0.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kuojouhsiang/Documents/DM2025-Lab2-Exercise/.venv/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "op_X7pR-YTpX"
   },
   "source": [
    "---\n",
    "## <a id='toc1_3_'></a>[**1. Data Preparation**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgoEbZzSYTpX"
   },
   "source": [
    "---\n",
    "## <a id='toc1_4_'></a>[**1.1 Load data**](#toc0_)\n",
    "\n",
    "We start by loading the csv files into a single pandas dataframe for training and one for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "anfjcPSSYTpX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "### training data\n",
    "anger_train = pd.read_csv(\"data/semeval/train/anger-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None,names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "sadness_train = pd.read_csv(\"data/semeval/train/sadness-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "fear_train = pd.read_csv(\"data/semeval/train/fear-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "joy_train = pd.read_csv(\"data/semeval/train/joy-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yVc2T5MIYTpX"
   },
   "outputs": [],
   "source": [
    "# combine 4 sub-dataset\n",
    "train_df = pd.concat([anger_train, fear_train, joy_train, sadness_train], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Kw8bGMv7YTpX",
    "outputId": "9f6f7052-302e-4794-ef69-b84450b61b36"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>So my Indian Uber driver just called someone t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>@DPD_UK I asked for my parcel to be delivered ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text emotion  intensity\n",
       "0  10000  How the fu*k! Who the heck! moved my fridge!.....   anger      0.938\n",
       "1  10001  So my Indian Uber driver just called someone t...   anger      0.896\n",
       "2  10002  @DPD_UK I asked for my parcel to be delivered ...   anger      0.896\n",
       "3  10003  so ef whichever butt wipe pulled the fire alar...   anger      0.896\n",
       "4  10004  Don't join @BTCare they put the phone down on ...   anger      0.896"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### testing data\n",
    "anger_test = pd.read_csv(\"data/semeval/dev/anger-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "sadness_test = pd.read_csv(\"data/semeval/dev/sadness-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "fear_test = pd.read_csv(\"data/semeval/dev/fear-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "joy_test = pd.read_csv(\"data/semeval/dev/joy-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "\n",
    "# combine 4 sub-dataset\n",
    "test_df = pd.concat([anger_test, fear_test, joy_test, sadness_test], ignore_index=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HBHwcL8sYTpX"
   },
   "outputs": [],
   "source": [
    "# shuffle dataset\n",
    "train_df = train_df.sample(frac=1)\n",
    "test_df = test_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9w_cDUwCYTpX",
    "outputId": "3582ac44-1f5f-4cb2-b833-d477f152461a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training df:  (3613, 4)\n",
      "Shape of Testing df:  (347, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Training df: \", train_df.shape)\n",
    "print(\"Shape of Testing df: \", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hr8aKhlYTpo"
   },
   "source": [
    "---\n",
    "### <a id='toc1_4_1_'></a>[**1.2 Save data**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dZzepBdpYTpo"
   },
   "outputs": [],
   "source": [
    "# save to pickle file\n",
    "train_df.to_pickle(\"./data/train_df.pkl\") \n",
    "test_df.to_pickle(\"./data/test_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "H5uO-kOUYTpo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load a pickle file\n",
    "train_df = pd.read_pickle(\"./data/train_df.pkl\")\n",
    "test_df = pd.read_pickle(\"./data/test_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sLDcQzeYTpo"
   },
   "source": [
    "For more information: https://reurl.cc/0Dzqx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <a id='toc1_5_'></a>[**2. Large Language Models (LLMs)**](#toc0_)\n",
    "\n",
    "Before we start we strongly suggest that you watch the following video explanations so you can understand the concepts that we are gonna discuss about LLMs: \n",
    "\n",
    "1. [How Large Language Models Work](https://www.youtube.com/watch?v=5sLYAQS9sWQ)\n",
    "2. [Large Language Models explained briefly](https://www.youtube.com/watch?v=LPZh9BOjkQs)\n",
    "3. [What is Prompt Tuning?](https://www.youtube.com/watch?v=yu27PWzJI_Y)\n",
    "4. [Why Large Language Models Hallucinate](https://www.youtube.com/watch?v=cfqtFvWOfg0)\n",
    "5. [What are LLM Embeddings?](https://www.youtube.com/watch?v=UShw_1NbpCw&t=182s)\n",
    "6. [What is Retrieval-Augmented Generation (RAG)?](https://www.youtube.com/watch?v=T-D1OfcDW1M)\n",
    "7. [RAG vs Fine-Tuning vs Prompt Engineering: Optimizing AI Models](https://www.youtube.com/watch?v=zYGDpG-pTho)\n",
    "8. [Discover Few-Shot Prompting | Google AI Essentials](https://www.youtube.com/watch?v=9qdgEBVkWR4)\n",
    "9. [What is Zero-Shot Learning?](https://www.youtube.com/watch?v=pVpr4GYLzAo)\n",
    "10. [Zero-shot, One-shot and Few-shot Prompting Explained | Prompt Engineering 101](https://www.youtube.com/watch?v=sW5xoicq5TY)\n",
    "\n",
    "`These videos can help you get a better grasp on the core concepts of LLMs if you were not familiar before.`\n",
    "\n",
    "**So now let's start with the main content of Lab 2 Phase 2.**\n",
    "\n",
    "Large Language Models (LLMs) are AI systems trained on vast amounts of text to understand and generate human language for tasks like summarization and translation.\n",
    "\n",
    "### <a id='toc1_5_1_'></a>[Open-Source vs. Proprietary LLMs](#toc0_)\n",
    "*   **Open-Source Models** (e.g., Llama, Gemma) are customizable and cost-effective but require technical skill to manage and may be less powerful.\n",
    "*   **Proprietary Models** (e.g., Gemini, ChatGPT) offer top performance and ease of use but are more costly and less flexible.\n",
    "\n",
    "For students interested in running models locally, the optional notebook `DM2025-Lab2-Optional-Ollama.ipynb` explores using Ollama ([Ollama GitHub Link](https://github.com/ollama/ollama)). It needs a capable GPU to run models (**at least 4GB VRAM**).\n",
    "\n",
    "You can explore the variety of models available through Ollama here:\n",
    "\n",
    "![pic10.png](./pics/pic10.png)\n",
    "\n",
    "### <a id='toc1_5_2_'></a>[Why Use Code (API) for Data Mining?](#toc0_)\n",
    "\n",
    "For data analysis, accessing LLMs programmatically is superior to using web chatbots because it allows for:\n",
    "*   **Automation:** Easily process entire datasets with loops.\n",
    "*   **Structured Output:** Receive data in usable formats like **JSON**, ready for analysis in tools like pandas.\n",
    "*   **Reproducibility:** Ensure consistent results by setting fixed parameters.\n",
    "*   **Privacy:** Maintain data security, especially when running models locally.\n",
    "\n",
    "For the main exercises in this lab, we will use **the Gemini API**. This approach offers several advantages over running local open-source models, such as access to state-of-the-art model performance without needing specialized hardware. While the API has usage limits (rate limits and token quotas), it provides a generous **free tier** that is more than sufficient for our exercises.\n",
    "\n",
    "![pic13.png](./pics/pic13.png)\n",
    "\n",
    "![pic14.png](./pics/pic14.png)\n",
    "\n",
    "### <a id='toc1_5_3_'></a>[The Gemini API](#toc0_)\n",
    "\n",
    "We will primarily use the **Gemini 2.5 Flash-Lite** (`gemini-2.5-flash-lite`) model. As shown in the rate limit table, this model is optimized for high-frequency tasks and offers a high request-per-day limit of 1,000, making it ideal for completing the lab exercises without interruption.\n",
    "\n",
    "Students are encouraged to explore other models available through the API but should remain mindful of their respective usage limits. For instance:\n",
    "*   **Gemini 2.5 Pro** is a more powerful model but has a lower daily request limit of 100.\n",
    "*   The **Gemma 3** model available via the API offers an impressive 14,400 requests per day, providing another excellent alternative for experimentation.\n",
    "\n",
    "Please be aware of your usage limits as you work through the exercises to ensure you do not get rate-limited.\n",
    "\n",
    "[Gemini Documentation](https://ai.google.dev/gemini-api/docs)\n",
    "\n",
    "[Gemini Rate Limits](https://ai.google.dev/gemini-api/docs/rate-limits)\n",
    "\n",
    "[Description of Gemini Models](https://ai.google.dev/gemini-api/docs/models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc1_5_4_'></a>[Interacting with the Gemini API](#toc0_)\n",
    "\n",
    "The code cell below contains the primary function, `prompt_gemini`, that we will use throughout this lab to communicate with the Gemini API. It's designed to be a flexible wrapper that handles the details of sending a request and receiving a response.\n",
    "\n",
    "Before you run the exercises, here are the key things you need to understand in this setup:\n",
    "\n",
    "*   **API Key Configuration**: The script loads your API key from a `.env` file located in the `./config/` directory. **You must create this file and add your API key** like this: `GOOGLE_API_KEY='YOUR_API_KEY_HERE'`. This is a security best practice to keep your credentials out of the code.\n",
    "\n",
    "*   **Global Settings**: At the top of the script, you can find and modify several important defaults:\n",
    "    *   `MODEL_NAME`: We've set this to `\"gemini-2.5-flash-lite\"`, but you can easily switch to other models like `\"gemini-2.5-pro\"` to experiment.\n",
    "    *   `SYSTEM_INSTRUCTION`: This sets the model's default behavior or persona (e.g., \"You are a helpful assistant\"). You can customize this for different tasks.\n",
    "    *   `SAFETY_SETTINGS`: For our academic exercises, these are turned off to prevent interference. In real-world applications, you would configure these carefully.\n",
    "\n",
    "*   **The `prompt_gemini` function**: This is the main tool you will use. Here are its most important parameters:\n",
    "    *   `input_prompt`: The list of contents (text, images, etc.) you want to send to the model.\n",
    "    *   `temperature`: Controls the randomness of the output. `0.0` makes the output deterministic and less creative, while a higher value (e.g., `0.7`) makes it more varied.\n",
    "    *   `schema`: A powerful feature that allows you to specify a JSON format for the model's output. This is extremely useful for structured data extraction.\n",
    "    *   `with_tokens_info`: If set to `True`, the function will also return the number of input and output tokens used, which is helpful for monitoring your usage against the free tier limits.\n",
    "\n",
    "In the following exercises, you will call this function with different prompts and configurations to solve various tasks.\n",
    "\n",
    "If needed, you can also check some tutorials on how a python function works: [Python Functions Tutorial](https://realpython.com/defining-your-own-python-function/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "env_path = \"./config/.env\"\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# System instruction that can dictate how the model behaves in the output, can be customized as needed\n",
    "SYSTEM_INSTRUCTION = (\n",
    "        \"You are a helpful assistant\"\n",
    "    )\n",
    "\n",
    "# Max amount of tokens that the model can output, the Gemini 2.5 Models have this maximum amount\n",
    "# For other models need to check their documentation \n",
    "MAX_OUTPUT_TOKENS = 65535\n",
    "MODEL_NAME = \"gemini-2.5-flash-lite\" # Other models: \"gemini-2.5-pro\", \"gemini-2.5-flash\"; Check different max output tokens: \"gemini-2.0-flash\" , \"gemini-2.0-flash-lite\" \n",
    "\n",
    "# We disable the safety settings, as no moderation is needed in our tasks\n",
    "SAFETY_SETTINGS = [\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_HATE_SPEECH\", threshold=\"OFF\"),\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_DANGEROUS_CONTENT\", threshold=\"OFF\"),\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\", threshold=\"OFF\"),\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_HARASSMENT\", threshold=\"OFF\")\n",
    "]\n",
    "\n",
    "#IMPORTANT: The script loads your API key from a `.env` file located in the `./config/` directory. \n",
    "# You must create this file and add your API key like this: `GOOGLE_API_KEY='YOUR_API_KEY_HERE'`\n",
    "\n",
    "# We input the API Key to be able to use the Gemini models\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "# We also set LangExtract to use the API key as well:\n",
    "if 'GEMINI_API_KEY' not in os.environ:\n",
    "    os.environ['GEMINI_API_KEY'] = api_key\n",
    "\n",
    "def prompt_gemini(\n",
    "        input_prompt: list,\n",
    "        schema = None,\n",
    "        temperature: float = 0.0,\n",
    "        system_instruction: str = SYSTEM_INSTRUCTION,\n",
    "        max_output_tokens: int = MAX_OUTPUT_TOKENS,\n",
    "        client: genai.Client = client,\n",
    "        model_name: str = MODEL_NAME,\n",
    "        new_config: types.GenerateContentConfig = None,\n",
    "        with_tools: bool = False,\n",
    "        with_parts: bool = False,\n",
    "        with_tokens_info: bool = False\n",
    "    ):\n",
    "        try:\n",
    "            # If we need a JSON schema we set up the following\n",
    "            if schema:\n",
    "                generate_content_config = types.GenerateContentConfig(\n",
    "                    temperature=temperature,\n",
    "                    system_instruction=system_instruction,\n",
    "                    max_output_tokens=max_output_tokens,\n",
    "                    response_modalities=[\"TEXT\"],\n",
    "                    response_mime_type=\"application/json\",\n",
    "                    response_schema=schema,\n",
    "                    safety_settings=SAFETY_SETTINGS\n",
    "                )\n",
    "            # If there is no need we leave it unstructured\n",
    "            else:\n",
    "                generate_content_config = types.GenerateContentConfig(\n",
    "                    temperature=temperature,\n",
    "                    system_instruction=system_instruction,\n",
    "                    max_output_tokens=max_output_tokens,\n",
    "                    response_modalities=[\"TEXT\"],\n",
    "                    safety_settings=SAFETY_SETTINGS\n",
    "                )\n",
    "            \n",
    "            # We add a different custom configuration if we need it\n",
    "            if new_config:\n",
    "                generate_content_config = new_config\n",
    "            \n",
    "            # For some tasks we need a more specific way to add the contents when prompting the model\n",
    "            # So we need custom parts for it sometimes from the \"types\" objects\n",
    "            if with_parts:\n",
    "                response = client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    contents=types.Content(parts=input_prompt),\n",
    "                    config=generate_content_config,\n",
    "                )\n",
    "            # In the simplest form the contents can be expressed as a list [] of simple objects like str and Pillow images\n",
    "            else:\n",
    "                response = client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    contents=input_prompt,\n",
    "                    config=generate_content_config,\n",
    "                )\n",
    "\n",
    "            if with_tools:\n",
    "                # print(response)\n",
    "                # Include raw response when function calling\n",
    "                completion = response\n",
    "                if with_tokens_info:\n",
    "                    log = {\n",
    "                        \"model\": model_name,\n",
    "                        \"input_tokens\": response.usage_metadata.prompt_token_count,\n",
    "                        \"output_tokens\": response.usage_metadata.candidates_token_count,\n",
    "                    }\n",
    "                    return completion, log\n",
    "                return completion\n",
    "            else:\n",
    "                completion = response.text\n",
    "                if with_tokens_info:\n",
    "                    log = {\n",
    "                        \"model\": model_name,\n",
    "                        \"input_tokens\": response.usage_metadata.prompt_token_count,\n",
    "                        \"output_tokens\": response.usage_metadata.candidates_token_count,\n",
    "                    }\n",
    "                    # Return the text response and logs (if selected)\n",
    "                    return completion, log\n",
    "                return completion\n",
    "        except Exception as e:\n",
    "             print(f\"Error occurred when generating response, error: {e}\")\n",
    "             return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_5_'></a>[**2.1 Text Prompting**](#toc0_)\n",
    "\n",
    "In the same way as with ChatGPT we can use the Gemini models to ask about anything. Here we are going to ask a question requesting the response to be in markdown format, this is to make it have a better display afterwards.\n",
    "\n",
    "For more information visit:\n",
    "[Gemini's Text Generation Documentation](https://ai.google.dev/gemini-api/docs/text-generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data mining is the process of **discovering patterns, insights, and knowledge from large datasets**. It's essentially about extracting valuable information that isn't immediately obvious from raw data. Think of it as sifting through a mountain of information to find hidden gems.\n",
      "\n",
      "Here's a breakdown of what that means:\n",
      "\n",
      "**Key Concepts:**\n",
      "\n",
      "*   **Large Datasets:** Data mining is typically applied to datasets that are too large and complex for manual analysis. This can include customer transaction records, website logs, sensor data, social media feeds, scientific experiment results, and much more.\n",
      "*   **Patterns and Insights:** The goal is to identify recurring trends, correlations, anomalies, and relationships within the data. These patterns can reveal underlying structures, predict future behavior, or explain observed phenomena.\n",
      "*   **Knowledge Discovery:** The ultimate aim is to transform raw data into actionable knowledge that can be used for decision-making, problem-solving, and strategic planning.\n",
      "\n",
      "**How it Works (The Process):**\n",
      "\n",
      "Data mining is usually an iterative process that involves several stages:\n",
      "\n",
      "1.  **Business Understanding:** Defining the problem or objective you want to achieve with data mining. What questions are you trying to answer? What business goals are you trying to meet?\n",
      "2.  **Data Understanding:** Exploring and getting familiar with the data. This involves collecting, cleaning, and understanding the data's structure, quality, and meaning.\n",
      "3.  **Data Preparation (Preprocessing):** This is often the most time-consuming stage. It involves:\n",
      "    *   **Cleaning:** Handling missing values, noisy data, and inconsistencies.\n",
      "    *   **Integration:** Combining data from multiple sources.\n",
      "    *   **Transformation:** Normalizing or aggregating data to make it suitable for mining.\n",
      "    *   **Reduction:** Reducing the size of the dataset while preserving important information.\n",
      "4.  **Modeling:** Selecting and applying appropriate data mining techniques (algorithms) to discover patterns. This is where the \"mining\" happens.\n",
      "5.  **Evaluation:** Assessing the quality and usefulness of the discovered patterns. Do they make sense? Are they statistically significant? Do they meet the business objectives?\n",
      "6.  **Deployment:** Putting the discovered knowledge into practice. This could involve integrating it into business processes, creating reports, or building predictive models.\n",
      "\n",
      "**Common Data Mining Techniques:**\n",
      "\n",
      "Data mining employs a variety of techniques, often drawing from statistics, machine learning, and database systems. Some of the most common include:\n",
      "\n",
      "*   **Classification:** Categorizing data into predefined classes (e.g., predicting whether a customer will churn or not).\n",
      "*   **Clustering:** Grouping similar data points together without predefined classes (e.g., segmenting customers into different groups based on their purchasing behavior).\n",
      "*   **Association Rule Mining:** Discovering relationships between items in a dataset (e.g., \"customers who buy bread also tend to buy milk\"). This is often used in market basket analysis.\n",
      "*   **Regression:** Predicting a continuous numerical value (e.g., predicting the price of a house based on its features).\n",
      "*   **Anomaly Detection (Outlier Detection):** Identifying data points that deviate significantly from the norm (e.g., detecting fraudulent transactions).\n",
      "*   **Sequential Pattern Mining:** Discovering patterns that occur in a sequence over time (e.g., identifying common user navigation paths on a website).\n",
      "\n",
      "**Why is Data Mining Important?**\n",
      "\n",
      "Data mining is crucial for businesses and organizations because it enables them to:\n",
      "\n",
      "*   **Make Better Decisions:** By understanding customer behavior, market trends, and operational efficiencies, organizations can make more informed and strategic decisions.\n",
      "*   **Improve Customer Relationships:** Identifying customer preferences and predicting their needs allows for personalized marketing, better customer service, and increased loyalty.\n",
      "*   **Detect Fraud and Risk:** Anomaly detection can help identify fraudulent activities, security breaches, and potential risks.\n",
      "*   **Optimize Operations:** Understanding patterns in operational data can lead to improved efficiency, reduced costs, and better resource allocation.\n",
      "*   **Drive Innovation:** Discovering new insights can spark new product development, service offerings, and business models.\n",
      "*   **Gain a Competitive Advantage:** Organizations that effectively leverage data mining can outperform their competitors by understanding their market and customers better.\n",
      "\n",
      "In essence, data mining is a powerful tool for transforming raw data into valuable intelligence, driving progress and innovation across various fields.\n"
     ]
    }
   ],
   "source": [
    "input_prompt = [\"What is Data Mining?\"]\n",
    "text_response, logs = prompt_gemini(input_prompt = input_prompt, with_tokens_info = True)\n",
    "print(text_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the logs of the usage with our model that we defined in our previous function. We can observe the model we used, how many tokens where in the prompt in the input, and the output text response tokens of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'gemini-2.5-flash-lite', 'input_tokens': 12, 'output_tokens': 911}\n"
     ]
    }
   ],
   "source": [
    "print(logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can use the IPython library to make the response look better:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Data mining is the process of **discovering patterns, insights, and knowledge from large datasets**. It's essentially about extracting valuable information that isn't immediately obvious from raw data. Think of it as sifting through a mountain of information to find hidden gems.\n",
       "\n",
       "Here's a breakdown of what that means:\n",
       "\n",
       "**Key Concepts:**\n",
       "\n",
       "*   **Large Datasets:** Data mining is typically applied to datasets that are too large and complex for manual analysis. This can include customer transaction records, website logs, sensor data, social media feeds, scientific experiment results, and much more.\n",
       "*   **Patterns and Insights:** The goal is to identify recurring trends, correlations, anomalies, and relationships within the data. These patterns can reveal underlying structures, predict future behavior, or explain observed phenomena.\n",
       "*   **Knowledge Discovery:** The ultimate aim is to transform raw data into actionable knowledge that can be used for decision-making, problem-solving, and strategic planning.\n",
       "\n",
       "**How it Works (The Process):**\n",
       "\n",
       "Data mining is usually an iterative process that involves several stages:\n",
       "\n",
       "1.  **Business Understanding:** Defining the problem or objective you want to achieve with data mining. What questions are you trying to answer? What business goals are you trying to meet?\n",
       "2.  **Data Understanding:** Exploring and getting familiar with the data. This involves collecting, cleaning, and understanding the data's structure, quality, and meaning.\n",
       "3.  **Data Preparation (Preprocessing):** This is often the most time-consuming stage. It involves:\n",
       "    *   **Cleaning:** Handling missing values, noisy data, and inconsistencies.\n",
       "    *   **Integration:** Combining data from multiple sources.\n",
       "    *   **Transformation:** Normalizing or aggregating data to make it suitable for mining.\n",
       "    *   **Reduction:** Reducing the size of the dataset while preserving important information.\n",
       "4.  **Modeling:** Selecting and applying appropriate data mining techniques (algorithms) to discover patterns. This is where the \"mining\" happens.\n",
       "5.  **Evaluation:** Assessing the quality and usefulness of the discovered patterns. Do they make sense? Are they statistically significant? Do they meet the business objectives?\n",
       "6.  **Deployment:** Putting the discovered knowledge into practice. This could involve integrating it into business processes, creating reports, or building predictive models.\n",
       "\n",
       "**Common Data Mining Techniques:**\n",
       "\n",
       "Data mining employs a variety of techniques, often drawing from statistics, machine learning, and database systems. Some of the most common include:\n",
       "\n",
       "*   **Classification:** Categorizing data into predefined classes (e.g., predicting whether a customer will churn or not).\n",
       "*   **Clustering:** Grouping similar data points together without predefined classes (e.g., segmenting customers into different groups based on their purchasing behavior).\n",
       "*   **Association Rule Mining:** Discovering relationships between items in a dataset (e.g., \"customers who buy bread also tend to buy milk\"). This is often used in market basket analysis.\n",
       "*   **Regression:** Predicting a continuous numerical value (e.g., predicting the price of a house based on its features).\n",
       "*   **Anomaly Detection (Outlier Detection):** Identifying data points that deviate significantly from the norm (e.g., detecting fraudulent transactions).\n",
       "*   **Sequential Pattern Mining:** Discovering patterns that occur in a sequence over time (e.g., identifying common user navigation paths on a website).\n",
       "\n",
       "**Why is Data Mining Important?**\n",
       "\n",
       "Data mining is crucial for businesses and organizations because it enables them to:\n",
       "\n",
       "*   **Make Better Decisions:** By understanding customer behavior, market trends, and operational efficiencies, organizations can make more informed and strategic decisions.\n",
       "*   **Improve Customer Relationships:** Identifying customer preferences and predicting their needs allows for personalized marketing, better customer service, and increased loyalty.\n",
       "*   **Detect Fraud and Risk:** Anomaly detection can help identify fraudulent activities, security breaches, and potential risks.\n",
       "*   **Optimize Operations:** Understanding patterns in operational data can lead to improved efficiency, reduced costs, and better resource allocation.\n",
       "*   **Drive Innovation:** Discovering new insights can spark new product development, service offerings, and business models.\n",
       "*   **Gain a Competitive Advantage:** Organizations that effectively leverage data mining can outperform their competitors by understanding their market and customers better.\n",
       "\n",
       "In essence, data mining is a powerful tool for transforming raw data into valuable intelligence, driving progress and innovation across various fields."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(text_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_5_1_1_'></a>[**>>> Exercise 1 (Take home):**](#toc0_)\n",
    "\n",
    "`With your own prompt`, run the previous example in the following way:\n",
    "\n",
    "1. Run it with the same model as the example (gemini-2.5-flash-lite). \n",
    "2. Run it with a different gemini model from the available options for the API.\n",
    "3. Discuss the differences on the results with different models.\n",
    "4. Discuss what would happen if you change the system prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# ===== gemini-2.5-flash-lite Output ====="
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Tuning a large language model (LLM) is crucial for adapting its general capabilities to specific tasks, domains, or desired behaviors. Here's a breakdown of the common methods used for LLM tuning, categorized for clarity:\n",
       "\n",
       "**I. Fine-tuning (The Most Common Approach)**\n",
       "\n",
       "Fine-tuning involves taking a pre-trained LLM and further training it on a smaller, task-specific dataset. This allows the model to learn new patterns and nuances relevant to the target application.\n",
       "\n",
       "*   **Full Fine-tuning:**\n",
       "    *   **Description:** All parameters of the pre-trained LLM are updated during training.\n",
       "    *   **Pros:** Can achieve the best performance for the specific task as the entire model adapts.\n",
       "    *   **Cons:** Computationally expensive, requires significant memory, and can lead to catastrophic forgetting (where the model loses its general capabilities).\n",
       "    *   **When to use:** When maximum performance on a specific task is paramount and computational resources are not a major constraint.\n",
       "\n",
       "*   **Parameter-Efficient Fine-tuning (PEFT):** These methods aim to reduce the number of trainable parameters, making fine-tuning more efficient in terms of computation, memory, and storage.\n",
       "\n",
       "    *   **LoRA (Low-Rank Adaptation):**\n",
       "        *   **Description:** Injects trainable low-rank matrices into specific layers of the pre-trained model. Only these low-rank matrices are trained, while the original model weights remain frozen.\n",
       "        *   **Pros:** Significantly reduces the number of trainable parameters, faster training, smaller storage footprint for adapters, less prone to catastrophic forgetting.\n",
       "        *   **Cons:** Might not reach the absolute peak performance of full fine-tuning in all cases.\n",
       "        *   **When to use:** A very popular and effective method for most fine-tuning tasks, especially when dealing with limited resources or when deploying multiple task-specific models.\n",
       "\n",
       "    *   **Adapter Layers:**\n",
       "        *   **Description:** Inserts small, trainable \"adapter\" modules between the layers of the pre-trained LLM. The original LLM weights are frozen.\n",
       "        *   **Pros:** Similar benefits to LoRA in terms of efficiency and reduced forgetting.\n",
       "        *   **Cons:** Can introduce slight latency due to the added layers.\n",
       "        *   **When to use:** Another good PEFT option, often compared to LoRA.\n",
       "\n",
       "    *   **Prefix Tuning / P-Tuning:**\n",
       "        *   **Description:** Learns a small, continuous \"prefix\" or \"prompt\" that is prepended to the input sequence. The LLM's weights are frozen.\n",
       "        *   **Pros:** Very parameter-efficient, can be effective for certain tasks.\n",
       "        *   **Cons:** Can be less flexible than LoRA or adapters for complex tasks.\n",
       "        *   **When to use:** When you want to steer the model's behavior without modifying its core weights, often for tasks like text generation or classification.\n",
       "\n",
       "    *   **Prompt Tuning:**\n",
       "        *   **Description:** Similar to prefix tuning, but learns a set of trainable \"soft prompts\" that are prepended to the input. The LLM's weights are frozen.\n",
       "        *   **Pros:** Extremely parameter-efficient, can be very effective for specific tasks.\n",
       "        *   **Cons:** The learned prompts are not human-readable.\n",
       "        *   **When to use:** When you need to adapt the model with minimal computational overhead and are comfortable with learned, non-interpretable prompts.\n",
       "\n",
       "    *   **QLoRA:**\n",
       "        *   **Description:** An optimization of LoRA that quantizes the pre-trained model to 4-bit precision, further reducing memory usage and enabling fine-tuning of very large models on consumer hardware.\n",
       "        *   **Pros:** Enables fine-tuning of massive LLMs on significantly less hardware.\n",
       "        *   **Cons:** Potential for slight degradation in performance compared to higher precision.\n",
       "        *   **When to use:** When you need to fine-tune extremely large LLMs and have limited GPU memory.\n",
       "\n",
       "**II. Instruction Tuning**\n",
       "\n",
       "Instruction tuning focuses on training LLMs to follow instructions given in natural language. This makes them more versatile and better at zero-shot or few-shot learning.\n",
       "\n",
       "*   **Description:** The LLM is trained on a dataset of (instruction, input, output) triplets. The goal is to teach the model to understand and execute a wide range of tasks based on textual instructions.\n",
       "*   **Pros:** Improves the model's ability to generalize to unseen tasks, makes it more user-friendly, and enhances its performance in zero-shot and few-shot settings.\n",
       "*   **Cons:** Requires carefully curated instruction datasets.\n",
       "*   **When to use:** To create general-purpose chatbots, assistants, or models that can perform many different tasks without explicit fine-tuning for each.\n",
       "\n",
       "**III. Reinforcement Learning from Human Feedback (RLHF)**\n",
       "\n",
       "RLHF is a powerful technique for aligning LLM behavior with human preferences, making them safer, more helpful, and less prone to generating undesirable content.\n",
       "\n",
       "*   **Description:**\n",
       "    1.  **Supervised Fine-tuning (SFT):** A base LLM is fine-tuned on a dataset of high-quality demonstrations.\n",
       "    2.  **Reward Model Training:** Human annotators rank different model outputs for the same prompt. A reward model is trained to predict these human preferences.\n",
       "    3.  **Reinforcement Learning:** The LLM is further fine-tuned using reinforcement learning (e.g., PPO algorithm), where the reward model provides feedback to guide the LLM towards generating outputs that are preferred by humans.\n",
       "*   **Pros:** Crucial for aligning LLMs with human values, improving safety, reducing toxicity, and enhancing helpfulness.\n",
       "*   **Cons:** Complex to implement, requires significant human annotation effort, and can be computationally intensive.\n",
       "*   **When to use:** To create safe, ethical, and helpful AI assistants, chatbots, and other applications where human alignment is critical.\n",
       "\n",
       "**IV. Prompt Engineering (Not strictly \"tuning\" but a related adaptation method)**\n",
       "\n",
       "While not modifying the model's weights, prompt engineering is a crucial technique for guiding LLM behavior.\n",
       "\n",
       "*   **Description:** Carefully crafting the input prompt to elicit the desired output from the LLM. This can involve providing context, examples (few-shot learning), specifying the desired format, or using specific keywords.\n",
       "*   **Pros:** No training required, quick to iterate, can be very effective for many tasks.\n",
       "*   **Cons:** Can be brittle, requires experimentation, and may not be sufficient for complex or highly specialized tasks.\n",
       "*   **When to use:** For quick experimentation, when you don't have the resources for fine-tuning, or to complement fine-tuned models.\n",
       "\n",
       "**V. Other Advanced Techniques**\n",
       "\n",
       "*   **Knowledge Distillation:** Training a smaller, \"student\" model to mimic the behavior of a larger, \"teacher\" LLM. This is useful for deploying LLMs on resource-constrained devices.\n",
       "*   **Continual Learning:** Methods that allow LLMs to learn new information or adapt to new tasks over time without forgetting previously learned knowledge.\n",
       "*   **Domain Adaptation:** Specifically tailoring an LLM to a particular domain (e.g., medical, legal, financial) by training on domain-specific data. This can be a form of fine-tuning.\n",
       "\n",
       "**Choosing the Right Method:**\n",
       "\n",
       "The best method for tuning an LLM depends on several factors:\n",
       "\n",
       "*   **Task Complexity:** Simple tasks might be solvable with prompt engineering, while complex tasks often require fine-tuning.\n",
       "*   **Data Availability:** The amount and quality of your task-specific data will influence your choice.\n",
       "*   **Computational Resources:** Full fine-tuning is resource-intensive, while PEFT methods are more efficient.\n",
       "*   **Desired Performance:** If peak performance is critical, full fine-tuning might be necessary, but PEFT often offers a good trade-off.\n",
       "*   **Safety and Alignment Requirements:** RLHF is essential for ensuring safe and aligned behavior.\n",
       "*   **Deployment Constraints:** For edge devices or mobile applications, parameter-efficient methods or distillation are preferred.\n",
       "\n",
       "In practice, a combination of these methods is often used. For example, an LLM might first be instruction-tuned, then further fine-tuned using LoRA for a specific task, and finally aligned with human preferences using RLHF."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'gemini-2.5-flash-lite', 'input_tokens': 22, 'output_tokens': 1774}\n"
     ]
    }
   ],
   "source": [
    "# Answer here\n",
    "#gemini-2.5-flash-lite\n",
    "input_prompt = [\"What kind of methods that can be used to tune a large language model?\"]\n",
    "text_response1, logs1 = prompt_gemini(input_prompt = input_prompt,model_name=\"gemini-2.5-flash-lite\", with_tokens_info = True)\n",
    "display(Markdown(\"# ===== gemini-2.5-flash-lite Output =====\"))\n",
    "display(Markdown(text_response1))\n",
    "print(logs1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# ===== gemini-2.5-flash Output ====="
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Tuning a Large Language Model (LLM) refers to the process of adapting a pre-trained model to perform better on specific tasks, align with human preferences, or specialize in a particular domain. Given the immense size of LLMs, full fine-tuning (updating all parameters) is often prohibitively expensive. This has led to the development of various efficient tuning methods.\n",
       "\n",
       "Here's a breakdown of the main methods:\n",
       "\n",
       "---\n",
       "\n",
       "### 1. Full Fine-tuning (FFT)\n",
       "\n",
       "*   **Description:** This is the traditional approach where *all* parameters of the pre-trained LLM are updated during training on a new dataset.\n",
       "*   **How it works:** The entire model is loaded, and gradients are computed and applied to every single weight in the network based on the new training data and loss function.\n",
       "*   **Pros:**\n",
       "    *   Potentially achieves the highest performance for the target task/domain.\n",
       "    *   Most flexible, as the entire model can adapt.\n",
       "*   **Cons:**\n",
       "    *   **Extremely computationally expensive:** Requires significant GPU memory and processing power.\n",
       "    *   **Time-consuming:** Training can take days or weeks.\n",
       "    *   **Large storage:** The fine-tuned model checkpoint is as large as the original pre-trained model.\n",
       "    *   **Catastrophic forgetting:** Risk of losing general capabilities learned during pre-training if the fine-tuning data is too narrow or small.\n",
       "*   **When to use:** When you have ample computational resources, a large and high-quality domain-specific dataset, and the highest possible performance is critical, or for smaller base models.\n",
       "\n",
       "---\n",
       "\n",
       "### 2. Parameter-Efficient Fine-tuning (PEFT)\n",
       "\n",
       "PEFT methods aim to reduce the computational and memory costs of fine-tuning by only updating a small subset of parameters or adding a few new trainable parameters, while keeping the vast majority of the pre-trained model frozen.\n",
       "\n",
       "#### a. LoRA (Low-Rank Adaptation)\n",
       "\n",
       "*   **Description:** LoRA injects small, trainable matrices into the existing weight matrices of the pre-trained model.\n",
       "*   **How it works:** For each large weight matrix $W_0$ in the original model, LoRA adds a low-rank decomposition $W_0 + BA$, where $B$ and $A$ are much smaller matrices. Only $A$ and $B$ are trained, while $W_0$ remains frozen. The rank $r$ (dimension of the inner product of $A$ and $B$) is a hyperparameter.\n",
       "*   **Pros:**\n",
       "    *   **Highly memory efficient:** Only a tiny fraction of parameters are trained.\n",
       "    *   **Faster training:** Reduced computational overhead.\n",
       "    *   **Small checkpoint size:** The LoRA adapters are very small and can be easily swapped or merged.\n",
       "    *   **No inference latency:** The adapters can be merged into the base model weights for deployment.\n",
       "*   **Cons:**\n",
       "    *   May not always reach the absolute peak performance of full fine-tuning, especially for highly complex tasks.\n",
       "*   **When to use:** Most common and recommended method for efficient fine-tuning, especially when resources are limited, or you need to adapt a model to multiple tasks/domains.\n",
       "\n",
       "#### b. QLoRA (Quantized Low-Rank Adaptation)\n",
       "\n",
       "*   **Description:** QLoRA is an extension of LoRA that quantizes the pre-trained model to 4-bit precision (e.g., using NF4 quantization) and then applies LoRA adapters.\n",
       "*   **How it works:** The base LLM is loaded in a quantized (e.g., 4-bit) format, significantly reducing its memory footprint. LoRA adapters are then trained on top of this quantized model. The gradients are computed in 16-bit and then used to update the 4-bit quantized weights.\n",
       "*   **Pros:**\n",
       "    *   **Massive memory savings:** Enables fine-tuning very large models (e.g., 70B parameters) on consumer-grade GPUs (e.g., 24GB VRAM).\n",
       "    *   Retains most of LoRA's benefits (small checkpoint, faster training).\n",
       "*   **Cons:**\n",
       "    *   Slight potential performance degradation due to quantization, though often negligible.\n",
       "*   **When to use:** When you need to fine-tune very large models but have limited GPU memory.\n",
       "\n",
       "#### c. Prompt Tuning / Prefix Tuning / P-Tuning\n",
       "\n",
       "*   **Description:** These methods involve adding a small, trainable \"virtual prompt\" (a sequence of continuous vectors) to the input of the LLM, while keeping the entire LLM frozen.\n",
       "*   **How it works:** Instead of modifying the model's weights, a short sequence of trainable vectors is prepended to the input embeddings. The model then processes the combined sequence (virtual prompt + actual input). Only these virtual prompt vectors are updated during training.\n",
       "*   **Pros:**\n",
       "    *   **Extremely parameter-efficient:** Only a few hundred or thousand parameters are trained.\n",
       "    *   **Very small checkpoint:** The \"tuned model\" is just the virtual prompt vectors.\n",
       "    *   **No inference latency:** The virtual prompt is just part of the input.\n",
       "*   **Cons:**\n",
       "    *   Can be less performant than LoRA or full fine-tuning for complex tasks.\n",
       "    *   Performance can be sensitive to the length and initialization of the virtual prompt.\n",
       "*   **When to use:** When extreme efficiency is paramount, and the task is relatively simple, or when you need to quickly adapt a model to many different tasks without storing many large model copies.\n",
       "\n",
       "#### d. Adapter-based Methods\n",
       "\n",
       "*   **Description:** Adapter methods insert small, task-specific neural network modules (adapters) between the layers of the pre-trained LLM.\n",
       "*   **How it works:** The pre-trained LLM's weights are frozen. Small adapter modules, typically consisting of a down-projection, a non-linearity, and an up-projection, are inserted after attention or feed-forward layers. Only the parameters of these adapter modules are trained.\n",
       "*   **Pros:**\n",
       "    *   **Modular:** Different adapters can be trained for different tasks and easily swapped.\n",
       "    *   **Parameter-efficient:** Only the adapter weights are updated.\n",
       "*   **Cons:**\n",
       "    *   **Increased inference latency:** The additional adapter layers add computational steps during inference.\n",
       "    *   Can be more complex to implement than LoRA.\n",
       "*   **When to use:** When you need to manage multiple tasks with a single base model and are willing to accept a slight increase in inference time.\n",
       "\n",
       "---\n",
       "\n",
       "### 3. Reinforcement Learning from Human Feedback (RLHF)\n",
       "\n",
       "*   **Description:** RLHF is a powerful technique used to align LLMs with human preferences, making them more helpful, harmless, and honest. It's a multi-stage process that often builds upon supervised fine-tuning.\n",
       "*   **How it works (Simplified):**\n",
       "    1.  **Supervised Fine-tuning (SFT):** The base LLM is first fine-tuned on a dataset of high-quality human-written demonstrations (e.g., instruction-following examples). This initial step makes the model capable of following instructions.\n",
       "    2.  **Reward Model (RM) Training:** A separate model (often a smaller LLM) is trained to predict human preferences. Humans rank or score different model outputs for a given prompt. The RM learns to assign a \"reward\" score to an LLM's response based on these human preferences.\n",
       "    3.  **Reinforcement Learning (RL):** The SFT model is then fine-tuned using an RL algorithm (e.g., Proximal Policy Optimization - PPO). The RM acts as the reward function, guiding the LLM to generate responses that maximize the predicted human preference score.\n",
       "*   **Pros:**\n",
       "    *   Produces highly aligned, conversational, and safe models (e.g., ChatGPT, Claude).\n",
       "    *   Can significantly improve the quality and helpfulness of responses.\n",
       "*   **Cons:**\n",
       "    *   **Extremely complex and resource-intensive:** Requires significant engineering effort, large amounts of human-labeled preference data, and substantial compute.\n",
       "    *   **Data collection is challenging:** Gathering high-quality human preference data is expensive and time-consuming.\n",
       "    *   Can introduce biases present in the human feedback.\n",
       "*   **When to use:** For developing general-purpose conversational AI, chatbots, or models that need to adhere strictly to ethical guidelines and human values.\n",
       "\n",
       "---\n",
       "\n",
       "### 4. Instruction Tuning\n",
       "\n",
       "*   **Description:** A form of supervised fine-tuning where the model is trained on a dataset of (instruction, output) pairs. The goal is to teach the model to follow instructions and generalize to new, unseen instructions.\n",
       "*   **How it works:** The model is fine-tuned on datasets like Alpaca, FLAN, or Dolly, which consist of prompts formulated as instructions and their corresponding desired responses. This can be done with full fine-tuning or PEFT methods like LoRA.\n",
       "*   **Pros:**\n",
       "    *   Significantly improves the model's ability to follow instructions and perform zero-shot/few-shot tasks.\n",
       "    *   Makes the model more versatile and user-friendly.\n",
       "*   **Cons:**\n",
       "    *   Requires high-quality instruction datasets, which can be expensive to create or curate.\n",
       "*   **When to use:** As a foundational step for making an LLM more generally useful and instruction-following, often preceding or integrated with RLHF.\n",
       "\n",
       "---\n",
       "\n",
       "### 5. Prompt Engineering / In-Context Learning\n",
       "\n",
       "*   **Description:** While not \"tuning\" the model's weights, prompt engineering is a crucial method for guiding an LLM's behavior without any training. It involves carefully crafting the input prompt to elicit the desired output.\n",
       "*   **How it works:**\n",
       "    *   **Zero-shot prompting:** Giving an instruction without examples.\n",
       "    *   **Few-shot prompting:** Providing a few examples of input-output pairs within the prompt to demonstrate the desired task.\n",
       "    *   **Chain-of-Thought (CoT) prompting:** Encouraging the model to \"think step-by-step\" to improve reasoning.\n",
       "    *   **Self-consistency:** Generating multiple CoT paths and taking a majority vote.\n",
       "    *   **Tree-of-Thought:** Exploring multiple reasoning paths in a tree structure.\n",
       "*   **Pros:**\n",
       "    *   **No training required:** Instant results, highly flexible.\n",
       "    *   **Cost-effective:** No compute needed for training.\n",
       "    *   Can unlock powerful capabilities of pre-trained models.\n",
       "*   **Cons:**\n",
       "    *   Performance can be limited compared to fine-tuning for complex or highly specialized tasks.\n",
       "    *   Sensitive to prompt wording; finding the optimal prompt can be an art.\n",
       "    *   Doesn't fundamentally change the model's underlying knowledge or biases.\n",
       "*   **When to use:** For quick experimentation, prototyping, or when fine-tuning is not feasible or necessary. Often the first approach to try.\n",
       "\n",
       "---\n",
       "\n",
       "### Key Considerations When Choosing a Method:\n",
       "\n",
       "*   **Computational Resources:** GPU memory, processing power, and time available.\n",
       "*   **Dataset Size and Quality:** The amount and relevance of your training data.\n",
       "*   **Target Task/Domain:** How specialized or complex is the task?\n",
       "*   **Desired Performance:** What level of accuracy or alignment is required?\n",
       "*   **Model Size:** Larger models benefit more from PEFT methods.\n",
       "*   **Deployment Constraints:** Inference latency, model storage size.\n",
       "\n",
       "Often, a combination of these methods is used, for example, starting with instruction tuning using QLoRA, followed by RLHF for alignment."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'gemini-2.5-flash', 'input_tokens': 22, 'output_tokens': 2512}\n"
     ]
    }
   ],
   "source": [
    "#gemini-2.5-flash\n",
    "input_prompt = [\"What kind of methods that can be used to tune a large language model?\"]\n",
    "text_response2, logs2 = prompt_gemini(input_prompt = input_prompt,model_name=\"gemini-2.5-flash\", with_tokens_info = True)\n",
    "display(Markdown(\"# ===== gemini-2.5-flash Output =====\"))\n",
    "display(Markdown(text_response2))\n",
    "print(logs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **Difference Between gemini-2.5-flash-lite and gemini-2.5-flash**\n",
    "\n",
    "**Flash-lite**Delivers a more instructional and easy-to-read explanation, using simplified concepts, clear categorization, and minimal technical depth. Its tone is approachable, and the content focuses on high-level understanding. \n",
    "\n",
    "**Flash** Provides a significantly more detailed, technically rich, and research-oriented answer. It includes engineering-level descriptions, mathematical notation, implementation mechanisms, and extensive domain-specific terminology, resulting in higher information density and longer output. \n",
    "\n",
    "In essence, Flash-lite is suited for conceptual overviews, while Flash is tailored for expert-level analysis requiring depth, precision, and comprehensive technical coverage.\n",
    "\n",
    "|                                                  | Input Tokens | Output Tokens |  Tokens |\n",
    "| -------------------------------------------------- | ------------ | ------------- | -------- |\n",
    "| **gemini-2.5-flash-lite**                      | 22           | 1774          | **1796** |\n",
    "| **gemini-2.5-flash**                           | 22           | 2512          | **2534** |\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# ===== gemini-2.5-flash-lite Output ---AI expert ====="
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Tuning a large language model (LLM) is a crucial step to adapt its general capabilities to specific tasks, domains, or desired behaviors. There are several categories of methods, each with its own strengths and weaknesses. Here's a breakdown of the most common and effective approaches:\n",
       "\n",
       "## 1. Fine-tuning (Full Fine-tuning)\n",
       "\n",
       "This is the most traditional and comprehensive method.\n",
       "\n",
       "*   **How it works:** You take a pre-trained LLM and continue training it on a new, task-specific dataset. This involves updating *all* the parameters of the model.\n",
       "*   **Pros:**\n",
       "    *   Can achieve state-of-the-art performance on the target task.\n",
       "    *   Allows the model to deeply learn the nuances of the new data.\n",
       "*   **Cons:**\n",
       "    *   **Computationally expensive:** Requires significant GPU resources and time.\n",
       "    *   **Large storage requirements:** The fine-tuned model is as large as the original pre-trained model.\n",
       "    *   **Catastrophic forgetting:** The model might forget some of its general knowledge from pre-training if the fine-tuning dataset is very different or too small.\n",
       "*   **When to use:** When you have a substantial amount of high-quality, task-specific data and the computational resources to support it. This is often the go-to for achieving the best possible performance on a specific downstream task.\n",
       "\n",
       "## 2. Parameter-Efficient Fine-Tuning (PEFT) Methods\n",
       "\n",
       "These methods aim to reduce the computational and storage costs of fine-tuning by only updating a small subset of the model's parameters or by introducing a small number of new parameters.\n",
       "\n",
       "### a) Adapter-based Methods\n",
       "\n",
       "*   **How it works:** Small, trainable \"adapter\" modules are inserted between the layers of the pre-trained LLM. Only the parameters of these adapters are trained, while the original LLM weights remain frozen.\n",
       "*   **Examples:** Adapters, LoRA (Low-Rank Adaptation), QLoRA (Quantized LoRA).\n",
       "*   **Pros:**\n",
       "    *   Significantly reduces the number of trainable parameters.\n",
       "    *   Much faster training and lower memory usage compared to full fine-tuning.\n",
       "    *   Smaller storage footprint for the fine-tuned components.\n",
       "    *   Less prone to catastrophic forgetting.\n",
       "*   **Cons:**\n",
       "    *   May not reach the absolute peak performance of full fine-tuning in all cases.\n",
       "    *   Adds a slight inference latency due to the extra adapter layers.\n",
       "*   **When to use:** When computational resources are limited, you need to fine-tune for many different tasks, or you want to avoid catastrophic forgetting. LoRA and QLoRA are currently very popular and effective.\n",
       "\n",
       "### b) Prompt Tuning / Prefix Tuning\n",
       "\n",
       "*   **How it works:** Instead of modifying the model's weights, these methods learn a small set of continuous \"prompt\" or \"prefix\" embeddings that are prepended to the input. The LLM's weights are frozen.\n",
       "*   **Examples:** Prompt Tuning, Prefix Tuning, P-Tuning.\n",
       "*   **Pros:**\n",
       "    *   Extremely parameter-efficient (only a few hundred or thousand parameters to train).\n",
       "    *   Very fast training.\n",
       "    *   No modification to the original LLM architecture.\n",
       "*   **Cons:**\n",
       "    *   Performance can be more sensitive to initialization and hyperparameter tuning.\n",
       "    *   May not be as effective as adapter-based methods for complex tasks.\n",
       "*   **When to use:** For tasks where a simple prompt can effectively guide the model, and extreme parameter efficiency is paramount.\n",
       "\n",
       "### c) LoRA (Low-Rank Adaptation)\n",
       "\n",
       "*   **How it works:** This is a very popular PEFT method. It injects trainable low-rank decomposition matrices into specific layers (typically attention layers) of the pre-trained model. Instead of updating the full weight matrix, it updates these smaller, low-rank matrices.\n",
       "*   **Pros:**\n",
       "    *   Highly effective at reducing trainable parameters while maintaining performance.\n",
       "    *   Can be combined with quantization (QLoRA) for even greater efficiency.\n",
       "    *   Relatively easy to implement and integrate.\n",
       "*   **Cons:**\n",
       "    *   Still requires some computational resources, though much less than full fine-tuning.\n",
       "*   **When to use:** A strong default choice for most PEFT scenarios due to its balance of efficiency and performance.\n",
       "\n",
       "### d) QLoRA (Quantized LoRA)\n",
       "\n",
       "*   **How it works:** An optimization of LoRA that uses quantization techniques (e.g., 4-bit NormalFloat) to further reduce memory usage. It quantizes the pre-trained model weights to a lower precision while keeping the LoRA adapters in higher precision during training.\n",
       "*   **Pros:**\n",
       "    *   Enables fine-tuning of very large models on consumer-grade hardware.\n",
       "    *   Significant memory savings.\n",
       "*   **Cons:**\n",
       "    *   Potential for slight degradation in performance due to quantization, though often negligible.\n",
       "*   **When to use:** When you need to fine-tune extremely large models (e.g., 65B parameters) on limited hardware.\n",
       "\n",
       "## 3. Instruction Tuning\n",
       "\n",
       "*   **How it works:** This is a form of fine-tuning where the model is trained on a dataset of instructions and their corresponding outputs. The goal is to teach the model to follow instructions and perform a wide range of tasks in a zero-shot or few-shot manner.\n",
       "*   **Pros:**\n",
       "    *   Improves the model's ability to generalize to new, unseen tasks described by instructions.\n",
       "    *   Enhances conversational abilities and task completion.\n",
       "*   **Cons:**\n",
       "    *   Requires a diverse and well-curated instruction dataset.\n",
       "    *   Can be computationally intensive if done on a large scale.\n",
       "*   **When to use:** To make LLMs more versatile and better at understanding and executing user commands. Many modern LLMs are instruction-tuned.\n",
       "\n",
       "## 4. Reinforcement Learning from Human Feedback (RLHF)\n",
       "\n",
       "*   **How it works:** This is a multi-stage process:\n",
       "    1.  **Supervised Fine-tuning (SFT):** The LLM is fine-tuned on a dataset of high-quality demonstrations.\n",
       "    2.  **Reward Model Training:** Human annotators rank different model outputs for the same prompt. A separate reward model is trained to predict these human preferences.\n",
       "    3.  **Reinforcement Learning:** The LLM is further fine-tuned using reinforcement learning (e.g., PPO algorithm), where the reward model provides the reward signal.\n",
       "*   **Pros:**\n",
       "    *   Aligns the model's behavior with human values, safety, and preferences.\n",
       "    *   Can lead to more helpful, honest, and harmless outputs.\n",
       "*   **Cons:**\n",
       "    *   Complex and resource-intensive to implement.\n",
       "    *   Requires significant human annotation effort.\n",
       "    *   Can be challenging to balance reward signals effectively.\n",
       "*   **When to use:** To make LLMs safer, more aligned with human intent, and to improve their helpfulness and conversational quality. This is a key technique behind models like ChatGPT.\n",
       "\n",
       "## 5. Direct Preference Optimization (DPO)\n",
       "\n",
       "*   **How it works:** A more recent and simpler alternative to RLHF. DPO directly optimizes the LLM on a dataset of human preferences (pairs of preferred and dispreferred responses) without needing to train a separate reward model or use complex RL algorithms.\n",
       "*   **Pros:**\n",
       "    *   Simpler to implement than RLHF.\n",
       "    *   More stable training.\n",
       "    *   Often achieves comparable or better results than RLHF.\n",
       "*   **Cons:**\n",
       "    *   Still requires a dataset of human preferences.\n",
       "*   **When to use:** As a more efficient and stable alternative to RLHF for aligning LLMs with human preferences.\n",
       "\n",
       "## 6. Few-Shot Learning / In-Context Learning\n",
       "\n",
       "*   **How it works:** This isn't strictly \"tuning\" in the sense of updating model weights. Instead, you provide the LLM with a few examples of the task directly within the prompt. The model then uses these examples to infer the task and generate an output for a new query.\n",
       "*   **Pros:**\n",
       "    *   No training required, extremely fast to adapt.\n",
       "    *   No computational cost for adaptation.\n",
       "*   **Cons:**\n",
       "    *   Performance is limited by the LLM's inherent capabilities and the quality of the few examples.\n",
       "    *   Context window limitations can restrict the number of examples.\n",
       "    *   Can be less robust than fine-tuning.\n",
       "*   **When to use:** For quick experimentation, when you have very few examples, or when you want to leverage the LLM's existing knowledge without modifying it.\n",
       "\n",
       "## Choosing the Right Method\n",
       "\n",
       "The best method for tuning an LLM depends on several factors:\n",
       "\n",
       "*   **Task Complexity:** Simple tasks might be fine with prompt tuning or few-shot learning, while complex tasks often benefit from fine-tuning.\n",
       "*   **Data Availability:** Full fine-tuning requires a large dataset, while PEFT methods can work with smaller datasets. RLHF and DPO require preference data.\n",
       "*   **Computational Resources:** Full fine-tuning is the most demanding, followed by adapter-based PEFT, then prompt tuning, and finally few-shot learning.\n",
       "*   **Desired Performance:** For maximum performance, full fine-tuning is often the best, but PEFT methods are closing the gap.\n",
       "*   **Alignment Needs:** If aligning with human values and safety is critical, RLHF or DPO are essential.\n",
       "*   **Storage Constraints:** PEFT methods offer significant advantages in terms of storage.\n",
       "\n",
       "In practice, a combination of these methods is often used. For example, a model might be instruction-tuned first, then further aligned using RLHF or DPO, and finally adapted to a specific downstream task using LoRA."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'gemini-2.5-flash-lite', 'input_tokens': 27, 'output_tokens': 2127}\n"
     ]
    }
   ],
   "source": [
    "# System instruction -- AI expert\n",
    "input_prompt = [\"What kind of methods that can be used to tune a large language model?\"]\n",
    "SYSTEM_INSTRUCTION = \"You are an expert in AI and machine learning.\"\n",
    "text_response1, logs1 = prompt_gemini(input_prompt = input_prompt,model_name=\"gemini-2.5-flash-lite\", system_instruction = SYSTEM_INSTRUCTION, with_tokens_info = True)\n",
    "display(Markdown(\"# ===== gemini-2.5-flash-lite Output ---AI expert =====\"))\n",
    "display(Markdown(text_response1))\n",
    "print(logs1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **Effect of changing System Instruction on gemini-2.5-flash-lite**\n",
    "\n",
    "Adding the AI expert system instruction noticeably shifts the tone and depth of the gemini-2.5-flash-lite response. Compared to the original version, which was more conceptual, concise, and written in an instructional or introductory style. The modified output becomes significantly more technical, structured, and expert-oriented. The model expands each tuning method with clearer operational details, explicit pros and cons, practical use cases, and more specific terminology. It even introduces additional techniques such as DPO and P-Tuning that were not mentioned in the default response. \n",
    "\n",
    "Overall, the system instruction effectively repositions the models persona, leading to a more comprehensive, detailed, and professional explanation that resembles a technical document rather than a beginner-friendly overview.\n",
    "\n",
    "|                                                  | Input Tokens | Output Tokens |  Tokens |\n",
    "| -------------------------------------------------- | ------------ | ------------- | -------- |\n",
    "| **gemini-2.5-flash-lite**                      | 22           | 1774          | **1796**  | \n",
    "| **gemini-2.5-flash-liteAI expert system prompt** | 27           | 2127          | **2154** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_6_'></a>[**2.2 Structured Output**](#toc0_)\n",
    "\n",
    "By default, an LLM responds with unstructured, free-form text. For data mining, this is often impractical, as we need data in a predictable format to load into tools like a pandas DataFrame for analysis. **Structured output** is a powerful feature that forces the model to return its response in a specific, machine-readable format, such as JSON.\n",
    "\n",
    "The key to enabling this is to provide the model with a **response schema**. This schema acts as a strict template or blueprint that the model's output must conform to. Instead of generating a paragraph, the model will fill in the fields defined in your schema with the relevant information it extracts from the prompt.\n",
    "\n",
    "In the following code, we define this schema using Python classes. Think of each class as defining a JSON object:\n",
    "*   The **attributes** of the class (e.g., `topic_name`, `sub_title`) become the keys in the final JSON object.\n",
    "*   The **type hints** for those attributes (e.g., `str`, `list`) tell the model what kind of data is expected for each key's value.\n",
    "\n",
    "We can even nest these classes inside one another to create complex, hierarchical JSON structures. This allows us to precisely control the format of the output, transforming the LLM from a simple text generator into a reliable tool for automated and structured data extraction.\n",
    "\n",
    "[Gemini's Structured Output Documentation](https://ai.google.dev/gemini-api/docs/structured-output)\n",
    "\n",
    "For data validation of schemas Gemini API uses the Pydantic library, for more documentation on it you can check: [Pydantic](https://docs.pydantic.dev/latest/) \n",
    "\n",
    "[JSON Format Documentation](https://docs.python.org/3/library/json.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "# We define our structure schema that Gemini should follow for the output response\n",
    "\n",
    "# Subsections on the topics we query\n",
    "class Subsection(BaseModel):\n",
    "    sub_title: str\n",
    "    sub_explanation: str\n",
    "\n",
    "# The top-level structure for the entire topic analysis\n",
    "class Topic(BaseModel):\n",
    "    topic_name: str\n",
    "    subsections: list[Subsection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"topic_name\": \"Machine Learning\",\n",
      "    \"subsections\": [\n",
      "      {\n",
      "        \"sub_title\": \"Definition\",\n",
      "        \"sub_explanation\": \"Machine learning (ML) is a subset of artificial intelligence (AI) that focuses on building systems that can learn from and make decisions based on data. Instead of being explicitly programmed, ML algorithms use statistical techniques to enable systems to 'learn' from data, identify patterns, and make predictions or decisions without human intervention.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Types of Machine Learning\",\n",
      "        \"sub_explanation\": \"Common types include supervised learning (learning from labeled data), unsupervised learning (finding patterns in unlabeled data), and reinforcement learning (learning through trial and error with rewards and penalties).\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Applications\",\n",
      "        \"sub_explanation\": \"ML is used in a wide range of applications, such as image recognition, natural language processing, recommendation systems, fraud detection, and medical diagnosis.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"topic_name\": \"Data Centers\",\n",
      "    \"subsections\": [\n",
      "      {\n",
      "        \"sub_title\": \"Definition\",\n",
      "        \"sub_explanation\": \"A data center is a dedicated physical facility that an organization uses to house its critical IT infrastructure, including servers, storage systems, networking equipment, and related components. These facilities are designed to provide a secure, reliable, and controlled environment for computing operations.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Key Components\",\n",
      "        \"sub_explanation\": \"Essential components include servers, storage devices, network switches and routers, power supplies (including UPS and generators), cooling systems (HVAC), and physical security measures.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Purpose\",\n",
      "        \"sub_explanation\": \"Data centers serve as the central hub for data storage, processing, and management, enabling businesses to run applications, host websites, and manage their digital operations.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"topic_name\": \"Large Language Models (LLMs)\",\n",
      "    \"subsections\": [\n",
      "      {\n",
      "        \"sub_title\": \"Definition\",\n",
      "        \"sub_explanation\": \"Large Language Models (LLMs) are a type of artificial intelligence model that are trained on massive amounts of text data. They are designed to understand, generate, and manipulate human language. LLMs are characterized by their enormous size (billions or trillions of parameters) and their ability to perform a wide variety of natural language processing tasks.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Capabilities\",\n",
      "        \"sub_explanation\": \"LLMs can perform tasks such as text generation, translation, summarization, question answering, code generation, and creative writing. They learn complex linguistic patterns, grammar, facts, and reasoning abilities from their training data.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Underlying Technology\",\n",
      "        \"sub_explanation\": \"LLMs are typically built using deep learning architectures, most notably the Transformer architecture, which allows them to process sequential data like text very effectively.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"topic_name\": \"Relationship Between Machine Learning, Data Centers, and LLMs\",\n",
      "    \"subsections\": [\n",
      "      {\n",
      "        \"sub_title\": \"LLMs as a Product of Machine Learning\",\n",
      "        \"sub_explanation\": \"LLMs are a sophisticated application and outcome of machine learning research and development. The techniques used to train LLMs, such as deep learning and neural networks, are core machine learning concepts. Therefore, LLMs are a specific, advanced type of machine learning model.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Data Centers as the Foundation for LLMs and ML\",\n",
      "        \"sub_explanation\": \"Training and running LLMs, as well as many other complex machine learning models, requires immense computational power and vast amounts of data storage. Data centers provide the necessary infrastructure  high-performance servers, specialized hardware (like GPUs and TPUs), robust networking, and reliable power  to handle these computationally intensive tasks. Without data centers, it would be practically impossible to develop, train, and deploy LLMs at scale.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Interdependence\",\n",
      "        \"sub_explanation\": \"In essence, machine learning is the field of study and the set of techniques. LLMs are a powerful manifestation of these techniques. Data centers are the physical environments and infrastructure that enable the training, deployment, and operation of both general machine learning models and highly demanding LLMs. LLMs rely on ML principles, and both ML and LLMs rely heavily on the resources provided by data centers.\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "input_prompt = [\"Explain what are machine learning, data centers, llms and how do they relate to each other.\"]\n",
    "text_response = prompt_gemini(input_prompt = input_prompt, schema = list[Topic])\n",
    "print(text_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'topic_name': 'Machine Learning', 'subsections': [{'sub_title': 'Definition', 'sub_explanation': \"Machine learning (ML) is a subset of artificial intelligence (AI) that focuses on building systems that can learn from and make decisions based on data. Instead of being explicitly programmed, ML algorithms use statistical techniques to enable systems to 'learn' from data, identify patterns, and make predictions or decisions without human intervention.\"}, {'sub_title': 'Types of Machine Learning', 'sub_explanation': 'Common types include supervised learning (learning from labeled data), unsupervised learning (finding patterns in unlabeled data), and reinforcement learning (learning through trial and error with rewards and penalties).'}, {'sub_title': 'Applications', 'sub_explanation': 'ML is used in a wide range of applications, such as image recognition, natural language processing, recommendation systems, fraud detection, and medical diagnosis.'}]}, {'topic_name': 'Data Centers', 'subsections': [{'sub_title': 'Definition', 'sub_explanation': 'A data center is a dedicated physical facility that an organization uses to house its critical IT infrastructure, including servers, storage systems, networking equipment, and related components. These facilities are designed to provide a secure, reliable, and controlled environment for computing operations.'}, {'sub_title': 'Key Components', 'sub_explanation': 'Essential components include servers, storage devices, network switches and routers, power supplies (including UPS and generators), cooling systems (HVAC), and physical security measures.'}, {'sub_title': 'Purpose', 'sub_explanation': 'Data centers serve as the central hub for data storage, processing, and management, enabling businesses to run applications, host websites, and manage their digital operations.'}]}, {'topic_name': 'Large Language Models (LLMs)', 'subsections': [{'sub_title': 'Definition', 'sub_explanation': 'Large Language Models (LLMs) are a type of artificial intelligence model that are trained on massive amounts of text data. They are designed to understand, generate, and manipulate human language. LLMs are characterized by their enormous size (billions or trillions of parameters) and their ability to perform a wide variety of natural language processing tasks.'}, {'sub_title': 'Capabilities', 'sub_explanation': 'LLMs can perform tasks such as text generation, translation, summarization, question answering, code generation, and creative writing. They learn complex linguistic patterns, grammar, facts, and reasoning abilities from their training data.'}, {'sub_title': 'Underlying Technology', 'sub_explanation': 'LLMs are typically built using deep learning architectures, most notably the Transformer architecture, which allows them to process sequential data like text very effectively.'}]}, {'topic_name': 'Relationship Between Machine Learning, Data Centers, and LLMs', 'subsections': [{'sub_title': 'LLMs as a Product of Machine Learning', 'sub_explanation': 'LLMs are a sophisticated application and outcome of machine learning research and development. The techniques used to train LLMs, such as deep learning and neural networks, are core machine learning concepts. Therefore, LLMs are a specific, advanced type of machine learning model.'}, {'sub_title': 'Data Centers as the Foundation for LLMs and ML', 'sub_explanation': 'Training and running LLMs, as well as many other complex machine learning models, requires immense computational power and vast amounts of data storage. Data centers provide the necessary infrastructure  high-performance servers, specialized hardware (like GPUs and TPUs), robust networking, and reliable power  to handle these computationally intensive tasks. Without data centers, it would be practically impossible to develop, train, and deploy LLMs at scale.'}, {'sub_title': 'Interdependence', 'sub_explanation': 'In essence, machine learning is the field of study and the set of techniques. LLMs are a powerful manifestation of these techniques. Data centers are the physical environments and infrastructure that enable the training, deployment, and operation of both general machine learning models and highly demanding LLMs. LLMs rely on ML principles, and both ML and LLMs rely heavily on the resources provided by data centers.'}]}]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Now the response can be parsed to a python object using the JSON dictionary structure loading\n",
    "structured_resp = json.loads(text_response)\n",
    "print(structured_resp)\n",
    "print(type(structured_resp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning \n",
      "\n",
      "\t Definition \n",
      "\n",
      "\t\t Machine learning (ML) is a subset of artificial intelligence (AI) that focuses on building systems that can learn from and make decisions based on data. Instead of being explicitly programmed, ML algorithms use statistical techniques to enable systems to 'learn' from data, identify patterns, and make predictions or decisions without human intervention. \n",
      "\n",
      "\t Types of Machine Learning \n",
      "\n",
      "\t\t Common types include supervised learning (learning from labeled data), unsupervised learning (finding patterns in unlabeled data), and reinforcement learning (learning through trial and error with rewards and penalties). \n",
      "\n",
      "\t Applications \n",
      "\n",
      "\t\t ML is used in a wide range of applications, such as image recognition, natural language processing, recommendation systems, fraud detection, and medical diagnosis. \n",
      "\n",
      "Data Centers \n",
      "\n",
      "\t Definition \n",
      "\n",
      "\t\t A data center is a dedicated physical facility that an organization uses to house its critical IT infrastructure, including servers, storage systems, networking equipment, and related components. These facilities are designed to provide a secure, reliable, and controlled environment for computing operations. \n",
      "\n",
      "\t Key Components \n",
      "\n",
      "\t\t Essential components include servers, storage devices, network switches and routers, power supplies (including UPS and generators), cooling systems (HVAC), and physical security measures. \n",
      "\n",
      "\t Purpose \n",
      "\n",
      "\t\t Data centers serve as the central hub for data storage, processing, and management, enabling businesses to run applications, host websites, and manage their digital operations. \n",
      "\n",
      "Large Language Models (LLMs) \n",
      "\n",
      "\t Definition \n",
      "\n",
      "\t\t Large Language Models (LLMs) are a type of artificial intelligence model that are trained on massive amounts of text data. They are designed to understand, generate, and manipulate human language. LLMs are characterized by their enormous size (billions or trillions of parameters) and their ability to perform a wide variety of natural language processing tasks. \n",
      "\n",
      "\t Capabilities \n",
      "\n",
      "\t\t LLMs can perform tasks such as text generation, translation, summarization, question answering, code generation, and creative writing. They learn complex linguistic patterns, grammar, facts, and reasoning abilities from their training data. \n",
      "\n",
      "\t Underlying Technology \n",
      "\n",
      "\t\t LLMs are typically built using deep learning architectures, most notably the Transformer architecture, which allows them to process sequential data like text very effectively. \n",
      "\n",
      "Relationship Between Machine Learning, Data Centers, and LLMs \n",
      "\n",
      "\t LLMs as a Product of Machine Learning \n",
      "\n",
      "\t\t LLMs are a sophisticated application and outcome of machine learning research and development. The techniques used to train LLMs, such as deep learning and neural networks, are core machine learning concepts. Therefore, LLMs are a specific, advanced type of machine learning model. \n",
      "\n",
      "\t Data Centers as the Foundation for LLMs and ML \n",
      "\n",
      "\t\t Training and running LLMs, as well as many other complex machine learning models, requires immense computational power and vast amounts of data storage. Data centers provide the necessary infrastructure  high-performance servers, specialized hardware (like GPUs and TPUs), robust networking, and reliable power  to handle these computationally intensive tasks. Without data centers, it would be practically impossible to develop, train, and deploy LLMs at scale. \n",
      "\n",
      "\t Interdependence \n",
      "\n",
      "\t\t In essence, machine learning is the field of study and the set of techniques. LLMs are a powerful manifestation of these techniques. Data centers are the physical environments and infrastructure that enable the training, deployment, and operation of both general machine learning models and highly demanding LLMs. LLMs rely on ML principles, and both ML and LLMs rely heavily on the resources provided by data centers. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# So now we have an object that we can explore/use in a pythonic way for our purposes\n",
    "for topic in structured_resp:\n",
    "    print(topic[\"topic_name\"], \"\\n\")\n",
    "    # We can access each subsection as well\n",
    "    for subsection in topic[\"subsections\"]:\n",
    "        print(\"\\t\", subsection[\"sub_title\"], \"\\n\")\n",
    "        print(\"\\t\\t\", subsection[\"sub_explanation\"], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc1_5_6_1_1_'></a>[**>>> Exercise 2 (Take home):**](#toc0_)\n",
    "\n",
    "Try a prompt with your own schema structure, it needs to be completely different to the example. It should show an intuitive way to represent the text output of the model based on the prompt you chose. See the documentation for reference: https://ai.google.dev/gemini-api/docs/structured-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "# Contents of the methods\n",
    "class contents(BaseModel):\n",
    "    How_it_works: str\n",
    "    Example: str\n",
    "    Pros_Cons: str\n",
    "    When_to_use: str\n",
    "\n",
    "# The methods used to tune LLMs\n",
    "class Methods(BaseModel):\n",
    "    Method_Name: str\n",
    "    Contents:list[contents]\n",
    "   \n",
    "# The top-level structure for the Ouery analysis\n",
    "class Overview(BaseModel):\n",
    "    overall_summary: str\n",
    "    Methods: list[Methods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"overall_summary\": \"Tuning large language models (LLMs) involves adapting a pre-trained model to specific tasks or datasets. This can be achieved through various methods, each with its own strengths and weaknesses, suitable for different scenarios.\",\n",
      "    \"Methods\": [\n",
      "      {\n",
      "        \"Method_Name\": \"Fine-tuning\",\n",
      "        \"Contents\": [\n",
      "          {\n",
      "            \"How_it_works\": \"Fine-tuning involves taking a pre-trained LLM and further training it on a smaller, task-specific dataset. This process adjusts the model's weights to better perform the target task. It can involve training all layers or only a subset of the top layers.\",\n",
      "            \"Example\": \"A general LLM pre-trained on a massive corpus can be fine-tuned on a dataset of medical texts to create a model specialized in answering medical questions.\",\n",
      "            \"Pros_Cons\": \"Pros: Achieves high performance on specific tasks, adapts the model's knowledge. Cons: Can be computationally expensive, requires a labeled dataset, risks catastrophic forgetting of general knowledge if not done carefully.\",\n",
      "            \"When_to_use\": \"When high accuracy on a specific downstream task is required, and a relevant dataset is available. Useful for classification, summarization, translation, and question-answering on specialized domains.\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"Method_Name\": \"Parameter-Efficient Fine-Tuning (PEFT)\",\n",
      "        \"Contents\": [\n",
      "          {\n",
      "            \"How_it_works\": \"PEFT methods update only a small subset of the model's parameters or add a small number of new parameters, keeping the majority of the pre-trained weights frozen. Examples include LoRA (Low-Rank Adaptation), Adapters, and Prefix Tuning.\",\n",
      "            \"Example\": \"Using LoRA to fine-tune a large language model for sentiment analysis by adding small, trainable low-rank matrices to specific layers, rather than updating all weights.\",\n",
      "            \"Pros_Cons\": \"Pros: Significantly reduces computational cost and memory requirements, faster training, less prone to catastrophic forgetting, smaller storage for fine-tuned models. Cons: May not achieve the absolute peak performance of full fine-tuning in all cases.\",\n",
      "            \"When_to_use\": \"When computational resources are limited, or when fine-tuning many different tasks from the same base model. Ideal for scenarios where storage efficiency is important.\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"Method_Name\": \"Prompt Engineering\",\n",
      "        \"Contents\": [\n",
      "          {\n",
      "            \"How_it_works\": \"This method involves carefully crafting the input prompt given to the LLM to elicit the desired output, without modifying the model's weights. Techniques include few-shot learning (providing examples in the prompt), chain-of-thought prompting (asking the model to reason step-by-step), and instruction tuning.\",\n",
      "            \"Example\": \"Instead of just asking 'Translate this to French: Hello', providing a prompt like 'Translate the following English sentences to French. Example 1: English: Goodbye, French: Au revoir. Example 2: English: Thank you, French: Merci. Now translate: English: Hello, French:'\",\n",
      "            \"Pros_Cons\": \"Pros: No training required, computationally inexpensive, flexible and quick to iterate. Cons: Performance can be sensitive to prompt wording, may not be sufficient for complex tasks requiring deep domain knowledge, can be difficult to optimize.\",\n",
      "            \"When_to_use\": \"For rapid prototyping, when no labeled data is available, or for tasks that can be clearly defined with instructions and examples. Useful for zero-shot or few-shot learning scenarios.\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"Method_Name\": \"Reinforcement Learning from Human Feedback (RLHF)\",\n",
      "        \"Contents\": [\n",
      "          {\n",
      "            \"How_it_works\": \"RLHF aligns the LLM's behavior with human preferences. It typically involves training a reward model based on human rankings of model outputs, and then using reinforcement learning to fine-tune the LLM to maximize this reward.\",\n",
      "            \"Example\": \"Training a chatbot to be more helpful and less toxic by having humans rank different responses to prompts, then using RL to optimize the chatbot's responses based on these rankings.\",\n",
      "            \"Pros_Cons\": \"Pros: Improves alignment with human values and preferences, enhances safety and helpfulness. Cons: Complex to implement, requires significant human annotation effort for ranking, can be computationally intensive.\",\n",
      "            \"When_to_use\": \"When the goal is to make the LLM's outputs more aligned with human preferences, safety guidelines, or desired conversational styles. Crucial for developing responsible AI.\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"Method_Name\": \"Instruction Tuning\",\n",
      "        \"Contents\": [\n",
      "          {\n",
      "            \"How_it_works\": \"Instruction tuning is a form of fine-tuning where the model is trained on a dataset of instructions and their corresponding desired outputs. This teaches the model to follow instructions across a wide range of tasks.\",\n",
      "            \"Example\": \"Training a model on datasets like FLAN, which contains tasks formatted as instructions (e.g., 'Summarize the following article: [article text]').\",\n",
      "            \"Pros_Cons\": \"Pros: Improves generalization to unseen tasks, enhances the model's ability to follow instructions. Cons: Requires curated instruction datasets, can still be computationally intensive.\",\n",
      "            \"When_to_use\": \"To improve a model's ability to perform a wide variety of tasks described via natural language instructions, enhancing its versatility and usability.\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "input_prompt = [\"What kind of methods that can be used to tune a large language model?\"]\n",
    "text_response = prompt_gemini(input_prompt = input_prompt, schema = list[Overview])\n",
    "print(text_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_7_'></a>[**2.3 Information Extraction and Grounding:**](#toc0_)\n",
    "\n",
    "`NOTE: This whole section including the exercise is now considered a bonus section, not counted for the main grade.`\n",
    "\n",
    "When using LLMs to extract structured data from text, two main challenges arise:\n",
    "\n",
    "1.  **Trust:** LLMs can \"hallucinate\" or invent information. We need to ensure the extracted data is accurate and comes directly from the source text.\n",
    "2.  **Scalability:** We need a reliable way to extract complex information consistently from thousands of large, messy documents.\n",
    "\n",
    "The solution to these challenges is **grounding**the process of linking every piece of extracted data back to its specific origin in the source document. This creates a verifiable audit trail, building trust in the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### <a id='toc1_5_7_1_'></a>[**`langextract`: A Library for Grounded Extraction**](#toc0_)\n",
    "\n",
    "**`langextract`** is an open-source Python library from Google designed to create trustworthy data extraction pipelines. It uses LLMs to convert unstructured text into structured data with a focus on reliability and traceability.\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "*   **Precise Grounding:** Its core feature. It maps every extracted item to its exact character position in the original text, allowing for easy verification.\n",
    "*   **Reliable Structured Output:** Uses examples (few-shot prompting) to ensure the LLM's output consistently follows a predefined format.\n",
    "*   **Adaptable & No Fine-Tuning:** Can be adapted to any domain (e.g., legal, medical) simply by changing the examples and instructions, without needing to retrain a model.\n",
    "*   **Handles Long Documents:** Built to process lengthy texts that might exceed an LLM's standard context window.\n",
    "*   **Flexible LLM Support:** It is model-agnostic and works with various LLMs like Gemini, OpenAI models, and even local open-source models through Ollama.\n",
    "\n",
    "**`Github repository:`** [langextract](https://github.com/google/langextract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##### <a id='toc1_5_7_1_1_'></a>[**2.3.1 Using PDF Documents:**](#toc0_)\n",
    "\n",
    "For PDF Document information extraction we are going to use the `pymupdf` library. Documentation: [pymupdf](https://pymupdf.readthedocs.io/en/latest/)\n",
    "\n",
    "And then we are going to pass it on to langextract to get insights on the document's content.\n",
    "\n",
    "We can also process documents using Gemini, for more information you can check their documentation: [Document Understanding](https://ai.google.dev/gemini-api/docs/document-processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Extracted text from './data/documents/doc_example_review_interstellar.pdf'\n"
     ]
    }
   ],
   "source": [
    "import pymupdf\n",
    "# Extract text from the PDF and format it for the prompt\n",
    "# This is a review from the movie interstellar\n",
    "pdf_path = \"./data/documents/doc_example_review_interstellar.pdf\"\n",
    "formatted_text = \"\"\n",
    "try:\n",
    "    doc = pymupdf.open(pdf_path)\n",
    "    # In case the PDF documents have more than one page, in this example it only has one\n",
    "    for i, page in enumerate(doc):\n",
    "        text = page.get_text(\"text\")\n",
    "        # Format follows the prompt's requirement: **Page X** \"\"\"document's text\"\"\"\n",
    "        formatted_text += f'**Page {i + 1}**\\n'\n",
    "        formatted_text += f'\"\"\"\\n{text.strip()}\\n\"\"\"\\n\\n'\n",
    "    doc.close()\n",
    "    print(f\" Extracted text from '{pdf_path}'\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not read PDF: {e}\")\n",
    "    formatted_text = \"Error: Could not process PDF file.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Page 1**\n",
      "\"\"\"\n",
      "Dan Baldwin\n",
      "Group 4\n",
      "Auteur Review - Interstellar \n",
      "I believe Christopher Nolan: the director behind the 2014 sci-/adventure cinematic Interstellar, \n",
      "to be a very intellectual and imaginative inventive talent.  \n",
      "His style in his previous lms sets characters in epic unique locations, with gargantuan issues to \n",
      "face, and artistically impresses the audience with how the characters solve their problems. For \n",
      "example, in Nolans 2010 lm Inception, he tackles the idea of dreams, and sets his characters \n",
      "diving through dreams within dreams within even more dreams to complete their goals. Because \n",
      "this idea is so farfetched, and dreams are a subject in which science has made little factual \n",
      "discovery in, Nolan is free to use his creativity to present ideas such as landscapes folding in on \n",
      "themselves and corridors spinning, without seeming unrealistic. \n",
      "This brain-racking epic theme is once again evident in Interstellar, as Nolan sets his characters \n",
      "during a second American dust bowl on future Earth. The world is short of food, and will soon be \n",
      "uninhabitable. So, ex-NASA pilot Cooper (Matthew McConaughey) is summoned back to space \n",
      "travel in a bid to nd a new planet for the species to inhabit. Luckily for Cooper and his team, a \n",
      "black hole orbiting Saturn can transport them further into space to land on these potential \n",
      "planets. \n",
      "Throughout the ick, the crew explore multiple worlds - again feeding Nolans mind more \n",
      "opportunities to create crazy scenarios. For example, one planet that Cooper and his friends, \n",
      "Brand, (Anne Hathaway) and Romilly, (David Gyasi) visit initially seems like an innite sea of two \n",
      "feet deep water. Not threatening at all right? Well think again, because the crew suddenly nd out \n",
      "that a giant 100ft tidal wave is about to hit them, and they have minutes to y away. Nolan further \n",
      "increases the stakes in this scene as it is explained that every hour spent on this planet counts for \n",
      "seven years on earth, meaning the planet will be destroyed before they return if their ship sinks. \n",
      "At the climax of the lm, the crew end up sending themselves through a black hole into a \n",
      "tesseract (a 3D representation of a larger dimension) to nd the secret to harnessing gravity \n",
      "which will let the human race bend space-time in order to survive o earth. I know. Mental. \n",
      "The imagination that Nolan possesses and implicates into Interstellar is farfetched and \n",
      "wonderful, not only impressing his audience with the appealing visuals he creates, but induces \n",
      "them to think and discuss what is going on due its scientic depth. Personally, as someone who is \n",
      "bamboozled by the idea of how big the universe is, I nd it unendingly entertaining to repeatedly \n",
      "watch this lm and understanding it more each time, and can only hope the technology portrayed \n",
      "will one day come true. \n",
      "Overall, Interstellar is a clear example of Nolans auteur talent, as he once again gments yet \n",
      "another cluster of conditions for us to marvel at. With a fantastic score from world famous \n",
      "composer Hanz Zimmer, his epic, orchestral theme sets the audience in the palm of his hands as \n",
      "we stress over how we are all going to be saved once again.\n",
      "\"\"\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(formatted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our prompt and examples based on our required type of data, in this case we are going to do it having `movie reviews` in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langextract as lx\n",
    "import textwrap\n",
    "\n",
    "# Defining the extraction prompt for \"movie review\" type of data\n",
    "prompt = textwrap.dedent(\"\"\"\\\n",
    "    Extract specific opinions and their impact on the audience from this movie review.\n",
    "    Important: Use exact text verbatim from the input for extraction_text. Do not paraphrase.\n",
    "    Extract entities in order of appearance with no overlapping text spans.\n",
    "\n",
    "    Use the 'opinion_statement' class for direct judgments about film elements (like plot, score, or acting).\n",
    "    - 'subject' should be the element being reviewed.\n",
    "    - 'sentiment' should be Positive, Negative, or Neutral.\n",
    "    - 'key_phrase' should be the core descriptive words.\n",
    "\n",
    "    Use the 'audience_impact' class for phrases describing the effect on the viewer.\n",
    "    - 'emotion_evoked' should be the feeling or reaction (e.g., stress, joy, confusion).\n",
    "    - 'causal_element' is what part of the film caused the reaction.\n",
    "    - 'target_audience' is who was affected (e.g., 'the audience', 'the reviewer').\n",
    "    \"\"\")\n",
    "\n",
    "# Providing high-quality examples to guide the model\n",
    "# These examples show the model exactly how to differentiate between the two classes\n",
    "examples = [\n",
    "    # Example 1: Demonstrates a positive opinion on the plot and its direct impact on the reviewer\n",
    "    lx.data.ExampleData(\n",
    "        text=\"The film boasts a truly clever plot that kept me guessing until the very end.\",\n",
    "        extractions=[\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"opinion_statement\",\n",
    "                extraction_text=\"a truly clever plot\",\n",
    "                attributes={\n",
    "                    \"subject\": \"The plot\",\n",
    "                    \"sentiment\": \"Positive\",\n",
    "                    \"key_phrase\": \"truly clever\"\n",
    "                }\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"audience_impact\",\n",
    "                extraction_text=\"kept me guessing until the very end\",\n",
    "                attributes={\n",
    "                    \"emotion_evoked\": [\"engaged\", \"curious\"],\n",
    "                    \"causal_element\": \"The plot\",\n",
    "                    \"target_audience\": \"the reviewer\"\n",
    "                }\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    # Example 2: Shows a negative opinion and a separate audience impact caused by the soundtrack\n",
    "    lx.data.ExampleData(\n",
    "        text=\"Unfortunately, the dialogue felt clunky and unnatural, and the jarring soundtrack made the audience jump.\",\n",
    "        extractions=[\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"opinion_statement\",\n",
    "                extraction_text=\"the dialogue felt clunky and unnatural\",\n",
    "                attributes={\n",
    "                    \"subject\": \"The dialogue\",\n",
    "                    \"sentiment\": \"Negative\",\n",
    "                    \"key_phrase\": \"clunky and unnatural\"\n",
    "                }\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"audience_impact\",\n",
    "                extraction_text=\"made the audience jump\",\n",
    "                attributes={\n",
    "                    \"emotion_evoked\": [\"startled\", \"on edge\"],\n",
    "                    \"causal_element\": \"The soundtrack\",\n",
    "                    \"target_audience\": \"the audience\"\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define our main function to call for langextract information extraction, note that there are some constants in the functions that we are not going to change for the example but it would be required to explore and understand in the exercise. In this function we obtain the resulting raw extracted information into a .jsonl file and the visualization into a .html file. Check the documentation for more information.\n",
    "\n",
    "The files will be saved in the following directory: `results/info_extractions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import langextract as lx\n",
    "\n",
    "# We define our main langextract function \n",
    "def grounded_info_extraction(input_documents, prompt, examples, file_name, model_id =\"gemini-2.5-flash-lite\", extraction_passes = 1, max_workers = 5, max_char_buffer = 2000):\n",
    "    result = lx.extract(\n",
    "        text_or_documents=input_documents,\n",
    "        prompt_description=prompt,\n",
    "        examples=examples,\n",
    "        model_id=model_id,\n",
    "        extraction_passes=extraction_passes,    # Improves recall through multiple passes over the same text, needs temperature above 0.0\n",
    "        max_workers=max_workers,         # Parallel processing for speed, remember there are API call rate limits, so do not abuse\n",
    "        max_char_buffer=max_char_buffer    # Smaller contexts for better accuracy, currently: 1000 characters per batch\n",
    "    )\n",
    "\n",
    "    # Display results\n",
    "    print(f\"Extracted {len(result.extractions)} entities:\\n\")\n",
    "    for extraction in result.extractions:\n",
    "        print(f\" {extraction.extraction_class}: '{extraction.extraction_text}'\")\n",
    "        if extraction.attributes:\n",
    "            for key, value in extraction.attributes.items():\n",
    "                print(f\"  - {key}: {value}\")\n",
    "    \n",
    "    output_dir = \"./results/info_extractions\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # Save results to JSONL\n",
    "    lx.io.save_annotated_documents([result], output_name=f\"{file_name}.jsonl\", output_dir=output_dir)\n",
    "\n",
    "    # Generate interactive visualization\n",
    "    html_content = lx.visualize(f\"{output_dir}/{file_name}.jsonl\")\n",
    "    with open(f\"{output_dir}/{file_name}_vis.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        if hasattr(html_content, 'data'):\n",
    "            f.write(html_content.data)\n",
    "        else:\n",
    "            f.write(html_content)\n",
    "\n",
    "    print(f\" Visualization saved to {output_dir}/{file_name}_vis.html\")\n",
    "    \n",
    "    # returning html content for display\n",
    "    return html_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google_genai._api_client:Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 13 entities:\n",
      "\n",
      " opinion_statement: 'a very intellectual and imaginative inventive talent'\n",
      "  - subject: Christopher Nolan\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: very intellectual and imaginative inventive talent\n",
      " opinion_statement: 'artistically impresses the audience'\n",
      "  - subject: Nolan's style\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: artistically impresses\n",
      " opinion_statement: 'This brain-racking epic theme is once again evident in Interstellar,'\n",
      "  - subject: The theme\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: brain-racking epic theme\n",
      " opinion_statement: 'crazy scenarios'\n",
      "  - subject: Nolan's mind\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: crazy\n",
      " opinion_statement: 'Not threatening at all right?'\n",
      "  - subject: The planet\n",
      "  - sentiment: Neutral\n",
      "  - key_phrase: Not threatening at all\n",
      " opinion_statement: 'a giant 100ft tidal wave is about to hit them'\n",
      "  - subject: The tidal wave\n",
      "  - sentiment: Negative\n",
      "  - key_phrase: giant 100ft tidal wave\n",
      " audience_impact: 'minutes to y away'\n",
      "  - emotion_evoked: ['stress', 'urgency']\n",
      "  - causal_element: The tidal wave\n",
      "  - target_audience: the crew\n",
      " opinion_statement: 'farfetched and wonderful'\n",
      "  - subject: The imagination that Nolan possesses and implicates into Interstellar\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: farfetched and wonderful\n",
      " audience_impact: 'not only impressing his audience with the appealing visuals he creates, but induces them to think and discuss what is going on due its scientic depth'\n",
      "  - emotion_evoked: ['impressed', 'thoughtful', 'engaged']\n",
      "  - causal_element: The appealing visuals and scientific depth\n",
      "  - target_audience: his audience\n",
      " audience_impact: 'I nd it unendingly entertaining to repeatedly watch this lm and understanding it more each time'\n",
      "  - emotion_evoked: ['entertained', 'intellectually stimulated']\n",
      "  - causal_element: The film's complexity and depth\n",
      "  - target_audience: the reviewer\n",
      " opinion_statement: 'a clear example of Nolans auteur talent'\n",
      "  - subject: Interstellar\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: clear example of Nolans auteur talent\n",
      " opinion_statement: 'fantastic score'\n",
      "  - subject: The score\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: fantastic\n",
      " audience_impact: 'sets the audience in the palm of his hands as we stress over how we are all going to be saved once again'\n",
      "  - emotion_evoked: ['captivated', 'stressed']\n",
      "  - causal_element: His epic, orchestral theme\n",
      "  - target_audience: the audience\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mLangExtract\u001b[0m: Saving to \u001b[92mreview_extraction_example.jsonl\u001b[0m: 1 docs [00:00, 424.44 docs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[0m Saved \u001b[1m1\u001b[0m documents to \u001b[92mreview_extraction_example.jsonl\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[94m\u001b[1mLangExtract\u001b[0m: Loading \u001b[92mreview_extraction_example.jsonl\u001b[0m: 100%|| 8.58k/8.58k [00:00<00:00, 17.1MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[0m Loaded \u001b[1m1\u001b[0m documents from \u001b[92mreview_extraction_example.jsonl\u001b[0m\n",
      " Visualization saved to ./results/info_extractions/review_extraction_example_vis.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "html_content = grounded_info_extraction(formatted_text, prompt, examples, \"review_extraction_example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'extractions': [{'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'a very intellectual and imaginative inventive talent',\n",
       "   'char_interval': {'start_pos': 172, 'end_pos': 224},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 1,\n",
       "   'group_index': 0,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'Christopher Nolan',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'very intellectual and imaginative inventive talent'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'artistically impresses the audience',\n",
       "   'char_interval': {'start_pos': 338, 'end_pos': 373},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 2,\n",
       "   'group_index': 1,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': \"Nolan's style\",\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'artistically impresses'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'This brain-racking epic theme is once again evident in Interstellar,',\n",
       "   'char_interval': {'start_pos': 878, 'end_pos': 948},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 3,\n",
       "   'group_index': 2,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The theme',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'brain-racking epic theme'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'crazy scenarios',\n",
       "   'char_interval': {'start_pos': 1484, 'end_pos': 1499},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 4,\n",
       "   'group_index': 3,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': \"Nolan's mind\",\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'crazy'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'Not threatening at all right?',\n",
       "   'char_interval': {'start_pos': 1676, 'end_pos': 1705},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 5,\n",
       "   'group_index': 4,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The planet',\n",
       "    'sentiment': 'Neutral',\n",
       "    'key_phrase': 'Not threatening at all'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'a giant 100ft tidal wave is about to hit them',\n",
       "   'char_interval': {'start_pos': 1764, 'end_pos': 1809},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 6,\n",
       "   'group_index': 5,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The tidal wave',\n",
       "    'sentiment': 'Negative',\n",
       "    'key_phrase': 'giant 100ft tidal wave'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'minutes to y away',\n",
       "   'char_interval': {'start_pos': 1825, 'end_pos': 1843},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 7,\n",
       "   'group_index': 6,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['stress', 'urgency'],\n",
       "    'causal_element': 'The tidal wave',\n",
       "    'target_audience': 'the crew'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'farfetched and wonderful',\n",
       "   'char_interval': {'start_pos': 2418, 'end_pos': 2443},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 1,\n",
       "   'group_index': 0,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The imagination that Nolan possesses and implicates into Interstellar',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'farfetched and wonderful'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'not only impressing his audience with the appealing visuals he creates, but induces them to think and discuss what is going on due its scientic depth',\n",
       "   'char_interval': {'start_pos': 2445, 'end_pos': 2596},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 2,\n",
       "   'group_index': 1,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['impressed', 'thoughtful', 'engaged'],\n",
       "    'causal_element': 'The appealing visuals and scientific depth',\n",
       "    'target_audience': 'his audience'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'I nd it unendingly entertaining to repeatedly watch this lm and understanding it more each time',\n",
       "   'char_interval': {'start_pos': 2680, 'end_pos': 2778},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 3,\n",
       "   'group_index': 2,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['entertained',\n",
       "     'intellectually stimulated'],\n",
       "    'causal_element': \"The film's complexity and depth\",\n",
       "    'target_audience': 'the reviewer'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'a clear example of Nolans auteur talent',\n",
       "   'char_interval': {'start_pos': 2876, 'end_pos': 2916},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 4,\n",
       "   'group_index': 3,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'Interstellar',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'clear example of Nolans auteur talent'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'fantastic score',\n",
       "   'char_interval': {'start_pos': 3006, 'end_pos': 3021},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 5,\n",
       "   'group_index': 4,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The score',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'fantastic'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'sets the audience in the palm of his hands as we stress over how we are all going to be saved once again',\n",
       "   'char_interval': {'start_pos': 3090, 'end_pos': 3195},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 6,\n",
       "   'group_index': 5,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['captivated', 'stressed'],\n",
       "    'causal_element': 'His epic, orchestral theme',\n",
       "    'target_audience': 'the audience'}}],\n",
       " 'text': '**Page 1**\\n\"\"\"\\nDan Baldwin\\nGroup 4\\nAuteur Review - Interstellar \\nI believe Christopher Nolan: the director behind the 2014 sci-/adventure cinematic Interstellar, \\nto be a very intellectual and imaginative inventive talent.  \\nHis style in his previous lms sets characters in epic unique locations, with gargantuan issues to \\nface, and artistically impresses the audience with how the characters solve their problems. For \\nexample, in Nolans 2010 lm Inception, he tackles the idea of dreams, and sets his characters \\ndiving through dreams within dreams within even more dreams to complete their goals. Because \\nthis idea is so farfetched, and dreams are a subject in which science has made little factual \\ndiscovery in, Nolan is free to use his creativity to present ideas such as landscapes folding in on \\nthemselves and corridors spinning, without seeming unrealistic. \\nThis brain-racking epic theme is once again evident in Interstellar, as Nolan sets his characters \\nduring a second American dust bowl on future Earth. The world is short of food, and will soon be \\nuninhabitable. So, ex-NASA pilot Cooper (Matthew McConaughey) is summoned back to space \\ntravel in a bid to nd a new planet for the species to inhabit. Luckily for Cooper and his team, a \\nblack hole orbiting Saturn can transport them further into space to land on these potential \\nplanets. \\nThroughout the ick, the crew explore multiple worlds - again feeding Nolans mind more \\nopportunities to create crazy scenarios. For example, one planet that Cooper and his friends, \\nBrand, (Anne Hathaway) and Romilly, (David Gyasi) visit initially seems like an innite sea of two \\nfeet deep water. Not threatening at all right? Well think again, because the crew suddenly nd out \\nthat a giant 100ft tidal wave is about to hit them, and they have minutes to y away. Nolan further \\nincreases the stakes in this scene as it is explained that every hour spent on this planet counts for \\nseven years on earth, meaning the planet will be destroyed before they return if their ship sinks. \\nAt the climax of the lm, the crew end up sending themselves through a black hole into a \\ntesseract (a 3D representation of a larger dimension) to nd the secret to harnessing gravity \\nwhich will let the human race bend space-time in order to survive o earth. I know. Mental. \\nThe imagination that Nolan possesses and implicates into Interstellar is farfetched and \\nwonderful, not only impressing his audience with the appealing visuals he creates, but induces \\nthem to think and discuss what is going on due its scientic depth. Personally, as someone who is \\nbamboozled by the idea of how big the universe is, I nd it unendingly entertaining to repeatedly \\nwatch this lm and understanding it more each time, and can only hope the technology portrayed \\nwill one day come true. \\nOverall, Interstellar is a clear example of Nolans auteur talent, as he once again gments yet \\nanother cluster of conditions for us to marvel at. With a fantastic score from world famous \\ncomposer Hanz Zimmer, his epic, orchestral theme sets the audience in the palm of his hands as \\nwe stress over how we are all going to be saved once again.\\n\"\"\"\\n\\n',\n",
       " 'document_id': 'doc_7463486f'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "# We can also observe the structure of the raw extracted data\n",
    "with open(\"./results/info_extractions/review_extraction_example.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    content_extracted_raw = json.load(f)\n",
    "content_extracted_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".lx-highlight { position: relative; border-radius:3px; padding:1px 2px;}\n",
       ".lx-highlight .lx-tooltip {\n",
       "  visibility: hidden;\n",
       "  opacity: 0;\n",
       "  transition: opacity 0.2s ease-in-out;\n",
       "  background: #333;\n",
       "  color: #fff;\n",
       "  text-align: left;\n",
       "  border-radius: 4px;\n",
       "  padding: 6px 8px;\n",
       "  position: absolute;\n",
       "  z-index: 1000;\n",
       "  bottom: 125%;\n",
       "  left: 50%;\n",
       "  transform: translateX(-50%);\n",
       "  font-size: 12px;\n",
       "  max-width: 240px;\n",
       "  white-space: normal;\n",
       "  box-shadow: 0 2px 6px rgba(0,0,0,0.3);\n",
       "}\n",
       ".lx-highlight:hover .lx-tooltip { visibility: visible; opacity:1; }\n",
       ".lx-animated-wrapper { max-width: 100%; font-family: Arial, sans-serif; }\n",
       ".lx-controls {\n",
       "  background: #fafafa; border: 1px solid #90caf9; border-radius: 8px;\n",
       "  padding: 12px; margin-bottom: 16px;\n",
       "}\n",
       ".lx-button-row {\n",
       "  display: flex; justify-content: center; gap: 8px; margin-bottom: 12px;\n",
       "}\n",
       ".lx-control-btn {\n",
       "  background: #4285f4; color: white; border: none; border-radius: 4px;\n",
       "  padding: 8px 16px; cursor: pointer; font-size: 13px; font-weight: 500;\n",
       "  transition: background-color 0.2s;\n",
       "}\n",
       ".lx-control-btn:hover { background: #3367d6; }\n",
       ".lx-progress-container {\n",
       "  margin-bottom: 8px;\n",
       "}\n",
       ".lx-progress-slider {\n",
       "  width: 100%; margin: 0; appearance: none; height: 6px;\n",
       "  background: #ddd; border-radius: 3px; outline: none;\n",
       "}\n",
       ".lx-progress-slider::-webkit-slider-thumb {\n",
       "  appearance: none; width: 18px; height: 18px; background: #4285f4;\n",
       "  border-radius: 50%; cursor: pointer;\n",
       "}\n",
       ".lx-progress-slider::-moz-range-thumb {\n",
       "  width: 18px; height: 18px; background: #4285f4; border-radius: 50%;\n",
       "  cursor: pointer; border: none;\n",
       "}\n",
       ".lx-status-text {\n",
       "  text-align: center; font-size: 12px; color: #666; margin-top: 4px;\n",
       "}\n",
       ".lx-text-window {\n",
       "  font-family: monospace; white-space: pre-wrap; border: 1px solid #90caf9;\n",
       "  padding: 12px; max-height: 260px; overflow-y: auto; margin-bottom: 12px;\n",
       "  line-height: 1.6;\n",
       "}\n",
       ".lx-attributes-panel {\n",
       "  background: #fafafa; border: 1px solid #90caf9; border-radius: 6px;\n",
       "  padding: 8px 10px; margin-top: 8px; font-size: 13px;\n",
       "}\n",
       ".lx-current-highlight {\n",
       "  border-bottom: 4px solid #ff4444;\n",
       "  font-weight: bold;\n",
       "  animation: lx-pulse 1s ease-in-out;\n",
       "}\n",
       "@keyframes lx-pulse {\n",
       "  0% { text-decoration-color: #ff4444; }\n",
       "  50% { text-decoration-color: #ff0000; }\n",
       "  100% { text-decoration-color: #ff4444; }\n",
       "}\n",
       ".lx-legend {\n",
       "  font-size: 12px; margin-bottom: 8px;\n",
       "  padding-bottom: 8px; border-bottom: 1px solid #e0e0e0;\n",
       "}\n",
       ".lx-label {\n",
       "  display: inline-block;\n",
       "  padding: 2px 4px;\n",
       "  border-radius: 3px;\n",
       "  margin-right: 4px;\n",
       "  color: #000;\n",
       "}\n",
       ".lx-attr-key {\n",
       "  font-weight: 600;\n",
       "  color: #1565c0;\n",
       "  letter-spacing: 0.3px;\n",
       "}\n",
       ".lx-attr-value {\n",
       "  font-weight: 400;\n",
       "  opacity: 0.85;\n",
       "  letter-spacing: 0.2px;\n",
       "}\n",
       "\n",
       "/* Add optimizations with larger fonts and better readability for GIFs */\n",
       ".lx-gif-optimized .lx-text-window { font-size: 16px; line-height: 1.8; }\n",
       ".lx-gif-optimized .lx-attributes-panel { font-size: 15px; }\n",
       ".lx-gif-optimized .lx-current-highlight { text-decoration-thickness: 4px; }\n",
       "</style>\n",
       "    <div class=\"lx-animated-wrapper lx-gif-optimized\">\n",
       "      <div class=\"lx-attributes-panel\">\n",
       "        <div class=\"lx-legend\">Highlights Legend: <span class=\"lx-label\" style=\"background-color:#D2E3FC;\">audience_impact</span> <span class=\"lx-label\" style=\"background-color:#C8E6C9;\">opinion_statement</span></div>\n",
       "        <div id=\"attributesContainer\"></div>\n",
       "      </div>\n",
       "      <div class=\"lx-text-window\" id=\"textWindow\">\n",
       "        **Page 1**\n",
       "&quot;&quot;&quot;\n",
       "Dan Baldwin\n",
       "Group 4\n",
       "Auteur Review - Interstellar \n",
       "I believe Christopher Nolan: the director behind the 2014 sci-/adventure cinematic Interstellar, \n",
       "to be <span class=\"lx-highlight lx-current-highlight\" data-idx=\"0\" style=\"background-color:#C8E6C9;\">a very intellectual and imaginative inventive talent</span>.  \n",
       "His style in his previous lms sets characters in epic unique locations, with gargantuan issues to \n",
       "face, and <span class=\"lx-highlight\" data-idx=\"1\" style=\"background-color:#C8E6C9;\">artistically impresses the audience</span> with how the characters solve their problems. For \n",
       "example, in Nolans 2010 lm Inception, he tackles the idea of dreams, and sets his characters \n",
       "diving through dreams within dreams within even more dreams to complete their goals. Because \n",
       "this idea is so farfetched, and dreams are a subject in which science has made little factual \n",
       "discovery in, Nolan is free to use his creativity to present ideas such as landscapes folding in on \n",
       "themselves and corridors spinning, without seeming unrealistic. \n",
       "<span class=\"lx-highlight\" data-idx=\"2\" style=\"background-color:#C8E6C9;\">This brain-racking epic theme is once again evident in Interstellar,</span> as Nolan sets his characters \n",
       "during a second American dust bowl on future Earth. The world is short of food, and will soon be \n",
       "uninhabitable. So, ex-NASA pilot Cooper (Matthew McConaughey) is summoned back to space \n",
       "travel in a bid to nd a new planet for the species to inhabit. Luckily for Cooper and his team, a \n",
       "black hole orbiting Saturn can transport them further into space to land on these potential \n",
       "planets. \n",
       "Throughout the ick, the crew explore multiple worlds - again feeding Nolans mind more \n",
       "opportunities to create <span class=\"lx-highlight\" data-idx=\"3\" style=\"background-color:#C8E6C9;\">crazy scenarios</span>. For example, one planet that Cooper and his friends, \n",
       "Brand, (Anne Hathaway) and Romilly, (David Gyasi) visit initially seems like an innite sea of two \n",
       "feet deep water. <span class=\"lx-highlight\" data-idx=\"4\" style=\"background-color:#C8E6C9;\">Not threatening at all right?</span> Well think again, because the crew suddenly nd out \n",
       "that <span class=\"lx-highlight\" data-idx=\"5\" style=\"background-color:#C8E6C9;\">a giant 100ft tidal wave is about to hit them</span>, and they have <span class=\"lx-highlight\" data-idx=\"6\" style=\"background-color:#D2E3FC;\">minutes to y away</span>. Nolan further \n",
       "increases the stakes in this scene as it is explained that every hour spent on this planet counts for \n",
       "seven years on earth, meaning the planet will be destroyed before they return if their ship sinks. \n",
       "At the climax of the lm, the crew end up sending themselves through a black hole into a \n",
       "tesseract (a 3D representation of a larger dimension) to nd the secret to harnessing gravity \n",
       "which will let the human race bend space-time in order to survive o earth. I know. Mental. \n",
       "The imagination that Nolan possesses and implicates into Interstellar is <span class=\"lx-highlight\" data-idx=\"7\" style=\"background-color:#C8E6C9;\">farfetched and \n",
       "wonderful</span>, <span class=\"lx-highlight\" data-idx=\"8\" style=\"background-color:#D2E3FC;\">not only impressing his audience with the appealing visuals he creates, but induces \n",
       "them to think and discuss what is going on due its scientic depth</span>. Personally, as someone who is \n",
       "bamboozled by the idea of how big the universe is, <span class=\"lx-highlight\" data-idx=\"9\" style=\"background-color:#D2E3FC;\">I nd it unendingly entertaining to repeatedly \n",
       "watch this lm and understanding it more each time</span>, and can only hope the technology portrayed \n",
       "will one day come true. \n",
       "Overall, Interstellar is <span class=\"lx-highlight\" data-idx=\"10\" style=\"background-color:#C8E6C9;\">a clear example of Nolans auteur talent</span>, as he once again gments yet \n",
       "another cluster of conditions for us to marvel at. With a <span class=\"lx-highlight\" data-idx=\"11\" style=\"background-color:#C8E6C9;\">fantastic score</span> from world famous \n",
       "composer Hanz Zimmer, his epic, orchestral theme <span class=\"lx-highlight\" data-idx=\"12\" style=\"background-color:#D2E3FC;\">sets the audience in the palm of his hands as \n",
       "we stress over how we are all going to be saved once again</span>.\n",
       "&quot;&quot;&quot;\n",
       "\n",
       "\n",
       "      </div>\n",
       "      <div class=\"lx-controls\">\n",
       "        <div class=\"lx-button-row\">\n",
       "          <button class=\"lx-control-btn\" onclick=\"playPause()\"> Play</button>\n",
       "          <button class=\"lx-control-btn\" onclick=\"prevExtraction()\"> Previous</button>\n",
       "          <button class=\"lx-control-btn\" onclick=\"nextExtraction()\"> Next</button>\n",
       "        </div>\n",
       "        <div class=\"lx-progress-container\">\n",
       "          <input type=\"range\" id=\"progressSlider\" class=\"lx-progress-slider\"\n",
       "                 min=\"0\" max=\"12\" value=\"0\"\n",
       "                 onchange=\"jumpToExtraction(this.value)\">\n",
       "        </div>\n",
       "        <div class=\"lx-status-text\">\n",
       "          Entity <span id=\"entityInfo\">1/13</span> |\n",
       "          Pos <span id=\"posInfo\">[172-224]</span>\n",
       "        </div>\n",
       "      </div>\n",
       "    </div>\n",
       "\n",
       "    <script>\n",
       "      (function() {\n",
       "        const extractions = [{\"index\": 0, \"class\": \"opinion_statement\", \"text\": \"a very intellectual and imaginative inventive talent\", \"color\": \"#C8E6C9\", \"startPos\": 172, \"endPos\": 224, \"beforeText\": \"dwin\\nGroup 4\\nAuteur Review - Interstellar \\nI believe Christopher Nolan: the director behind the 2014 sci-\\ufb01/adventure cinematic \\u2018Interstellar,\\u2019 \\nto be \", \"extractionText\": \"a very intellectual and imaginative inventive talent\", \"afterText\": \".  \\nHis style in his previous \\ufb01lms sets characters in epic unique locations, with gargantuan issues to \\nface, and artistically impresses the audience \", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Christopher Nolan</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">very intellectual and imaginative inventive talent</span>}</div>\"}, {\"index\": 1, \"class\": \"opinion_statement\", \"text\": \"artistically impresses the audience\", \"color\": \"#C8E6C9\", \"startPos\": 338, \"endPos\": 373, \"beforeText\": \"ual and imaginative inventive talent.  \\nHis style in his previous \\ufb01lms sets characters in epic unique locations, with gargantuan issues to \\nface, and \", \"extractionText\": \"artistically impresses the audience\", \"afterText\": \" with how the characters solve their problems. For \\nexample, in Nolan\\u2019s 2010 \\ufb01lm \\u2018Inception,\\u2019 he tackles the idea of dreams, and sets his characters \\n\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Nolan&#x27;s style</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">artistically impresses</span>}</div>\"}, {\"index\": 2, \"class\": \"opinion_statement\", \"text\": \"This brain-racking epic theme is once again evident in \\u2018Interstellar,\\u2019\", \"color\": \"#C8E6C9\", \"startPos\": 878, \"endPos\": 948, \"beforeText\": \"lan is free to use his creativity to present ideas such as landscapes folding in on \\nthemselves and corridors spinning, without seeming unrealistic. \\n\", \"extractionText\": \"This brain-racking epic theme is once again evident in \\u2018Interstellar,\\u2019\", \"afterText\": \" as Nolan sets his characters \\nduring a second American dust bowl on future Earth. The world is short of food, and will soon be \\nuninhabitable. So, ex\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The theme</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">brain-racking epic theme</span>}</div>\"}, {\"index\": 3, \"class\": \"opinion_statement\", \"text\": \"crazy scenarios\", \"color\": \"#C8E6C9\", \"startPos\": 1484, \"endPos\": 1499, \"beforeText\": \"o land on these potential \\nplanets. \\nThroughout the \\ufb02ick, the crew explore multiple worlds - again feeding Nolan\\u2019s mind more \\nopportunities to create \", \"extractionText\": \"crazy scenarios\", \"afterText\": \". For example, one planet that Cooper and his friends, \\n\\u2018Brand,\\u2019 (Anne Hathaway) and \\u2018Romilly,\\u2019 (David Gyasi) visit initially seems like an in\\ufb01nite se\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Nolan&#x27;s mind</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">crazy</span>}</div>\"}, {\"index\": 4, \"class\": \"opinion_statement\", \"text\": \"Not threatening at all right?\", \"color\": \"#C8E6C9\", \"startPos\": 1676, \"endPos\": 1705, \"beforeText\": \"hat Cooper and his friends, \\n\\u2018Brand,\\u2019 (Anne Hathaway) and \\u2018Romilly,\\u2019 (David Gyasi) visit initially seems like an in\\ufb01nite sea of two \\nfeet deep water. \", \"extractionText\": \"Not threatening at all right?\", \"afterText\": \" Well think again, because the crew suddenly \\ufb01nd out \\nthat a giant 100ft tidal wave is about to hit them, and they have minutes to \\ufb02y away. Nolan furt\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The planet</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Neutral</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">Not threatening at all</span>}</div>\"}, {\"index\": 5, \"class\": \"opinion_statement\", \"text\": \"a giant 100ft tidal wave is about to hit them\", \"color\": \"#C8E6C9\", \"startPos\": 1764, \"endPos\": 1809, \"beforeText\": \" initially seems like an in\\ufb01nite sea of two \\nfeet deep water. Not threatening at all right? Well think again, because the crew suddenly \\ufb01nd out \\nthat \", \"extractionText\": \"a giant 100ft tidal wave is about to hit them\", \"afterText\": \", and they have minutes to \\ufb02y away. Nolan further \\nincreases the stakes in this scene as it is explained that every hour spent on this planet counts f\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The tidal wave</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Negative</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">giant 100ft tidal wave</span>}</div>\"}, {\"index\": 6, \"class\": \"audience_impact\", \"text\": \"minutes to \\ufb02y away\", \"color\": \"#D2E3FC\", \"startPos\": 1825, \"endPos\": 1843, \"beforeText\": \" Not threatening at all right? Well think again, because the crew suddenly \\ufb01nd out \\nthat a giant 100ft tidal wave is about to hit them, and they have \", \"extractionText\": \"minutes to \\ufb02y away\", \"afterText\": \". Nolan further \\nincreases the stakes in this scene as it is explained that every hour spent on this planet counts for \\nseven years on earth, meaning \", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">stress, urgency</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">The tidal wave</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">the crew</span>}</div>\"}, {\"index\": 7, \"class\": \"opinion_statement\", \"text\": \"farfetched and wonderful\", \"color\": \"#C8E6C9\", \"startPos\": 2418, \"endPos\": 2443, \"beforeText\": \" human race bend space-time in order to survive o\\ufb00 earth. I know. Mental. \\nThe imagination that Nolan possesses and implicates into \\u2018Interstellar\\u2019 is \", \"extractionText\": \"farfetched and \\nwonderful\", \"afterText\": \", not only impressing his audience with the appealing visuals he creates, but induces \\nthem to think and discuss what is going on due its scienti\\ufb01c de\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The imagination that Nolan possesses and implicates into \\u2018Interstellar\\u2019</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">farfetched and wonderful</span>}</div>\"}, {\"index\": 8, \"class\": \"audience_impact\", \"text\": \"not only impressing his audience with the appealing visuals he creates, but induces them to think and discuss what is going on due its scienti\\ufb01c depth\", \"color\": \"#D2E3FC\", \"startPos\": 2445, \"endPos\": 2596, \"beforeText\": \" in order to survive o\\ufb00 earth. I know. Mental. \\nThe imagination that Nolan possesses and implicates into \\u2018Interstellar\\u2019 is farfetched and \\nwonderful, \", \"extractionText\": \"not only impressing his audience with the appealing visuals he creates, but induces \\nthem to think and discuss what is going on due its scienti\\ufb01c depth\", \"afterText\": \". Personally, as someone who is \\nbamboozled by the idea of how big the universe is, I \\ufb01nd it unendingly entertaining to repeatedly \\nwatch this \\ufb01lm and\", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">impressed, thoughtful, engaged</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">The appealing visuals and scientific depth</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">his audience</span>}</div>\"}, {\"index\": 9, \"class\": \"audience_impact\", \"text\": \"I \\ufb01nd it unendingly entertaining to repeatedly watch this \\ufb01lm and understanding it more each time\", \"color\": \"#D2E3FC\", \"startPos\": 2680, \"endPos\": 2778, \"beforeText\": \"them to think and discuss what is going on due its scienti\\ufb01c depth. Personally, as someone who is \\nbamboozled by the idea of how big the universe is, \", \"extractionText\": \"I \\ufb01nd it unendingly entertaining to repeatedly \\nwatch this \\ufb01lm and understanding it more each time\", \"afterText\": \", and can only hope the technology portrayed \\nwill one day come true. \\nOverall, \\u2018Interstellar\\u2019 is a clear example of Nolan\\u2019s auteur talent, as he once\", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">entertained, intellectually stimulated</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">The film&#x27;s complexity and depth</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">the reviewer</span>}</div>\"}, {\"index\": 10, \"class\": \"opinion_statement\", \"text\": \"a clear example of Nolan\\u2019s auteur talent\", \"color\": \"#C8E6C9\", \"startPos\": 2876, \"endPos\": 2916, \"beforeText\": \" \\nwatch this \\ufb01lm and understanding it more each time, and can only hope the technology portrayed \\nwill one day come true. \\nOverall, \\u2018Interstellar\\u2019 is \", \"extractionText\": \"a clear example of Nolan\\u2019s auteur talent\", \"afterText\": \", as he once again \\ufb01gments yet \\nanother cluster of conditions for us to marvel at. With a fantastic score from world famous \\ncomposer Hanz Zimmer, his\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u2018Interstellar\\u2019</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">clear example of Nolan\\u2019s auteur talent</span>}</div>\"}, {\"index\": 11, \"class\": \"opinion_statement\", \"text\": \"fantastic score\", \"color\": \"#C8E6C9\", \"startPos\": 3006, \"endPos\": 3021, \"beforeText\": \", \\u2018Interstellar\\u2019 is a clear example of Nolan\\u2019s auteur talent, as he once again \\ufb01gments yet \\nanother cluster of conditions for us to marvel at. With a \", \"extractionText\": \"fantastic score\", \"afterText\": \" from world famous \\ncomposer Hanz Zimmer, his epic, orchestral theme sets the audience in the palm of his hands as \\nwe stress over how we are all goin\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The score</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">fantastic</span>}</div>\"}, {\"index\": 12, \"class\": \"audience_impact\", \"text\": \"sets the audience in the palm of his hands as we stress over how we are all going to be saved once again\", \"color\": \"#D2E3FC\", \"startPos\": 3090, \"endPos\": 3195, \"beforeText\": \"ts yet \\nanother cluster of conditions for us to marvel at. With a fantastic score from world famous \\ncomposer Hanz Zimmer, his epic, orchestral theme \", \"extractionText\": \"sets the audience in the palm of his hands as \\nwe stress over how we are all going to be saved once again\", \"afterText\": \".\\n&quot;&quot;&quot;\\n\\n\", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">captivated, stressed</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">His epic, orchestral theme</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">the audience</span>}</div>\"}];\n",
       "        let currentIndex = 0;\n",
       "        let isPlaying = false;\n",
       "        let animationInterval = null;\n",
       "        let animationSpeed = 1.0;\n",
       "\n",
       "        function updateDisplay() {\n",
       "          const extraction = extractions[currentIndex];\n",
       "          if (!extraction) return;\n",
       "\n",
       "          document.getElementById('attributesContainer').innerHTML = extraction.attributesHtml;\n",
       "          document.getElementById('entityInfo').textContent = (currentIndex + 1) + '/' + extractions.length;\n",
       "          document.getElementById('posInfo').textContent = '[' + extraction.startPos + '-' + extraction.endPos + ']';\n",
       "          document.getElementById('progressSlider').value = currentIndex;\n",
       "\n",
       "          const playBtn = document.querySelector('.lx-control-btn');\n",
       "          if (playBtn) playBtn.textContent = isPlaying ? ' Pause' : ' Play';\n",
       "\n",
       "          const prevHighlight = document.querySelector('.lx-text-window .lx-current-highlight');\n",
       "          if (prevHighlight) prevHighlight.classList.remove('lx-current-highlight');\n",
       "          const currentSpan = document.querySelector('.lx-text-window span[data-idx=\"' + currentIndex + '\"]');\n",
       "          if (currentSpan) {\n",
       "            currentSpan.classList.add('lx-current-highlight');\n",
       "            currentSpan.scrollIntoView({block: 'center', behavior: 'smooth'});\n",
       "          }\n",
       "        }\n",
       "\n",
       "        function nextExtraction() {\n",
       "          currentIndex = (currentIndex + 1) % extractions.length;\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function prevExtraction() {\n",
       "          currentIndex = (currentIndex - 1 + extractions.length) % extractions.length;\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function jumpToExtraction(index) {\n",
       "          currentIndex = parseInt(index);\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function playPause() {\n",
       "          if (isPlaying) {\n",
       "            clearInterval(animationInterval);\n",
       "            isPlaying = false;\n",
       "          } else {\n",
       "            animationInterval = setInterval(nextExtraction, animationSpeed * 1000);\n",
       "            isPlaying = true;\n",
       "          }\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        window.playPause = playPause;\n",
       "        window.nextExtraction = nextExtraction;\n",
       "        window.prevExtraction = prevExtraction;\n",
       "        window.jumpToExtraction = jumpToExtraction;\n",
       "\n",
       "        updateDisplay();\n",
       "      })();\n",
       "    </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_7_1_2_'></a>[**>>> Bonus Exercise 3 (Take home):**](#toc0_)\n",
    "\n",
    "`NOTE: This exercise is now considered a bonus one, not counted for the main grade, only as extra points.`\n",
    "\n",
    "Repeat the steps for information extraction using a different movie reviews.\n",
    "1. Search for movie reviews online and save them in a PDF, we suggest **at least 1 page worth of reviews** like in the example.\n",
    "2. Load the PDF and pass them to langextract to extract information from it.\n",
    "3. Display html with the grounded extracted attributes.\n",
    "4. Discuss about the quality of the extracted information with langextract, how could it be improved based on the options the documentation gives that we didn't try?\n",
    "\n",
    "**`Github repository for reference:`** [langextract](https://github.com/google/langextract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Extracted text from './data/documents/movie_review.pdf'\n",
      "**Page 1**\n",
      "\"\"\"\n",
      "Movie Reviews \n",
      "by Bob Mondello \n",
      "  \n",
      "'Wall-E,' Speaking Volumes with Stillness and Stars \n",
      "Listen Now [4 min 37 sec] add to playlist  \n",
      "  \n",
      " \n",
      "Enlarge \n",
      " \n",
      "Evolutionary thinking: Wall-E may have started out as a glorified trash compactor, but he's learned how to look to the sky. Pixar \n",
      "Wall-E \n",
      " \n",
      "Director: Andrew Stanton  \n",
      " \n",
      "Genre: Sci-Fi  \n",
      " \n",
      "Running Time: 97 minutes \n",
      "Rated G: Big-hearted and full of wonder, but too smart to be saccharine. \n",
      "The first hour of Wall-E is a crazily inventive, deliriously engaging and almost wordless silent comedy of the sort that \n",
      "Charlie Chaplin and Buster Keaton used to make. \n",
      " \n",
      "All Things Considered, June 27, 2008  The camera descends, at the start of Wall-E, from \n",
      "outer space to a landscape that looks eerily familiar  and sort of not. The sun filters \n",
      "down through a brownish haze. What seem at first like skyscrapers turn out to be neatly \n",
      "stacked mountains of trash. Stillness is everywhere, broken only by the unlikely sound of \n",
      "a song from Hello, Dolly!  and a solitary figure zipping around a junk-strewn \n",
      "cityscape.  \n",
      "Apparently, humans never changed course on pollution and consumerism, and sometime \n",
      "in the 22nd century they were forced to leave a planet they had turned into a giant \n",
      "garbage dump. But they left without turning off a robot they'd left behind. He's basically \n",
      "a trash compactor on treads  a Waste Allocation Load-Lifter: Earth Class, or WALL-E \n",
      " who has, over the course of 700 years, developed a personality.\n",
      "\"\"\"\n",
      "\n",
      "**Page 2**\n",
      "\"\"\"\n",
      "He tries to puzzle out what mankind's detritus was for (a Rubik's cube, a spork, a fire \n",
      "extinguisher), and he saves a few items  an alarmingly fresh 700-year-old Twinkie, \n",
      "say, for his pet cockroach.  \n",
      "But most of the trash he compacts and stacks, in a routine that is interrupted only when he \n",
      "falls head-over-treads for a sleek robot from the stars: EVE (for Extra-terrestrial \n",
      "Vegetation Evaluator), whom he watches from afar so he won't be incinerated.  \n",
      "Eve has an itchy trigger-finger, it turns out. \n",
      "The first hour of Wall-E is a crazily inventive, deliriously engaging and almost wordless \n",
      "silent comedy of the sort that Charlie Chaplin and Buster Keaton used to make. Things \n",
      "turn more conventional in the last half hour, when pudgy, machine-dependent humans \n",
      "make an appearance, but the glow of that first part will carry you through.  \n",
      "That and the majesty of the filmmaking: Wall-E's world, in all its epic decay, looks real. \n",
      "You can almost taste the dust. And it's emotionally real too  enough so that a \n",
      "cautionary tale about the environment, and about big corporations that don't take care of \n",
      "it, and about getting so caught up in our gadgetry that we forget to look at the stars all \n",
      "take a back seat to romance.  \n",
      "So do some specifically cinematic subtexts. Director Andrew Stanton and his animators \n",
      "have slipped in nods not just to Hello, Dolly!, but to Star Wars and Blade Runner, An \n",
      "Inconvenient Truth and the comedies of Chaplin and Jacques Tati. More than just a nod \n",
      "to Chaplin, actually: Wall-E, with his workaholic scruffiness and his yearning for \n",
      "someone to hold hands with, might as well be Chaplin's Little Tramp. \n",
      "There's actually a nice parallel between this largely silent film and Chaplin's first sound \n",
      "film, Modern Times. In that one, the silent clown used the soundtrack mostly for music \n",
      "and effects, not for speech, just as Pixar does here. Chaplin only let you hear a human \n",
      "voice a couple of times, and only on some sort of mechanical contraption  say a closed-\n",
      "circuit TV screen  to emphasize its artificiality. It was his way of saying to the sound \n",
      "world, \"OK, everybody's doing this talking thing now, but look how much more \n",
      "expressive our silent world is.\"  \n",
      "For the first time in a Pixar movie, Wall-E's filmmakers give a nod to the world of actual \n",
      "actors and cameras  and make them artificial in the same way: by only letting you see \n",
      "them on video screens, where they look flat and washed-out compared to the digital \n",
      "world around them. \n",
      "But there's one difference. Chaplin knew he had lost the battle: Silence was finished; \n",
      "sound had won. In today's Hollywood, digital is what's taking over  in special effects, \n",
      "in green-screen work, in animation. And Pixar's animators, bless them, are at the\n",
      "\"\"\"\n",
      "\n",
      "**Page 3**\n",
      "\"\"\"\n",
      "forefront, insisting that imagery created on computers doesn't have to be soulless. Wall-\n",
      "E's images are filled with emotion, just as silent film's images were  even though its \n",
      "characters look like they're made of metal and plastic, and can't say a word.  \n",
      "Wall-E is being sold as a futuristic fantasy, of course. But I have to say I'm just as \n",
      "gratified by their look back 70 years to silent movies as I am by their look forward 700 \n",
      "years to a silent planet.\n",
      "\"\"\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Answer here\n",
    "pdf_path = \"./data/documents/movie_review.pdf\"\n",
    "formatted_text = \"\"\n",
    "try:\n",
    "    doc = pymupdf.open(pdf_path)\n",
    "    # In case the PDF documents have more than one page, in this example it only has one\n",
    "    for i, page in enumerate(doc):\n",
    "        text = page.get_text(\"text\")\n",
    "        # Format follows the prompt's requirement: **Page X** \"\"\"document's text\"\"\"\n",
    "        formatted_text += f'**Page {i + 1}**\\n'\n",
    "        formatted_text += f'\"\"\"\\n{text.strip()}\\n\"\"\"\\n\\n'\n",
    "    doc.close()\n",
    "    print(f\" Extracted text from '{pdf_path}'\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not read PDF: {e}\")\n",
    "    formatted_text = \"Error: Could not process PDF file.\"\n",
    "print(formatted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langextract as lx\n",
    "import textwrap\n",
    "\n",
    "# Defining the extraction prompt for \"movie review\" type of data\n",
    "prompt = textwrap.dedent(\"\"\"\\\n",
    "    Extract specific opinions and their impact on the audience from this movie review.\n",
    "    Important: Use exact text verbatim from the input for extraction_text. Do not paraphrase.\n",
    "    Extract entities in order of appearance with no overlapping text spans.\n",
    "\n",
    "    Use the 'opinion_statement' class for direct judgments about film elements (like plot, score, or acting).\n",
    "    - 'subject' should be the element being reviewed.\n",
    "    - 'sentiment' should be Positive, Negative, or Neutral.\n",
    "    - 'key_phrase' should be the core descriptive words.\n",
    "\n",
    "    Use the 'audience_impact' class for phrases describing the effect on the viewer.\n",
    "    - 'emotion_evoked' should be the feeling or reaction (e.g., stress, joy, confusion).\n",
    "    - 'causal_element' is what part of the film caused the reaction.\n",
    "    - 'target_audience' is who was affected (e.g., 'the audience', 'the reviewer').\n",
    "    \"\"\")\n",
    "\n",
    "# Providing high-quality examples to guide the model\n",
    "# These examples show the model exactly how to differentiate between the two classes\n",
    "examples = [\n",
    "    # Example 1: Demonstrates a positive opinion on the plot and its direct impact on the reviewer\n",
    "    lx.data.ExampleData(\n",
    "        text=\"Wall-E's world, in all its epic decay, looks real. You can almost taste the dust.\",\n",
    "        extractions=[\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"opinion_statement\",\n",
    "                extraction_text=\"looks real\",\n",
    "                attributes={\n",
    "                    \"subject\": \"Wall-E's world\",\n",
    "                    \"sentiment\": \"Positive\",\n",
    "                    \"key_phrase\": \"looks real\"\n",
    "                }\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"audience_impact\",\n",
    "                extraction_text=\"You can almost taste the dust\",\n",
    "                attributes={\n",
    "                    \"emotion_evoked\":  [\"immersion\", \"sensory vividness\"],\n",
    "                    \"causal_element\": \"The dust\",\n",
    "                    \"target_audience\": \"the reviewer\"\n",
    "                }\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    # Example 2: Shows a negative opinion and a separate audience impact caused by the soundtrack\n",
    "    lx.data.ExampleData(\n",
    "        text=\"The first hour of Wall-E is a crazily inventive, deliriously engaging and almost wordless silent comedy of the sort that Charlie Chaplin and Buster Keaton used to make.\",\n",
    "        extractions=[\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"opinion_statement\",\n",
    "                extraction_text=\"a crazily inventive, deliriously engaging and almost wordless silent comedy\",\n",
    "                attributes={\n",
    "                    \"subject\": \"The first hour of Wall-E\",\n",
    "                    \"sentiment\": \"Positive\",\n",
    "                    \"key_phrase\": \"crazily inventive, deliriously engaging and almost wordless silent comedy\"\n",
    "                }\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"audience_impact\",\n",
    "                extraction_text=\"deliriously engaging\",\n",
    "                attributes={\n",
    "                    \"emotion_evoked\": [\"delight\", \"captivation\"],\n",
    "                    \"causal_element\": \"the silent comedy style\",\n",
    "                    \"target_audience\": \"the audience\"\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Prompt alignment: non-exact match: [example#1] class='audience_impact' status=AlignmentStatus.MATCH_FUZZY text='deliriously engaging' char_span=(49, 69)\n",
      "WARNING:google_genai._api_client:Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 24 entities:\n",
      "\n",
      " opinion_statement: 'Big-hearted and full of wonder, but too smart to be saccharine.'\n",
      "  - subject: Rated G\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: Big-hearted and full of wonder, but too smart to be saccharine\n",
      " opinion_statement: 'a crazily inventive, deliriously engaging and almost wordless silent comedy of the sort that Charlie Chaplin and Buster Keaton used to make.'\n",
      "  - subject: The first hour of Wall-E\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: crazily inventive, deliriously engaging and almost wordless silent comedy\n",
      " audience_impact: 'deliriously engaging'\n",
      "  - emotion_evoked: ['delight', 'captivation']\n",
      "  - causal_element: the silent comedy style\n",
      "  - target_audience: the audience\n",
      " opinion_statement: 'looks eerily familiar  and sort of not.'\n",
      "  - subject: a landscape\n",
      "  - sentiment: Neutral\n",
      "  - key_phrase: looks eerily familiar  and sort of not\n",
      " opinion_statement: 'Stillness is everywhere'\n",
      "  - subject: the landscape\n",
      "  - sentiment: Neutral\n",
      "  - key_phrase: Stillness is everywhere\n",
      " opinion_statement: 'developed a personality.'\n",
      "  - subject: He\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: developed a personality\n",
      " opinion_statement: 'a crazily inventive, deliriously engaging and almost wordless silent comedy'\n",
      "  - subject: The first hour of Wall-E\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: crazily inventive, deliriously engaging and almost wordless silent comedy\n",
      " opinion_statement: 'more conventional'\n",
      "  - subject: Things\n",
      "  - sentiment: Negative\n",
      "  - key_phrase: more conventional\n",
      " audience_impact: 'the glow of that first part will carry you through'\n",
      "  - emotion_evoked: ['sustained engagement', 'satisfaction']\n",
      "  - causal_element: the glow of that first part\n",
      "  - target_audience: the audience\n",
      " opinion_statement: 'looks real'\n",
      "  - subject: Wall-E's world\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: looks real\n",
      " audience_impact: 'You can almost taste the dust'\n",
      "  - emotion_evoked: ['immersion', 'sensory vividness']\n",
      "  - causal_element: The dust\n",
      "  - target_audience: the reviewer\n",
      " opinion_statement: 'emotionally real'\n",
      "  - subject: it\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: emotionally real\n",
      " opinion_statement: 'a cautionary tale about the environment, and about big corporations that don't take care of it, and about getting so caught up in our gadgetry that we forget to look at the stars all take a back seat to romance'\n",
      "  - subject: cautionary tale\n",
      "  - sentiment: Negative\n",
      "  - key_phrase: take a back seat to romance\n",
      " opinion_statement: 'nods not just to Hello, Dolly!, but to Star Wars and Blade Runner, An Inconvenient Truth and the comedies of Chaplin and Jacques Tati'\n",
      "  - subject: Director Andrew Stanton and his animators\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: slipped in nods\n",
      " opinion_statement: 'might as well be Chaplin's Little Tramp'\n",
      "  - subject: Wall-E\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: might as well be Chaplin's Little Tramp\n",
      " opinion_statement: 'nice parallel'\n",
      "  - subject: this largely silent film and Chaplin's first sound film, Modern Times\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: nice parallel\n",
      " opinion_statement: 'silent clown used the soundtrack mostly for music and effects, not for speech'\n",
      "  - subject: the silent clown\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: used the soundtrack mostly for music and effects, not for speech\n",
      " opinion_statement: 'look how much more expressive our silent world is'\n",
      "  - subject: our silent world\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: more expressive\n",
      " opinion_statement: 'look flat and washed-out'\n",
      "  - subject: actual actors and cameras\n",
      "  - sentiment: Negative\n",
      "  - key_phrase: flat and washed-out\n",
      " opinion_statement: 'digital is what's taking over'\n",
      "  - subject: digital\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: taking over\n",
      " opinion_statement: 'imagery created on computers doesn't have to be soulless'\n",
      "  - subject: imagery created on computers\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: doesn't have to be soulless\n",
      " opinion_statement: 'Wall-E's images are filled with emotion'\n",
      "  - subject: Wall-E's images\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: filled with emotion\n",
      " opinion_statement: 'gratified by their look back 70 years to silent movies'\n",
      "  - subject: their look back 70 years to silent movies\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: gratified\n",
      " opinion_statement: 'gratified by their look forward 700 years to a silent planet'\n",
      "  - subject: their look forward 700 years to a silent planet\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: gratified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mLangExtract\u001b[0m: Saving to \u001b[92mmovie_review_extraction_example.jsonl\u001b[0m: 1 docs [00:00, 466.45 docs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[0m Saved \u001b[1m1\u001b[0m documents to \u001b[92mmovie_review_extraction_example.jsonl\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[94m\u001b[1mLangExtract\u001b[0m: Loading \u001b[92mmovie_review_extraction_example.jsonl\u001b[0m: 100%|| 14.5k/14.5k [00:00<00:00, 53.7MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[0m Loaded \u001b[1m1\u001b[0m documents from \u001b[92mmovie_review_extraction_example.jsonl\u001b[0m\n",
      " Visualization saved to ./results/info_extractions/movie_review_extraction_example_vis.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'extractions': [{'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'Big-hearted and full of wonder, but too smart to be saccharine.',\n",
       "   'char_interval': {'start_pos': 389, 'end_pos': 452},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 1,\n",
       "   'group_index': 0,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'Rated G',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'Big-hearted and full of wonder, but too smart to be saccharine'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'a crazily inventive, deliriously engaging and almost wordless silent comedy of the sort that Charlie Chaplin and Buster Keaton used to make.',\n",
       "   'char_interval': {'start_pos': 483, 'end_pos': 623},\n",
       "   'alignment_status': 'match_lesser',\n",
       "   'extraction_index': 2,\n",
       "   'group_index': 1,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The first hour of Wall-E',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'crazily inventive, deliriously engaging and almost wordless silent comedy'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'deliriously engaging',\n",
       "   'char_interval': {'start_pos': 504, 'end_pos': 524},\n",
       "   'alignment_status': 'match_fuzzy',\n",
       "   'extraction_index': 3,\n",
       "   'group_index': 2,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['delight', 'captivation'],\n",
       "    'causal_element': 'the silent comedy style',\n",
       "    'target_audience': 'the audience'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'looks eerily familiar  and sort of not.',\n",
       "   'char_interval': {'start_pos': 751, 'end_pos': 791},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 4,\n",
       "   'group_index': 3,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'a landscape',\n",
       "    'sentiment': 'Neutral',\n",
       "    'key_phrase': 'looks eerily familiar  and sort of not'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'Stillness is everywhere',\n",
       "   'char_interval': {'start_pos': 926, 'end_pos': 949},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 5,\n",
       "   'group_index': 4,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'the landscape',\n",
       "    'sentiment': 'Neutral',\n",
       "    'key_phrase': 'Stillness is everywhere'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'developed a personality.',\n",
       "   'char_interval': {'start_pos': 1470, 'end_pos': 1494},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 6,\n",
       "   'group_index': 5,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'He',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'developed a personality'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'a crazily inventive, deliriously engaging and almost wordless silent comedy',\n",
       "   'char_interval': {'start_pos': 2052, 'end_pos': 2128},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 1,\n",
       "   'group_index': 0,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The first hour of Wall-E',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'crazily inventive, deliriously engaging and almost wordless silent comedy'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'more conventional',\n",
       "   'char_interval': {'start_pos': 2207, 'end_pos': 2224},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 2,\n",
       "   'group_index': 1,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'Things',\n",
       "    'sentiment': 'Negative',\n",
       "    'key_phrase': 'more conventional'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'the glow of that first part will carry you through',\n",
       "   'char_interval': {'start_pos': 2310, 'end_pos': 2360},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 3,\n",
       "   'group_index': 2,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['sustained engagement', 'satisfaction'],\n",
       "    'causal_element': 'the glow of that first part',\n",
       "    'target_audience': 'the audience'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'looks real',\n",
       "   'char_interval': {'start_pos': 2443, 'end_pos': 2453},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 4,\n",
       "   'group_index': 3,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': \"Wall-E's world\",\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'looks real'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'You can almost taste the dust',\n",
       "   'char_interval': {'start_pos': 2456, 'end_pos': 2485},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 5,\n",
       "   'group_index': 4,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['immersion', 'sensory vividness'],\n",
       "    'causal_element': 'The dust',\n",
       "    'target_audience': 'the reviewer'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'emotionally real',\n",
       "   'char_interval': {'start_pos': 2496, 'end_pos': 2512},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 6,\n",
       "   'group_index': 5,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'it',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'emotionally real'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': \"a cautionary tale about the environment, and about big corporations that don't take care of it, and about getting so caught up in our gadgetry that we forget to look at the stars all take a back seat to romance\",\n",
       "   'char_interval': {'start_pos': 2534, 'end_pos': 2747},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 7,\n",
       "   'group_index': 6,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'cautionary tale',\n",
       "    'sentiment': 'Negative',\n",
       "    'key_phrase': 'take a back seat to romance'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'nods not just to Hello, Dolly!, but to Star Wars and Blade Runner, An Inconvenient Truth and the comedies of Chaplin and Jacques Tati',\n",
       "   'char_interval': {'start_pos': 2854, 'end_pos': 2988},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 8,\n",
       "   'group_index': 7,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'Director Andrew Stanton and his animators',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'slipped in nods'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': \"might as well be Chaplin's Little Tramp\",\n",
       "   'char_interval': {'start_pos': 3124, 'end_pos': 3163},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 9,\n",
       "   'group_index': 8,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'Wall-E',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': \"might as well be Chaplin's Little Tramp\"}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'nice parallel',\n",
       "   'char_interval': {'start_pos': 3185, 'end_pos': 3198},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 10,\n",
       "   'group_index': 9,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': \"this largely silent film and Chaplin's first sound film, Modern Times\",\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'nice parallel'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'silent clown used the soundtrack mostly for music and effects, not for speech',\n",
       "   'char_interval': {'start_pos': 3296, 'end_pos': 3374},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 11,\n",
       "   'group_index': 10,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'the silent clown',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'used the soundtrack mostly for music and effects, not for speech'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'look how much more expressive our silent world is',\n",
       "   'char_interval': {'start_pos': 3674, 'end_pos': 3724},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 12,\n",
       "   'group_index': 11,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'our silent world',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'more expressive'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'look flat and washed-out',\n",
       "   'char_interval': {'start_pos': 3943, 'end_pos': 3967},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 1,\n",
       "   'group_index': 0,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'actual actors and cameras',\n",
       "    'sentiment': 'Negative',\n",
       "    'key_phrase': 'flat and washed-out'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': \"digital is what's taking over\",\n",
       "   'char_interval': {'start_pos': 4138, 'end_pos': 4167},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 2,\n",
       "   'group_index': 1,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'digital',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'taking over'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': \"imagery created on computers doesn't have to be soulless\",\n",
       "   'char_interval': {'start_pos': 4319, 'end_pos': 4375},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 3,\n",
       "   'group_index': 2,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'imagery created on computers',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': \"doesn't have to be soulless\"}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': \"Wall-E's images are filled with emotion\",\n",
       "   'char_interval': {'start_pos': 4377, 'end_pos': 4417},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 4,\n",
       "   'group_index': 3,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': \"Wall-E's images\",\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'filled with emotion'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'gratified by their look back 70 years to silent movies',\n",
       "   'char_interval': {'start_pos': 4640, 'end_pos': 4694},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 5,\n",
       "   'group_index': 4,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'their look back 70 years to silent movies',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'gratified'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'gratified by their look forward 700 years to a silent planet',\n",
       "   'char_interval': {'start_pos': 4640, 'end_pos': 4754},\n",
       "   'alignment_status': 'match_fuzzy',\n",
       "   'extraction_index': 6,\n",
       "   'group_index': 5,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'their look forward 700 years to a silent planet',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'gratified'}}],\n",
       " 'text': '**Page 1**\\n\"\"\"\\nMovie Reviews \\nby Bob Mondello \\n  \\n\\'Wall-E,\\' Speaking Volumes with Stillness and Stars \\nListen Now [4 min 37 sec] add to playlist  \\n  \\n \\nEnlarge \\n \\nEvolutionary thinking: Wall-E may have started out as a glorified trash compactor, but he\\'s learned how to look to the sky. Pixar \\nWall-E \\n \\nDirector: Andrew Stanton  \\n \\nGenre: Sci-Fi  \\n \\nRunning Time: 97 minutes \\nRated G: Big-hearted and full of wonder, but too smart to be saccharine. \\nThe first hour of Wall-E is a crazily inventive, deliriously engaging and almost wordless silent comedy of the sort that \\nCharlie Chaplin and Buster Keaton used to make. \\n \\nAll Things Considered, June 27, 2008  The camera descends, at the start of Wall-E, from \\nouter space to a landscape that looks eerily familiar  and sort of not. The sun filters \\ndown through a brownish haze. What seem at first like skyscrapers turn out to be neatly \\nstacked mountains of trash. Stillness is everywhere, broken only by the unlikely sound of \\na song from Hello, Dolly!  and a solitary figure zipping around a junk-strewn \\ncityscape.  \\nApparently, humans never changed course on pollution and consumerism, and sometime \\nin the 22nd century they were forced to leave a planet they had turned into a giant \\ngarbage dump. But they left without turning off a robot they\\'d left behind. He\\'s basically \\na trash compactor on treads  a Waste Allocation Load-Lifter: Earth Class, or WALL-E \\n who has, over the course of 700 years, developed a personality.\\n\"\"\"\\n\\n**Page 2**\\n\"\"\"\\nHe tries to puzzle out what mankind\\'s detritus was for (a Rubik\\'s cube, a spork, a fire \\nextinguisher), and he saves a few items  an alarmingly fresh 700-year-old Twinkie, \\nsay, for his pet cockroach.  \\nBut most of the trash he compacts and stacks, in a routine that is interrupted only when he \\nfalls head-over-treads for a sleek robot from the stars: EVE (for Extra-terrestrial \\nVegetation Evaluator), whom he watches from afar so he won\\'t be incinerated.  \\nEve has an itchy trigger-finger, it turns out. \\nThe first hour of Wall-E is a crazily inventive, deliriously engaging and almost wordless \\nsilent comedy of the sort that Charlie Chaplin and Buster Keaton used to make. Things \\nturn more conventional in the last half hour, when pudgy, machine-dependent humans \\nmake an appearance, but the glow of that first part will carry you through.  \\nThat and the majesty of the filmmaking: Wall-E\\'s world, in all its epic decay, looks real. \\nYou can almost taste the dust. And it\\'s emotionally real too  enough so that a \\ncautionary tale about the environment, and about big corporations that don\\'t take care of \\nit, and about getting so caught up in our gadgetry that we forget to look at the stars all \\ntake a back seat to romance.  \\nSo do some specifically cinematic subtexts. Director Andrew Stanton and his animators \\nhave slipped in nods not just to Hello, Dolly!, but to Star Wars and Blade Runner, An \\nInconvenient Truth and the comedies of Chaplin and Jacques Tati. More than just a nod \\nto Chaplin, actually: Wall-E, with his workaholic scruffiness and his yearning for \\nsomeone to hold hands with, might as well be Chaplin\\'s Little Tramp. \\nThere\\'s actually a nice parallel between this largely silent film and Chaplin\\'s first sound \\nfilm, Modern Times. In that one, the silent clown used the soundtrack mostly for music \\nand effects, not for speech, just as Pixar does here. Chaplin only let you hear a human \\nvoice a couple of times, and only on some sort of mechanical contraption  say a closed-\\ncircuit TV screen  to emphasize its artificiality. It was his way of saying to the sound \\nworld, \"OK, everybody\\'s doing this talking thing now, but look how much more \\nexpressive our silent world is.\"  \\nFor the first time in a Pixar movie, Wall-E\\'s filmmakers give a nod to the world of actual \\nactors and cameras  and make them artificial in the same way: by only letting you see \\nthem on video screens, where they look flat and washed-out compared to the digital \\nworld around them. \\nBut there\\'s one difference. Chaplin knew he had lost the battle: Silence was finished; \\nsound had won. In today\\'s Hollywood, digital is what\\'s taking over  in special effects, \\nin green-screen work, in animation. And Pixar\\'s animators, bless them, are at the\\n\"\"\"\\n\\n**Page 3**\\n\"\"\"\\nforefront, insisting that imagery created on computers doesn\\'t have to be soulless. Wall-\\nE\\'s images are filled with emotion, just as silent film\\'s images were  even though its \\ncharacters look like they\\'re made of metal and plastic, and can\\'t say a word.  \\nWall-E is being sold as a futuristic fantasy, of course. But I have to say I\\'m just as \\ngratified by their look back 70 years to silent movies as I am by their look forward 700 \\nyears to a silent planet.\\n\"\"\"\\n\\n',\n",
       " 'document_id': 'doc_db8190e4'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_content = grounded_info_extraction(formatted_text, prompt, examples, \"movie_review_extraction_example\")\n",
    "\n",
    "with open(\"./results/info_extractions/movie_review_extraction_example.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    content_extracted_raw = json.load(f)\n",
    "content_extracted_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".lx-highlight { position: relative; border-radius:3px; padding:1px 2px;}\n",
       ".lx-highlight .lx-tooltip {\n",
       "  visibility: hidden;\n",
       "  opacity: 0;\n",
       "  transition: opacity 0.2s ease-in-out;\n",
       "  background: #333;\n",
       "  color: #fff;\n",
       "  text-align: left;\n",
       "  border-radius: 4px;\n",
       "  padding: 6px 8px;\n",
       "  position: absolute;\n",
       "  z-index: 1000;\n",
       "  bottom: 125%;\n",
       "  left: 50%;\n",
       "  transform: translateX(-50%);\n",
       "  font-size: 12px;\n",
       "  max-width: 240px;\n",
       "  white-space: normal;\n",
       "  box-shadow: 0 2px 6px rgba(0,0,0,0.3);\n",
       "}\n",
       ".lx-highlight:hover .lx-tooltip { visibility: visible; opacity:1; }\n",
       ".lx-animated-wrapper { max-width: 100%; font-family: Arial, sans-serif; }\n",
       ".lx-controls {\n",
       "  background: #fafafa; border: 1px solid #90caf9; border-radius: 8px;\n",
       "  padding: 12px; margin-bottom: 16px;\n",
       "}\n",
       ".lx-button-row {\n",
       "  display: flex; justify-content: center; gap: 8px; margin-bottom: 12px;\n",
       "}\n",
       ".lx-control-btn {\n",
       "  background: #4285f4; color: white; border: none; border-radius: 4px;\n",
       "  padding: 8px 16px; cursor: pointer; font-size: 13px; font-weight: 500;\n",
       "  transition: background-color 0.2s;\n",
       "}\n",
       ".lx-control-btn:hover { background: #3367d6; }\n",
       ".lx-progress-container {\n",
       "  margin-bottom: 8px;\n",
       "}\n",
       ".lx-progress-slider {\n",
       "  width: 100%; margin: 0; appearance: none; height: 6px;\n",
       "  background: #ddd; border-radius: 3px; outline: none;\n",
       "}\n",
       ".lx-progress-slider::-webkit-slider-thumb {\n",
       "  appearance: none; width: 18px; height: 18px; background: #4285f4;\n",
       "  border-radius: 50%; cursor: pointer;\n",
       "}\n",
       ".lx-progress-slider::-moz-range-thumb {\n",
       "  width: 18px; height: 18px; background: #4285f4; border-radius: 50%;\n",
       "  cursor: pointer; border: none;\n",
       "}\n",
       ".lx-status-text {\n",
       "  text-align: center; font-size: 12px; color: #666; margin-top: 4px;\n",
       "}\n",
       ".lx-text-window {\n",
       "  font-family: monospace; white-space: pre-wrap; border: 1px solid #90caf9;\n",
       "  padding: 12px; max-height: 260px; overflow-y: auto; margin-bottom: 12px;\n",
       "  line-height: 1.6;\n",
       "}\n",
       ".lx-attributes-panel {\n",
       "  background: #fafafa; border: 1px solid #90caf9; border-radius: 6px;\n",
       "  padding: 8px 10px; margin-top: 8px; font-size: 13px;\n",
       "}\n",
       ".lx-current-highlight {\n",
       "  border-bottom: 4px solid #ff4444;\n",
       "  font-weight: bold;\n",
       "  animation: lx-pulse 1s ease-in-out;\n",
       "}\n",
       "@keyframes lx-pulse {\n",
       "  0% { text-decoration-color: #ff4444; }\n",
       "  50% { text-decoration-color: #ff0000; }\n",
       "  100% { text-decoration-color: #ff4444; }\n",
       "}\n",
       ".lx-legend {\n",
       "  font-size: 12px; margin-bottom: 8px;\n",
       "  padding-bottom: 8px; border-bottom: 1px solid #e0e0e0;\n",
       "}\n",
       ".lx-label {\n",
       "  display: inline-block;\n",
       "  padding: 2px 4px;\n",
       "  border-radius: 3px;\n",
       "  margin-right: 4px;\n",
       "  color: #000;\n",
       "}\n",
       ".lx-attr-key {\n",
       "  font-weight: 600;\n",
       "  color: #1565c0;\n",
       "  letter-spacing: 0.3px;\n",
       "}\n",
       ".lx-attr-value {\n",
       "  font-weight: 400;\n",
       "  opacity: 0.85;\n",
       "  letter-spacing: 0.2px;\n",
       "}\n",
       "\n",
       "/* Add optimizations with larger fonts and better readability for GIFs */\n",
       ".lx-gif-optimized .lx-text-window { font-size: 16px; line-height: 1.8; }\n",
       ".lx-gif-optimized .lx-attributes-panel { font-size: 15px; }\n",
       ".lx-gif-optimized .lx-current-highlight { text-decoration-thickness: 4px; }\n",
       "</style>\n",
       "    <div class=\"lx-animated-wrapper lx-gif-optimized\">\n",
       "      <div class=\"lx-attributes-panel\">\n",
       "        <div class=\"lx-legend\">Highlights Legend: <span class=\"lx-label\" style=\"background-color:#D2E3FC;\">audience_impact</span> <span class=\"lx-label\" style=\"background-color:#C8E6C9;\">opinion_statement</span></div>\n",
       "        <div id=\"attributesContainer\"></div>\n",
       "      </div>\n",
       "      <div class=\"lx-text-window\" id=\"textWindow\">\n",
       "        **Page 1**\n",
       "&quot;&quot;&quot;\n",
       "Movie Reviews \n",
       "by Bob Mondello \n",
       "\n",
       "&#x27;Wall-E,&#x27; Speaking Volumes with Stillness and Stars \n",
       "Listen Now [4 min 37 sec] add to playlist  \n",
       "\n",
       "\n",
       "Enlarge \n",
       "\n",
       "Evolutionary thinking: Wall-E may have started out as a glorified trash compactor, but he&#x27;s learned how to look to the sky. Pixar \n",
       "Wall-E \n",
       " \n",
       "Director: Andrew Stanton  \n",
       " \n",
       "Genre: Sci-Fi  \n",
       " \n",
       "Running Time: 97 minutes \n",
       "Rated G: <span class=\"lx-highlight lx-current-highlight\" data-idx=\"0\" style=\"background-color:#C8E6C9;\">Big-hearted and full of wonder, but too smart to be saccharine.</span> \n",
       "The first hour of Wall-E is <span class=\"lx-highlight\" data-idx=\"1\" style=\"background-color:#C8E6C9;\">a crazily inventive, <span class=\"lx-highlight\" data-idx=\"2\" style=\"background-color:#D2E3FC;\">deliriously engaging</span> and almost wordless silent comedy of the sort that \n",
       "Charlie Chaplin and Buster Keaton used to make</span>. \n",
       "\n",
       "All Things Considered, June 27, 2008  The camera descends, at the start of Wall-E, from \n",
       "outer space to a landscape that <span class=\"lx-highlight\" data-idx=\"3\" style=\"background-color:#C8E6C9;\">looks eerily familiar  and sort of not.</span> The sun filters \n",
       "down through a brownish haze. What seem at first like skyscrapers turn out to be neatly \n",
       "stacked mountains of trash. <span class=\"lx-highlight\" data-idx=\"4\" style=\"background-color:#C8E6C9;\">Stillness is everywhere</span>, broken only by the unlikely sound of \n",
       "a song from Hello, Dolly!  and a solitary figure zipping around a junk-strewn \n",
       "cityscape.  \n",
       "Apparently, humans never changed course on pollution and consumerism, and sometime \n",
       "in the 22nd century they were forced to leave a planet they had turned into a giant \n",
       "garbage dump. But they left without turning off a robot they&#x27;d left behind. He&#x27;s basically \n",
       "a trash compactor on treads  a Waste Allocation Load-Lifter: Earth Class, or WALL-E \n",
       " who has, over the course of 700 years, <span class=\"lx-highlight\" data-idx=\"5\" style=\"background-color:#C8E6C9;\">developed a personality.</span>\n",
       "&quot;&quot;&quot;\n",
       "\n",
       "**Page 2**\n",
       "&quot;&quot;&quot;\n",
       "He tries to puzzle out what mankind&#x27;s detritus was for (a Rubik&#x27;s cube, a spork, a fire \n",
       "extinguisher), and he saves a few items  an alarmingly fresh 700-year-old Twinkie, \n",
       "say, for his pet cockroach.  \n",
       "But most of the trash he compacts and stacks, in a routine that is interrupted only when he \n",
       "falls head-over-treads for a sleek robot from the stars: EVE (for Extra-terrestrial \n",
       "Vegetation Evaluator), whom he watches from afar so he won&#x27;t be incinerated.  \n",
       "Eve has an itchy trigger-finger, it turns out. \n",
       "The first hour of Wall-E is <span class=\"lx-highlight\" data-idx=\"6\" style=\"background-color:#C8E6C9;\">a crazily inventive, deliriously engaging and almost wordless \n",
       "silent comedy</span> of the sort that Charlie Chaplin and Buster Keaton used to make. Things \n",
       "turn <span class=\"lx-highlight\" data-idx=\"7\" style=\"background-color:#C8E6C9;\">more conventional</span> in the last half hour, when pudgy, machine-dependent humans \n",
       "make an appearance, but <span class=\"lx-highlight\" data-idx=\"8\" style=\"background-color:#D2E3FC;\">the glow of that first part will carry you through</span>.  \n",
       "That and the majesty of the filmmaking: Wall-E&#x27;s world, in all its epic decay, <span class=\"lx-highlight\" data-idx=\"9\" style=\"background-color:#C8E6C9;\">looks real</span>. \n",
       "<span class=\"lx-highlight\" data-idx=\"10\" style=\"background-color:#D2E3FC;\">You can almost taste the dust</span>. And it&#x27;s <span class=\"lx-highlight\" data-idx=\"11\" style=\"background-color:#C8E6C9;\">emotionally real</span> too  enough so that <span class=\"lx-highlight\" data-idx=\"12\" style=\"background-color:#C8E6C9;\">a \n",
       "cautionary tale about the environment, and about big corporations that don&#x27;t take care of \n",
       "it, and about getting so caught up in our gadgetry that we forget to look at the stars all \n",
       "take a back seat to romance</span>.  \n",
       "So do some specifically cinematic subtexts. Director Andrew Stanton and his animators \n",
       "have slipped in <span class=\"lx-highlight\" data-idx=\"13\" style=\"background-color:#C8E6C9;\">nods not just to Hello, Dolly!, but to Star Wars and Blade Runner, An \n",
       "Inconvenient Truth and the comedies of Chaplin and Jacques Tati</span>. More than just a nod \n",
       "to Chaplin, actually: Wall-E, with his workaholic scruffiness and his yearning for \n",
       "someone to hold hands with, <span class=\"lx-highlight\" data-idx=\"14\" style=\"background-color:#C8E6C9;\">might as well be Chaplin&#x27;s Little Tramp</span>. \n",
       "There&#x27;s actually a <span class=\"lx-highlight\" data-idx=\"15\" style=\"background-color:#C8E6C9;\">nice parallel</span> between this largely silent film and Chaplin&#x27;s first sound \n",
       "film, Modern Times. In that one, the <span class=\"lx-highlight\" data-idx=\"16\" style=\"background-color:#C8E6C9;\">silent clown used the soundtrack mostly for music \n",
       "and effects, not for speech</span>, just as Pixar does here. Chaplin only let you hear a human \n",
       "voice a couple of times, and only on some sort of mechanical contraption  say a closed-\n",
       "circuit TV screen  to emphasize its artificiality. It was his way of saying to the sound \n",
       "world, &quot;OK, everybody&#x27;s doing this talking thing now, but <span class=\"lx-highlight\" data-idx=\"17\" style=\"background-color:#C8E6C9;\">look how much more \n",
       "expressive our silent world is</span>.&quot;  \n",
       "For the first time in a Pixar movie, Wall-E&#x27;s filmmakers give a nod to the world of actual \n",
       "actors and cameras  and make them artificial in the same way: by only letting you see \n",
       "them on video screens, where they <span class=\"lx-highlight\" data-idx=\"18\" style=\"background-color:#C8E6C9;\">look flat and washed-out</span> compared to the digital \n",
       "world around them. \n",
       "But there&#x27;s one difference. Chaplin knew he had lost the battle: Silence was finished; \n",
       "sound had won. In today&#x27;s Hollywood, <span class=\"lx-highlight\" data-idx=\"19\" style=\"background-color:#C8E6C9;\">digital is what&#x27;s taking over</span>  in special effects, \n",
       "in green-screen work, in animation. And Pixar&#x27;s animators, bless them, are at the\n",
       "&quot;&quot;&quot;\n",
       "\n",
       "**Page 3**\n",
       "&quot;&quot;&quot;\n",
       "forefront, insisting that <span class=\"lx-highlight\" data-idx=\"20\" style=\"background-color:#C8E6C9;\">imagery created on computers doesn&#x27;t have to be soulless</span>. <span class=\"lx-highlight\" data-idx=\"21\" style=\"background-color:#C8E6C9;\">Wall-\n",
       "E&#x27;s images are filled with emotion</span>, just as silent film&#x27;s images were  even though its \n",
       "characters look like they&#x27;re made of metal and plastic, and can&#x27;t say a word.  \n",
       "Wall-E is being sold as a futuristic fantasy, of course. But I have to say I&#x27;m just as \n",
       "<span class=\"lx-highlight\" data-idx=\"22\" style=\"background-color:#C8E6C9;\"><span class=\"lx-highlight\" data-idx=\"23\" style=\"background-color:#C8E6C9;\">gratified by their look back 70 years to silent movies</span> as I am by their look forward 700 \n",
       "years to a silent planet</span>.\n",
       "&quot;&quot;&quot;\n",
       "\n",
       "\n",
       "      </div>\n",
       "      <div class=\"lx-controls\">\n",
       "        <div class=\"lx-button-row\">\n",
       "          <button class=\"lx-control-btn\" onclick=\"playPause()\"> Play</button>\n",
       "          <button class=\"lx-control-btn\" onclick=\"prevExtraction()\"> Previous</button>\n",
       "          <button class=\"lx-control-btn\" onclick=\"nextExtraction()\"> Next</button>\n",
       "        </div>\n",
       "        <div class=\"lx-progress-container\">\n",
       "          <input type=\"range\" id=\"progressSlider\" class=\"lx-progress-slider\"\n",
       "                 min=\"0\" max=\"23\" value=\"0\"\n",
       "                 onchange=\"jumpToExtraction(this.value)\">\n",
       "        </div>\n",
       "        <div class=\"lx-status-text\">\n",
       "          Entity <span id=\"entityInfo\">1/24</span> |\n",
       "          Pos <span id=\"posInfo\">[389-452]</span>\n",
       "        </div>\n",
       "      </div>\n",
       "    </div>\n",
       "\n",
       "    <script>\n",
       "      (function() {\n",
       "        const extractions = [{\"index\": 0, \"class\": \"opinion_statement\", \"text\": \"Big-hearted and full of wonder, but too smart to be saccharine.\", \"color\": \"#C8E6C9\", \"startPos\": 389, \"endPos\": 452, \"beforeText\": \"actor, but he&#x27;s learned how to look to the sky. Pixar \\nWall-E \\n\\u2022 \\nDirector: Andrew Stanton  \\n\\u2022 \\nGenre: Sci-Fi  \\n\\u2022 \\nRunning Time: 97 minutes \\nRated G: \", \"extractionText\": \"Big-hearted and full of wonder, but too smart to be saccharine.\", \"afterText\": \" \\n\\u201cThe first hour of Wall-E is a crazily inventive, deliriously engaging and almost wordless silent comedy of the sort that \\nCharlie Chaplin and Buste\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Rated G</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">Big-hearted and full of wonder, but too smart to be saccharine</span>}</div>\"}, {\"index\": 1, \"class\": \"opinion_statement\", \"text\": \"a crazily inventive, deliriously engaging and almost wordless silent comedy of the sort that Charlie Chaplin and Buster Keaton used to make.\", \"color\": \"#C8E6C9\", \"startPos\": 483, \"endPos\": 623, \"beforeText\": \" \\nGenre: Sci-Fi  \\n\\u2022 \\nRunning Time: 97 minutes \\nRated G: Big-hearted and full of wonder, but too smart to be saccharine. \\n\\u201cThe first hour of Wall-E is \", \"extractionText\": \"a crazily inventive, deliriously engaging and almost wordless silent comedy of the sort that \\nCharlie Chaplin and Buster Keaton used to make\", \"afterText\": \".\\u201d \\n \\nAll Things Considered, June 27, 2008 \\u00b7 The camera descends, at the start of Wall-E, from \\nouter space to a landscape that looks eerily familiar \", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The first hour of Wall-E</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">crazily inventive, deliriously engaging and almost wordless silent comedy</span>}</div>\"}, {\"index\": 2, \"class\": \"audience_impact\", \"text\": \"deliriously engaging\", \"color\": \"#D2E3FC\", \"startPos\": 504, \"endPos\": 524, \"beforeText\": \"Running Time: 97 minutes \\nRated G: Big-hearted and full of wonder, but too smart to be saccharine. \\n\\u201cThe first hour of Wall-E is a crazily inventive, \", \"extractionText\": \"deliriously engaging\", \"afterText\": \" and almost wordless silent comedy of the sort that \\nCharlie Chaplin and Buster Keaton used to make.\\u201d \\n \\nAll Things Considered, June 27, 2008 \\u00b7 The ca\", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">delight, captivation</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">the silent comedy style</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">the audience</span>}</div>\"}, {\"index\": 3, \"class\": \"opinion_statement\", \"text\": \"looks eerily familiar \\u2014 and sort of not.\", \"color\": \"#C8E6C9\", \"startPos\": 751, \"endPos\": 791, \"beforeText\": \"er Keaton used to make.\\u201d \\n \\nAll Things Considered, June 27, 2008 \\u00b7 The camera descends, at the start of Wall-E, from \\nouter space to a landscape that \", \"extractionText\": \"looks eerily familiar \\u2014 and sort of not.\", \"afterText\": \" The sun filters \\ndown through a brownish haze. What seem at first like skyscrapers turn out to be neatly \\nstacked mountains of trash. Stillness is ev\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">a landscape</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Neutral</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">looks eerily familiar \\u2014 and sort of not</span>}</div>\"}, {\"index\": 4, \"class\": \"opinion_statement\", \"text\": \"Stillness is everywhere\", \"color\": \"#C8E6C9\", \"startPos\": 926, \"endPos\": 949, \"beforeText\": \"nd sort of not. The sun filters \\ndown through a brownish haze. What seem at first like skyscrapers turn out to be neatly \\nstacked mountains of trash. \", \"extractionText\": \"Stillness is everywhere\", \"afterText\": \", broken only by the unlikely sound of \\na song from Hello, Dolly! \\u2014 and a solitary figure zipping around a junk-strewn \\ncityscape.  \\nApparently, human\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">the landscape</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Neutral</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">Stillness is everywhere</span>}</div>\"}, {\"index\": 5, \"class\": \"opinion_statement\", \"text\": \"developed a personality.\", \"color\": \"#C8E6C9\", \"startPos\": 1470, \"endPos\": 1494, \"beforeText\": \"ehind. He&#x27;s basically \\na trash compactor on treads \\u2014 a Waste Allocation Load-Lifter: Earth Class, or WALL-E \\n\\u2014 who has, over the course of 700 years, \", \"extractionText\": \"developed a personality.\", \"afterText\": \"\\n&quot;&quot;&quot;\\n\\n**Page 2**\\n&quot;&quot;&quot;\\nHe tries to puzzle out what mankind&#x27;s detritus was for (a Rubik&#x27;s cube, a spork, a fire \\nextinguisher), and he saves a few items \", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">He</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">developed a personality</span>}</div>\"}, {\"index\": 6, \"class\": \"opinion_statement\", \"text\": \"a crazily inventive, deliriously engaging and almost wordless silent comedy\", \"color\": \"#C8E6C9\", \"startPos\": 2052, \"endPos\": 2128, \"beforeText\": \"ation Evaluator), whom he watches from afar so he won&#x27;t be incinerated.  \\nEve has an itchy trigger-finger, it turns out. \\nThe first hour of Wall-E is \", \"extractionText\": \"a crazily inventive, deliriously engaging and almost wordless \\nsilent comedy\", \"afterText\": \" of the sort that Charlie Chaplin and Buster Keaton used to make. Things \\nturn more conventional in the last half hour, when pudgy, machine-dependent \", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The first hour of Wall-E</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">crazily inventive, deliriously engaging and almost wordless silent comedy</span>}</div>\"}, {\"index\": 7, \"class\": \"opinion_statement\", \"text\": \"more conventional\", \"color\": \"#C8E6C9\", \"startPos\": 2207, \"endPos\": 2224, \"beforeText\": \"zily inventive, deliriously engaging and almost wordless \\nsilent comedy of the sort that Charlie Chaplin and Buster Keaton used to make. Things \\nturn \", \"extractionText\": \"more conventional\", \"afterText\": \" in the last half hour, when pudgy, machine-dependent humans \\nmake an appearance, but the glow of that first part will carry you through.  \\nThat and t\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Things</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Negative</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">more conventional</span>}</div>\"}, {\"index\": 8, \"class\": \"audience_impact\", \"text\": \"the glow of that first part will carry you through\", \"color\": \"#D2E3FC\", \"startPos\": 2310, \"endPos\": 2360, \"beforeText\": \"n and Buster Keaton used to make. Things \\nturn more conventional in the last half hour, when pudgy, machine-dependent humans \\nmake an appearance, but \", \"extractionText\": \"the glow of that first part will carry you through\", \"afterText\": \".  \\nThat and the majesty of the filmmaking: Wall-E&#x27;s world, in all its epic decay, looks real. \\nYou can almost taste the dust. And it&#x27;s emotionally re\", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">sustained engagement, satisfaction</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">the glow of that first part</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">the audience</span>}</div>\"}, {\"index\": 9, \"class\": \"opinion_statement\", \"text\": \"looks real\", \"color\": \"#C8E6C9\", \"startPos\": 2443, \"endPos\": 2453, \"beforeText\": \" appearance, but the glow of that first part will carry you through.  \\nThat and the majesty of the filmmaking: Wall-E&#x27;s world, in all its epic decay, \", \"extractionText\": \"looks real\", \"afterText\": \". \\nYou can almost taste the dust. And it&#x27;s emotionally real too \\u2014 enough so that a \\ncautionary tale about the environment, and about big corporations \", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Wall-E&#x27;s world</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">looks real</span>}</div>\"}, {\"index\": 10, \"class\": \"audience_impact\", \"text\": \"You can almost taste the dust\", \"color\": \"#D2E3FC\", \"startPos\": 2456, \"endPos\": 2485, \"beforeText\": \"but the glow of that first part will carry you through.  \\nThat and the majesty of the filmmaking: Wall-E&#x27;s world, in all its epic decay, looks real. \\n\", \"extractionText\": \"You can almost taste the dust\", \"afterText\": \". And it&#x27;s emotionally real too \\u2014 enough so that a \\ncautionary tale about the environment, and about big corporations that don&#x27;t take care of \\nit, and\", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">immersion, sensory vividness</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">The dust</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">the reviewer</span>}</div>\"}, {\"index\": 11, \"class\": \"opinion_statement\", \"text\": \"emotionally real\", \"color\": \"#C8E6C9\", \"startPos\": 2496, \"endPos\": 2512, \"beforeText\": \"ry you through.  \\nThat and the majesty of the filmmaking: Wall-E&#x27;s world, in all its epic decay, looks real. \\nYou can almost taste the dust. And it&#x27;s \", \"extractionText\": \"emotionally real\", \"afterText\": \" too \\u2014 enough so that a \\ncautionary tale about the environment, and about big corporations that don&#x27;t take care of \\nit, and about getting so caught up\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">it</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">emotionally real</span>}</div>\"}, {\"index\": 12, \"class\": \"opinion_statement\", \"text\": \"a cautionary tale about the environment, and about big corporations that don't take care of it, and about getting so caught up in our gadgetry that we forget to look at the stars all take a back seat to romance\", \"color\": \"#C8E6C9\", \"startPos\": 2534, \"endPos\": 2747, \"beforeText\": \" of the filmmaking: Wall-E&#x27;s world, in all its epic decay, looks real. \\nYou can almost taste the dust. And it&#x27;s emotionally real too \\u2014 enough so that \", \"extractionText\": \"a \\ncautionary tale about the environment, and about big corporations that don&#x27;t take care of \\nit, and about getting so caught up in our gadgetry that we forget to look at the stars all \\ntake a back seat to romance\", \"afterText\": \".  \\nSo do some specifically cinematic subtexts. Director Andrew Stanton and his animators \\nhave slipped in nods not just to Hello, Dolly!, but to Star\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">cautionary tale</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Negative</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">take a back seat to romance</span>}</div>\"}, {\"index\": 13, \"class\": \"opinion_statement\", \"text\": \"nods not just to Hello, Dolly!, but to Star Wars and Blade Runner, An Inconvenient Truth and the comedies of Chaplin and Jacques Tati\", \"color\": \"#C8E6C9\", \"startPos\": 2854, \"endPos\": 2988, \"beforeText\": \" the stars all \\ntake a back seat to romance.  \\nSo do some specifically cinematic subtexts. Director Andrew Stanton and his animators \\nhave slipped in \", \"extractionText\": \"nods not just to Hello, Dolly!, but to Star Wars and Blade Runner, An \\nInconvenient Truth and the comedies of Chaplin and Jacques Tati\", \"afterText\": \". More than just a nod \\nto Chaplin, actually: Wall-E, with his workaholic scruffiness and his yearning for \\nsomeone to hold hands with, might as well \", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Director Andrew Stanton and his animators</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">slipped in nods</span>}</div>\"}, {\"index\": 14, \"class\": \"opinion_statement\", \"text\": \"might as well be Chaplin's Little Tramp\", \"color\": \"#C8E6C9\", \"startPos\": 3124, \"endPos\": 3163, \"beforeText\": \"d Jacques Tati. More than just a nod \\nto Chaplin, actually: Wall-E, with his workaholic scruffiness and his yearning for \\nsomeone to hold hands with, \", \"extractionText\": \"might as well be Chaplin&#x27;s Little Tramp\", \"afterText\": \". \\nThere&#x27;s actually a nice parallel between this largely silent film and Chaplin&#x27;s first sound \\nfilm, Modern Times. In that one, the silent clown used\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Wall-E</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">might as well be Chaplin&#x27;s Little Tramp</span>}</div>\"}, {\"index\": 15, \"class\": \"opinion_statement\", \"text\": \"nice parallel\", \"color\": \"#C8E6C9\", \"startPos\": 3185, \"endPos\": 3198, \"beforeText\": \"all-E, with his workaholic scruffiness and his yearning for \\nsomeone to hold hands with, might as well be Chaplin&#x27;s Little Tramp. \\nThere&#x27;s actually a \", \"extractionText\": \"nice parallel\", \"afterText\": \" between this largely silent film and Chaplin&#x27;s first sound \\nfilm, Modern Times. In that one, the silent clown used the soundtrack mostly for music \\na\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">this largely silent film and Chaplin&#x27;s first sound film, Modern Times</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">nice parallel</span>}</div>\"}, {\"index\": 16, \"class\": \"opinion_statement\", \"text\": \"silent clown used the soundtrack mostly for music and effects, not for speech\", \"color\": \"#C8E6C9\", \"startPos\": 3296, \"endPos\": 3374, \"beforeText\": \"in&#x27;s Little Tramp. \\nThere&#x27;s actually a nice parallel between this largely silent film and Chaplin&#x27;s first sound \\nfilm, Modern Times. In that one, the \", \"extractionText\": \"silent clown used the soundtrack mostly for music \\nand effects, not for speech\", \"afterText\": \", just as Pixar does here. Chaplin only let you hear a human \\nvoice a couple of times, and only on some sort of mechanical contraption \\u2014 say a closed-\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">the silent clown</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">used the soundtrack mostly for music and effects, not for speech</span>}</div>\"}, {\"index\": 17, \"class\": \"opinion_statement\", \"text\": \"look how much more expressive our silent world is\", \"color\": \"#C8E6C9\", \"startPos\": 3674, \"endPos\": 3724, \"beforeText\": \"\\ncircuit TV screen \\u2014 to emphasize its artificiality. It was his way of saying to the sound \\nworld, &quot;OK, everybody&#x27;s doing this talking thing now, but \", \"extractionText\": \"look how much more \\nexpressive our silent world is\", \"afterText\": \".&quot;  \\nFor the first time in a Pixar movie, Wall-E&#x27;s filmmakers give a nod to the world of actual \\nactors and cameras \\u2014 and make them artificial in the \", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">our silent world</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">more expressive</span>}</div>\"}, {\"index\": 18, \"class\": \"opinion_statement\", \"text\": \"look flat and washed-out\", \"color\": \"#C8E6C9\", \"startPos\": 3943, \"endPos\": 3967, \"beforeText\": \"nod to the world of actual \\nactors and cameras \\u2014 and make them artificial in the same way: by only letting you see \\nthem on video screens, where they \", \"extractionText\": \"look flat and washed-out\", \"afterText\": \" compared to the digital \\nworld around them. \\nBut there&#x27;s one difference. Chaplin knew he had lost the battle: Silence was finished; \\nsound had won. I\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">actual actors and cameras</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Negative</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">flat and washed-out</span>}</div>\"}, {\"index\": 19, \"class\": \"opinion_statement\", \"text\": \"digital is what's taking over\", \"color\": \"#C8E6C9\", \"startPos\": 4138, \"endPos\": 4167, \"beforeText\": \"tal \\nworld around them. \\nBut there&#x27;s one difference. Chaplin knew he had lost the battle: Silence was finished; \\nsound had won. In today&#x27;s Hollywood, \", \"extractionText\": \"digital is what&#x27;s taking over\", \"afterText\": \" \\u2014 in special effects, \\nin green-screen work, in animation. And Pixar&#x27;s animators, bless them, are at the\\n&quot;&quot;&quot;\\n\\n**Page 3**\\n&quot;&quot;&quot;\\nforefront, insisting tha\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">digital</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">taking over</span>}</div>\"}, {\"index\": 20, \"class\": \"opinion_statement\", \"text\": \"imagery created on computers doesn't have to be soulless\", \"color\": \"#C8E6C9\", \"startPos\": 4319, \"endPos\": 4375, \"beforeText\": \" in special effects, \\nin green-screen work, in animation. And Pixar&#x27;s animators, bless them, are at the\\n&quot;&quot;&quot;\\n\\n**Page 3**\\n&quot;&quot;&quot;\\nforefront, insisting that \", \"extractionText\": \"imagery created on computers doesn&#x27;t have to be soulless\", \"afterText\": \". Wall-\\nE&#x27;s images are filled with emotion, just as silent film&#x27;s images were \\u2014 even though its \\ncharacters look like they&#x27;re made of metal and plasti\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">imagery created on computers</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">doesn&#x27;t have to be soulless</span>}</div>\"}, {\"index\": 21, \"class\": \"opinion_statement\", \"text\": \"Wall-E's images are filled with emotion\", \"color\": \"#C8E6C9\", \"startPos\": 4377, \"endPos\": 4417, \"beforeText\": \"And Pixar&#x27;s animators, bless them, are at the\\n&quot;&quot;&quot;\\n\\n**Page 3**\\n&quot;&quot;&quot;\\nforefront, insisting that imagery created on computers doesn&#x27;t have to be soulless. \", \"extractionText\": \"Wall-\\nE&#x27;s images are filled with emotion\", \"afterText\": \", just as silent film&#x27;s images were \\u2014 even though its \\ncharacters look like they&#x27;re made of metal and plastic, and can&#x27;t say a word.  \\nWall-E is being\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Wall-E&#x27;s images</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">filled with emotion</span>}</div>\"}, {\"index\": 22, \"class\": \"opinion_statement\", \"text\": \"gratified by their look forward 700 years to a silent planet\", \"color\": \"#C8E6C9\", \"startPos\": 4640, \"endPos\": 4754, \"beforeText\": \"ke they&#x27;re made of metal and plastic, and can&#x27;t say a word.  \\nWall-E is being sold as a futuristic fantasy, of course. But I have to say I&#x27;m just as \\n\", \"extractionText\": \"gratified by their look back 70 years to silent movies as I am by their look forward 700 \\nyears to a silent planet\", \"afterText\": \".\\n&quot;&quot;&quot;\\n\\n\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">their look forward 700 years to a silent planet</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">gratified</span>}</div>\"}, {\"index\": 23, \"class\": \"opinion_statement\", \"text\": \"gratified by their look back 70 years to silent movies\", \"color\": \"#C8E6C9\", \"startPos\": 4640, \"endPos\": 4694, \"beforeText\": \"ke they&#x27;re made of metal and plastic, and can&#x27;t say a word.  \\nWall-E is being sold as a futuristic fantasy, of course. But I have to say I&#x27;m just as \\n\", \"extractionText\": \"gratified by their look back 70 years to silent movies\", \"afterText\": \" as I am by their look forward 700 \\nyears to a silent planet.\\n&quot;&quot;&quot;\\n\\n\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">their look back 70 years to silent movies</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">gratified</span>}</div>\"}];\n",
       "        let currentIndex = 0;\n",
       "        let isPlaying = false;\n",
       "        let animationInterval = null;\n",
       "        let animationSpeed = 1.0;\n",
       "\n",
       "        function updateDisplay() {\n",
       "          const extraction = extractions[currentIndex];\n",
       "          if (!extraction) return;\n",
       "\n",
       "          document.getElementById('attributesContainer').innerHTML = extraction.attributesHtml;\n",
       "          document.getElementById('entityInfo').textContent = (currentIndex + 1) + '/' + extractions.length;\n",
       "          document.getElementById('posInfo').textContent = '[' + extraction.startPos + '-' + extraction.endPos + ']';\n",
       "          document.getElementById('progressSlider').value = currentIndex;\n",
       "\n",
       "          const playBtn = document.querySelector('.lx-control-btn');\n",
       "          if (playBtn) playBtn.textContent = isPlaying ? ' Pause' : ' Play';\n",
       "\n",
       "          const prevHighlight = document.querySelector('.lx-text-window .lx-current-highlight');\n",
       "          if (prevHighlight) prevHighlight.classList.remove('lx-current-highlight');\n",
       "          const currentSpan = document.querySelector('.lx-text-window span[data-idx=\"' + currentIndex + '\"]');\n",
       "          if (currentSpan) {\n",
       "            currentSpan.classList.add('lx-current-highlight');\n",
       "            currentSpan.scrollIntoView({block: 'center', behavior: 'smooth'});\n",
       "          }\n",
       "        }\n",
       "\n",
       "        function nextExtraction() {\n",
       "          currentIndex = (currentIndex + 1) % extractions.length;\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function prevExtraction() {\n",
       "          currentIndex = (currentIndex - 1 + extractions.length) % extractions.length;\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function jumpToExtraction(index) {\n",
       "          currentIndex = parseInt(index);\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function playPause() {\n",
       "          if (isPlaying) {\n",
       "            clearInterval(animationInterval);\n",
       "            isPlaying = false;\n",
       "          } else {\n",
       "            animationInterval = setInterval(nextExtraction, animationSpeed * 1000);\n",
       "            isPlaying = true;\n",
       "          }\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        window.playPause = playPause;\n",
       "        window.nextExtraction = nextExtraction;\n",
       "        window.prevExtraction = prevExtraction;\n",
       "        window.jumpToExtraction = jumpToExtraction;\n",
       "\n",
       "        updateDisplay();\n",
       "      })();\n",
       "    </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **Disscusions**\n",
    "\n",
    "### **Results**\n",
    "\n",
    "Langextract successfully extracted multiple evaluative and emotionally expressive phrases from the Wall-E review, with grounding accurately highlighting each span in the original text. Expressions such as looks real and You can almost taste the dust were correctly categorized as critical opinions or audience impact, demonstrating that the model can reliably identify evaluative tone, viewing experience, and visual descriptions. Overall extraction quality is consistent and stable.\n",
    "\n",
    "### **Limitations**\n",
    "\n",
    "Some multi-adjective opinion phrases were only partially extracted, resulting in incomplete representation of the reviewers full description. Additionally, several emotionally charged or atmospheric expressions were not classified as audience impact, causing recall to drop. The model also displayed a bias toward positive sentiment, labeling terms like loneliness or emptiness as positive, indicating insufficient sensitivity in sentiment classification.\n",
    "\n",
    "### **Future works**\n",
    "\n",
    "Recall can be improved by increasing extraction_passes (e.g., to 23) and expanding max_char_buffer to provide more contextual continuity across batches. Adding more diverse few-shot examplesespecially those containing mixed emotions, negative imagery, and atmospheric descriptionscan reduce sentiment bias and help the model better interpret the tone of film criticism. Clearer prompt rules can also prevent partial extraction of long descriptive phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_8_'></a>[**2.4 Generating LLM Embeddings:**](#toc0_)\n",
    "\n",
    "LLM embeddings are dense numerical vectors that represent the semantic meaning of text. Generated by Large Language Models, they map words, phrases, or documents into a high-dimensional space where similar concepts are positioned closely together.\n",
    "\n",
    "Their key advantages are:\n",
    "\n",
    "*   **Contextual Understanding:** Unlike older methods, LLM embeddings are contextual. The vector for a word like **\"bank\"** will be different depending on whether it's used in the context of a \"river bank\" or a \"money bank,\" providing a more nuanced representation of language.\n",
    "\n",
    "*   **Versatility from Pre-training:** They are pre-trained on vast amounts of text data. This allows them to generalize effectively across various tasks, such as classification, clustering, and similarity detection. They do not require extensive retraining.\n",
    "\n",
    "<span style=\"color:green\">For the exercise in this section there is no need to re-run the cells, you can use the data that has been saved previously to the corresponding directory.</span>\n",
    "\n",
    "**Now let's generate some embeddings with Gemini for a sample of our dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import pandas as pd\n",
    "import time\n",
    "from google.api_core import exceptions\n",
    "\n",
    "# Let's define our function to get the embeddings with Gemini\n",
    "def get_gemini_embedding(text: str, model: str=\"gemini-embedding-001\"):\n",
    "    try:\n",
    "        result = client.models.embed_content(model=model, contents=[text])\n",
    "        # 100 requests per minute limit -> 60s / 100 = 0.6s per request\n",
    "        # buffer time to avoid rate limits\n",
    "        time.sleep(0.6)\n",
    "        return result.embeddings\n",
    "    except exceptions.ResourceExhausted as e:\n",
    "        print(f\"Rate limit exceeded. Waiting to retry... Error: {e}\")\n",
    "        time.sleep(5) # Wait for 5 seconds before the next attempt\n",
    "        return get_gemini_embedding(text, model) # Retry the request\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 160 rows from the training set...\n",
      "Sampling 40 rows from the test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lx/b868nzys5b9139jlvjxp7r800000gn/T/ipykernel_11882/2000596105.py:14: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df.groupby(stratify_col, group_keys=False).apply(\n",
      "/var/folders/lx/b868nzys5b9139jlvjxp7r800000gn/T/ipykernel_11882/2000596105.py:14: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df.groupby(stratify_col, group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "total_extractions = 200\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.2\n",
    "\n",
    "n_train_to_sample = int(total_extractions * train_ratio)\n",
    "n_test_to_sample = int(total_extractions * test_ratio)\n",
    "# We use the text column\n",
    "column_name = 'text'\n",
    "\n",
    "# This function is to get a stratified sample from our data, meaning to have the same distribution of labels as in the full dataset\n",
    "def stratified_sample(df: pd.DataFrame, n_samples: int, stratify_col: str = 'emotion') -> pd.DataFrame:\n",
    "    if n_samples >= len(df):\n",
    "        return df.copy() # Return a copy if requested sample is larger or equal\n",
    "    sampled_df = df.groupby(stratify_col, group_keys=False).apply(\n",
    "        lambda x: x.sample(n=max(0, int(round(len(x) / len(df) * n_samples))))\n",
    "    )\n",
    "\n",
    "    # Adjust for rounding errors to get the exact number of samples\n",
    "    current_samples = len(sampled_df)\n",
    "    if current_samples < n_samples:\n",
    "        remaining_indices = df.index.difference(sampled_df.index)\n",
    "        additional_samples = df.loc[remaining_indices].sample(n=n_samples - current_samples, random_state=42)\n",
    "        sampled_df = pd.concat([sampled_df, additional_samples])\n",
    "    elif current_samples > n_samples:\n",
    "        sampled_df = sampled_df.sample(n=n_samples, random_state=42)\n",
    "    return sampled_df\n",
    "\n",
    "print(f\"Sampling {n_train_to_sample} rows from the training set...\")\n",
    "train_df_new = stratified_sample(train_df, n_train_to_sample, 'emotion')\n",
    "\n",
    "print(f\"Sampling {n_test_to_sample} rows from the test set...\")\n",
    "test_df_new = stratified_sample(test_df, n_test_to_sample, 'emotion')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "fear       51\n",
       "anger      38\n",
       "joy        36\n",
       "sadness    35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_new[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "fear       13\n",
       "anger      10\n",
       "joy         9\n",
       "sadness     8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_new[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating embeddings for the new training set...\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to the specified column and store the result in a new column 'embeddings'\n",
    "print(\"\\nGenerating embeddings for the new training set...\")\n",
    "train_df_new['embeddings'] = train_df_new[column_name].apply(get_gemini_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating embeddings for the new test set...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGenerating embeddings for the new test set...\")\n",
    "test_df_new['embeddings'] = test_df_new[column_name].apply(get_gemini_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "\n",
    "# After getting the embeddings we need to convert the Gemini type ContentDict of the embeddings into a simple list with them\n",
    "train_df_new['embeddings_values'] = train_df_new[\"embeddings\"].apply(lambda row: list(types.ContentDict(row[0]).values())[0])\n",
    "test_df_new['embeddings_values'] = test_df_new[\"embeddings\"].apply(lambda row: list(types.ContentDict(row[0]).values())[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>embeddings_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>10494</td>\n",
       "      <td>@kitanoye Hell is hot and boiling, isi ewu</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.458</td>\n",
       "      <td>[values=[0.0070372447, -0.0032764277, 0.016852...</td>\n",
       "      <td>[0.0070372447, -0.0032764277, 0.016852034, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>10408</td>\n",
       "      <td>@JuliaHB1 Bloody right #fume</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[values=[0.011767001, 0.0039524795, -0.0050234...</td>\n",
       "      <td>[0.011767001, 0.0039524795, -0.0050234273, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>10745</td>\n",
       "      <td>@RealJeffsdomain Wolfpack theme and trons and ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.312</td>\n",
       "      <td>[values=[-0.0083146095, -0.01835516, 0.0261475...</td>\n",
       "      <td>[-0.0083146095, -0.01835516, 0.026147552, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>10192</td>\n",
       "      <td>Not giving a fuck is better than revenge.</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.625</td>\n",
       "      <td>[values=[-0.004375375, -0.0011419968, -0.03067...</td>\n",
       "      <td>[-0.004375375, -0.0011419968, -0.030673679, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>10800</td>\n",
       "      <td>testing</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.250</td>\n",
       "      <td>[values=[-0.022131933, -0.0013199075, 0.026252...</td>\n",
       "      <td>[-0.022131933, -0.0013199075, 0.026252111, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>40448</td>\n",
       "      <td>@kikibug13 Don't look. You'll only be very, ve...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.438</td>\n",
       "      <td>[values=[0.002784944, 0.0051120007, -0.0240733...</td>\n",
       "      <td>[0.002784944, 0.0051120007, -0.024073355, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3015</th>\n",
       "      <td>40188</td>\n",
       "      <td>All the 'juniors' are now wearing purple at ol...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.646</td>\n",
       "      <td>[values=[-0.0126338685, 0.005191998, 0.0049113...</td>\n",
       "      <td>[-0.0126338685, 0.005191998, 0.0049113403, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2844</th>\n",
       "      <td>40017</td>\n",
       "      <td>It's a gloomy ass day</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.888</td>\n",
       "      <td>[values=[-0.015133099, 0.033976454, -0.0428779...</td>\n",
       "      <td>[-0.015133099, 0.033976454, -0.042877983, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3488</th>\n",
       "      <td>40661</td>\n",
       "      <td>ya boy gets mad tired of pine trees</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.292</td>\n",
       "      <td>[values=[-0.0107395835, 0.004646165, -0.009771...</td>\n",
       "      <td>[-0.0107395835, 0.004646165, -0.009771083, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3542</th>\n",
       "      <td>40715</td>\n",
       "      <td>Mmmm #coffee and a good #book on a dreary day!...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.250</td>\n",
       "      <td>[values=[-0.0061762785, -0.0014339492, 0.01963...</td>\n",
       "      <td>[-0.0061762785, -0.0014339492, 0.019638922, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  emotion  \\\n",
       "494   10494         @kitanoye Hell is hot and boiling, isi ewu    anger   \n",
       "408   10408                       @JuliaHB1 Bloody right #fume    anger   \n",
       "745   10745  @RealJeffsdomain Wolfpack theme and trons and ...    anger   \n",
       "192   10192          Not giving a fuck is better than revenge.    anger   \n",
       "800   10800                                           testing     anger   \n",
       "...     ...                                                ...      ...   \n",
       "3275  40448  @kikibug13 Don't look. You'll only be very, ve...  sadness   \n",
       "3015  40188  All the 'juniors' are now wearing purple at ol...  sadness   \n",
       "2844  40017                              It's a gloomy ass day  sadness   \n",
       "3488  40661                ya boy gets mad tired of pine trees  sadness   \n",
       "3542  40715  Mmmm #coffee and a good #book on a dreary day!...  sadness   \n",
       "\n",
       "      intensity                                         embeddings  \\\n",
       "494       0.458  [values=[0.0070372447, -0.0032764277, 0.016852...   \n",
       "408       0.500  [values=[0.011767001, 0.0039524795, -0.0050234...   \n",
       "745       0.312  [values=[-0.0083146095, -0.01835516, 0.0261475...   \n",
       "192       0.625  [values=[-0.004375375, -0.0011419968, -0.03067...   \n",
       "800       0.250  [values=[-0.022131933, -0.0013199075, 0.026252...   \n",
       "...         ...                                                ...   \n",
       "3275      0.438  [values=[0.002784944, 0.0051120007, -0.0240733...   \n",
       "3015      0.646  [values=[-0.0126338685, 0.005191998, 0.0049113...   \n",
       "2844      0.888  [values=[-0.015133099, 0.033976454, -0.0428779...   \n",
       "3488      0.292  [values=[-0.0107395835, 0.004646165, -0.009771...   \n",
       "3542      0.250  [values=[-0.0061762785, -0.0014339492, 0.01963...   \n",
       "\n",
       "                                      embeddings_values  \n",
       "494   [0.0070372447, -0.0032764277, 0.016852034, -0....  \n",
       "408   [0.011767001, 0.0039524795, -0.0050234273, -0....  \n",
       "745   [-0.0083146095, -0.01835516, 0.026147552, -0.0...  \n",
       "192   [-0.004375375, -0.0011419968, -0.030673679, -0...  \n",
       "800   [-0.022131933, -0.0013199075, 0.026252111, -0....  \n",
       "...                                                 ...  \n",
       "3275  [0.002784944, 0.0051120007, -0.024073355, -0.0...  \n",
       "3015  [-0.0126338685, 0.005191998, 0.0049113403, -0....  \n",
       "2844  [-0.015133099, 0.033976454, -0.042877983, -0.0...  \n",
       "3488  [-0.0107395835, 0.004646165, -0.009771083, -0....  \n",
       "3542  [-0.0061762785, -0.0014339492, 0.019638922, -0...  \n",
       "\n",
       "[160 rows x 6 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_new #We can see the new column with the embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>embeddings_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>30893</td>\n",
       "      <td>Tutoring gives me such an exhilarating feeling...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.896</td>\n",
       "      <td>[values=[-0.001733817, 0.023356104, 0.00310448...</td>\n",
       "      <td>[-0.001733817, 0.023356104, 0.0031044893, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>21252</td>\n",
       "      <td>Staff on @ryainair FR1005. Asked for info and ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.312</td>\n",
       "      <td>[values=[-0.025618004, 0.0014453683, 0.0045416...</td>\n",
       "      <td>[-0.025618004, 0.0014453683, 0.0045416863, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>10887</td>\n",
       "      <td>Everybody talking about 'the first day of fall...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.417</td>\n",
       "      <td>[values=[-0.016532253, -0.018671215, 0.0024112...</td>\n",
       "      <td>[-0.016532253, -0.018671215, 0.0024112132, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>30823</td>\n",
       "      <td>@theclobra lol I thought maybe, couldn't decid...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.312</td>\n",
       "      <td>[values=[-0.009851168, -0.0074269082, -0.00489...</td>\n",
       "      <td>[-0.009851168, -0.0074269082, -0.004893037, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>10935</td>\n",
       "      <td>@TrevorHMoore @paget_old In Scotland, the righ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.604</td>\n",
       "      <td>[values=[0.009859718, -0.009872029, 0.02174849...</td>\n",
       "      <td>[0.009859718, -0.009872029, 0.02174849, -0.054...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>40847</td>\n",
       "      <td>Chalk dance notation entree manchester inasmuc...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.188</td>\n",
       "      <td>[values=[0.0019100033, -0.004571983, 0.0084986...</td>\n",
       "      <td>[0.0019100033, -0.004571983, 0.008498684, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>21192</td>\n",
       "      <td>And I cried in front of my guy last night. And...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.680</td>\n",
       "      <td>[values=[-0.006811888, -0.007458425, -0.008265...</td>\n",
       "      <td>[-0.006811888, -0.007458425, -0.008265424, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>40855</td>\n",
       "      <td>Common app just randomly logged me out as I wa...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.833</td>\n",
       "      <td>[values=[0.0018189758, 0.023590546, -0.0067852...</td>\n",
       "      <td>[0.0018189758, 0.023590546, -0.0067852526, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>30838</td>\n",
       "      <td>i was so embarrassed when she saw us i was lik...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.250</td>\n",
       "      <td>[values=[-0.021463713, -0.0071487995, -0.01163...</td>\n",
       "      <td>[-0.021463713, -0.0071487995, -0.011631403, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>10940</td>\n",
       "      <td>Lol little things like that make me so angry x</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.604</td>\n",
       "      <td>[values=[0.013566949, -0.00450142, 0.004378448...</td>\n",
       "      <td>[0.013566949, -0.00450142, 0.004378448, -0.054...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>30866</td>\n",
       "      <td>A #new day to #live and #smile. Hope all the #...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.688</td>\n",
       "      <td>[values=[-0.021614783, -0.014422985, -0.017751...</td>\n",
       "      <td>[-0.021614783, -0.014422985, -0.017751982, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>21175</td>\n",
       "      <td>@soozclifford Sure have... Sydney are too toug...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.356</td>\n",
       "      <td>[values=[-0.0070301127, -0.0028043932, 0.01494...</td>\n",
       "      <td>[-0.0070301127, -0.0028043932, 0.014941143, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>21217</td>\n",
       "      <td>@RyanAbe awe yay thank god I was so worried.</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[values=[-0.0054168217, -0.010775616, -0.01392...</td>\n",
       "      <td>[-0.0054168217, -0.010775616, -0.013928164, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>10925</td>\n",
       "      <td>Anger, resentment, and hatred are the destroye...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.375</td>\n",
       "      <td>[values=[0.006805829, 0.009590601, -0.00079551...</td>\n",
       "      <td>[0.006805829, 0.009590601, -0.0007955102, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>21167</td>\n",
       "      <td>@joey_coops yes Hun! Avoid at all costs!! #nig...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.667</td>\n",
       "      <td>[values=[0.00048812552, -0.009660845, -0.01429...</td>\n",
       "      <td>[0.00048812552, -0.009660845, -0.01429285, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>40841</td>\n",
       "      <td>I can't WAIT to go to work tomorrow with a hig...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.646</td>\n",
       "      <td>[values=[0.015356449, -0.010983185, 0.00574210...</td>\n",
       "      <td>[0.015356449, -0.010983185, 0.0057421084, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>21157</td>\n",
       "      <td>There goes the butterflies in my stomach.  #an...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.702</td>\n",
       "      <td>[values=[0.0116475625, -0.010445656, -0.008240...</td>\n",
       "      <td>[0.0116475625, -0.010445656, -0.008240249, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>40824</td>\n",
       "      <td>On bedrest since I got out of the hospital. U ...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.440</td>\n",
       "      <td>[values=[0.0041351523, -0.0051084706, -0.02860...</td>\n",
       "      <td>[0.0041351523, -0.0051084706, -0.028601801, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>40848</td>\n",
       "      <td>It's basically a dead skin peel which sounds g...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.354</td>\n",
       "      <td>[values=[0.026134387, 0.0031602613, -0.0021065...</td>\n",
       "      <td>[0.026134387, 0.0031602613, -0.0021065692, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10876</td>\n",
       "      <td>Hate when guys cant control their anger </td>\n",
       "      <td>anger</td>\n",
       "      <td>0.646</td>\n",
       "      <td>[values=[0.00510301, -0.023113215, -0.00640006...</td>\n",
       "      <td>[0.00510301, -0.023113215, -0.0064000674, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>30828</td>\n",
       "      <td>I love my family so much #lucky #grateful #sma...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.792</td>\n",
       "      <td>[values=[-0.041261364, -0.0025729102, 0.000523...</td>\n",
       "      <td>[-0.041261364, -0.0025729102, 0.00052370684, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10869</td>\n",
       "      <td>Me being on my dean really saving a lot of ppl...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.348</td>\n",
       "      <td>[values=[0.0064007128, -0.0034983447, -0.00495...</td>\n",
       "      <td>[0.0064007128, -0.0034983447, -0.004954461, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>21218</td>\n",
       "      <td>About 7 weeks till I can pick up my camera aga...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.396</td>\n",
       "      <td>[values=[-0.01749955, -0.019419283, -0.0182948...</td>\n",
       "      <td>[-0.01749955, -0.019419283, -0.018294835, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10884</td>\n",
       "      <td>@RevTrevK @Wolfman93011 @Daraidernation @EROCK...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.586</td>\n",
       "      <td>[values=[-0.013165958, -0.038608503, -0.008693...</td>\n",
       "      <td>[-0.013165958, -0.038608503, -0.008693953, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>30841</td>\n",
       "      <td>I turn 25 in two weeks. I am so happy. 24 was ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.708</td>\n",
       "      <td>[values=[-0.0019722884, 0.011153304, -0.023313...</td>\n",
       "      <td>[-0.0019722884, 0.011153304, -0.023313131, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>21196</td>\n",
       "      <td>@CNNPolitics I can't wait to hear what he had ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.354</td>\n",
       "      <td>[values=[0.0042716996, 0.021030126, 0.02605747...</td>\n",
       "      <td>[0.0042716996, 0.021030126, 0.026057476, -0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10882</td>\n",
       "      <td>It's the most magical time of the year......Xm...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.429</td>\n",
       "      <td>[values=[-0.032807905, 0.002414791, -0.0038823...</td>\n",
       "      <td>[-0.032807905, 0.002414791, -0.0038823327, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>30882</td>\n",
       "      <td>@chencouture LMAO Is it that 'so slutty' hater...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.700</td>\n",
       "      <td>[values=[-0.013635297, 0.0371389, -0.013098068...</td>\n",
       "      <td>[-0.013635297, 0.0371389, -0.013098068, -0.062...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>40798</td>\n",
       "      <td>@kayleighmcenany  @DonaldJTrumpJr Is that real...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.625</td>\n",
       "      <td>[values=[-0.021350382, 0.01630431, 0.01198983,...</td>\n",
       "      <td>[-0.021350382, 0.01630431, 0.01198983, -0.0519...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>10907</td>\n",
       "      <td>Just joined #pottermore and was sorted into HU...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.438</td>\n",
       "      <td>[values=[0.0007232955, -0.038711242, 0.0068611...</td>\n",
       "      <td>[0.0007232955, -0.038711242, 0.0068611447, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>40791</td>\n",
       "      <td>Buddha doesn't possess enough power to deliver...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.542</td>\n",
       "      <td>[values=[-0.0011776135, -0.010270097, -0.00675...</td>\n",
       "      <td>[-0.0011776135, -0.010270097, -0.0067513734, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>30844</td>\n",
       "      <td>@NateBLoL no it was that clear American natura...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.312</td>\n",
       "      <td>[values=[0.0005466202, 0.0077015567, 0.0056142...</td>\n",
       "      <td>[0.0005466202, 0.0077015567, 0.005614247, -0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>40846</td>\n",
       "      <td>Should of stayed in Dubai </td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.708</td>\n",
       "      <td>[values=[-0.021822749, -0.0510384, 0.013038017...</td>\n",
       "      <td>[-0.021822749, -0.0510384, 0.013038017, -0.066...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>21209</td>\n",
       "      <td>That's an awful miss from Rooney.</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.360</td>\n",
       "      <td>[values=[0.0067699635, 0.0032178797, -0.025996...</td>\n",
       "      <td>[0.0067699635, 0.0032178797, -0.025996458, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>21219</td>\n",
       "      <td>About 7 weeks till I can pick up my camera aga...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.312</td>\n",
       "      <td>[values=[-0.02468868, -0.015727378, -0.0265125...</td>\n",
       "      <td>[-0.02468868, -0.015727378, -0.026512522, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>21170</td>\n",
       "      <td>The Apocalypse has hit our gym and it's  nothi...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.583</td>\n",
       "      <td>[values=[0.00029141922, -0.038468916, 0.029741...</td>\n",
       "      <td>[0.00029141922, -0.038468916, 0.029741589, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>21215</td>\n",
       "      <td>When you're scared to press send #bgoodthepoet...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.842</td>\n",
       "      <td>[values=[-0.0022556814, -0.012241578, 0.005042...</td>\n",
       "      <td>[-0.0022556814, -0.012241578, 0.0050421893, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10878</td>\n",
       "      <td>Literally fuming fuck sake</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.860</td>\n",
       "      <td>[values=[0.004565768, -0.010073113, -0.0132940...</td>\n",
       "      <td>[0.004565768, -0.010073113, -0.013294056, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>21191</td>\n",
       "      <td>They'll be yo friend, shake your hand, then ki...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.417</td>\n",
       "      <td>[values=[0.008659948, -0.0070254644, -0.011189...</td>\n",
       "      <td>[0.008659948, -0.0070254644, -0.0111895, -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>30845</td>\n",
       "      <td>A cheerful heart is good medicine, but a broke...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.292</td>\n",
       "      <td>[values=[-0.010979394, 0.0126972, -0.029265268...</td>\n",
       "      <td>[-0.010979394, 0.0126972, -0.029265268, -0.051...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  emotion  \\\n",
       "264  30893  Tutoring gives me such an exhilarating feeling...      joy   \n",
       "189  21252  Staff on @ryainair FR1005. Asked for info and ...     fear   \n",
       "30   10887  Everybody talking about 'the first day of fall...    anger   \n",
       "194  30823  @theclobra lol I thought maybe, couldn't decid...      joy   \n",
       "78   10935  @TrevorHMoore @paget_old In Scotland, the righ...    anger   \n",
       "334  40847  Chalk dance notation entree manchester inasmuc...  sadness   \n",
       "129  21192  And I cried in front of my guy last night. And...     fear   \n",
       "342  40855  Common app just randomly logged me out as I wa...  sadness   \n",
       "209  30838  i was so embarrassed when she saw us i was lik...      joy   \n",
       "83   10940     Lol little things like that make me so angry x    anger   \n",
       "237  30866  A #new day to #live and #smile. Hope all the #...      joy   \n",
       "112  21175  @soozclifford Sure have... Sydney are too toug...     fear   \n",
       "154  21217       @RyanAbe awe yay thank god I was so worried.     fear   \n",
       "68   10925  Anger, resentment, and hatred are the destroye...    anger   \n",
       "104  21167  @joey_coops yes Hun! Avoid at all costs!! #nig...     fear   \n",
       "328  40841  I can't WAIT to go to work tomorrow with a hig...  sadness   \n",
       "94   21157  There goes the butterflies in my stomach.  #an...     fear   \n",
       "311  40824  On bedrest since I got out of the hospital. U ...  sadness   \n",
       "335  40848  It's basically a dead skin peel which sounds g...  sadness   \n",
       "19   10876         Hate when guys cant control their anger     anger   \n",
       "199  30828  I love my family so much #lucky #grateful #sma...      joy   \n",
       "12   10869  Me being on my dean really saving a lot of ppl...    anger   \n",
       "155  21218  About 7 weeks till I can pick up my camera aga...     fear   \n",
       "27   10884  @RevTrevK @Wolfman93011 @Daraidernation @EROCK...    anger   \n",
       "212  30841  I turn 25 in two weeks. I am so happy. 24 was ...      joy   \n",
       "133  21196  @CNNPolitics I can't wait to hear what he had ...     fear   \n",
       "25   10882  It's the most magical time of the year......Xm...    anger   \n",
       "253  30882  @chencouture LMAO Is it that 'so slutty' hater...      joy   \n",
       "285  40798  @kayleighmcenany  @DonaldJTrumpJr Is that real...  sadness   \n",
       "50   10907  Just joined #pottermore and was sorted into HU...    anger   \n",
       "278  40791  Buddha doesn't possess enough power to deliver...  sadness   \n",
       "215  30844  @NateBLoL no it was that clear American natura...      joy   \n",
       "333  40846                        Should of stayed in Dubai   sadness   \n",
       "146  21209                  That's an awful miss from Rooney.     fear   \n",
       "156  21219  About 7 weeks till I can pick up my camera aga...     fear   \n",
       "107  21170  The Apocalypse has hit our gym and it's  nothi...     fear   \n",
       "152  21215  When you're scared to press send #bgoodthepoet...     fear   \n",
       "21   10878                         Literally fuming fuck sake    anger   \n",
       "128  21191  They'll be yo friend, shake your hand, then ki...     fear   \n",
       "216  30845  A cheerful heart is good medicine, but a broke...      joy   \n",
       "\n",
       "     intensity                                         embeddings  \\\n",
       "264      0.896  [values=[-0.001733817, 0.023356104, 0.00310448...   \n",
       "189      0.312  [values=[-0.025618004, 0.0014453683, 0.0045416...   \n",
       "30       0.417  [values=[-0.016532253, -0.018671215, 0.0024112...   \n",
       "194      0.312  [values=[-0.009851168, -0.0074269082, -0.00489...   \n",
       "78       0.604  [values=[0.009859718, -0.009872029, 0.02174849...   \n",
       "334      0.188  [values=[0.0019100033, -0.004571983, 0.0084986...   \n",
       "129      0.680  [values=[-0.006811888, -0.007458425, -0.008265...   \n",
       "342      0.833  [values=[0.0018189758, 0.023590546, -0.0067852...   \n",
       "209      0.250  [values=[-0.021463713, -0.0071487995, -0.01163...   \n",
       "83       0.604  [values=[0.013566949, -0.00450142, 0.004378448...   \n",
       "237      0.688  [values=[-0.021614783, -0.014422985, -0.017751...   \n",
       "112      0.356  [values=[-0.0070301127, -0.0028043932, 0.01494...   \n",
       "154      0.500  [values=[-0.0054168217, -0.010775616, -0.01392...   \n",
       "68       0.375  [values=[0.006805829, 0.009590601, -0.00079551...   \n",
       "104      0.667  [values=[0.00048812552, -0.009660845, -0.01429...   \n",
       "328      0.646  [values=[0.015356449, -0.010983185, 0.00574210...   \n",
       "94       0.702  [values=[0.0116475625, -0.010445656, -0.008240...   \n",
       "311      0.440  [values=[0.0041351523, -0.0051084706, -0.02860...   \n",
       "335      0.354  [values=[0.026134387, 0.0031602613, -0.0021065...   \n",
       "19       0.646  [values=[0.00510301, -0.023113215, -0.00640006...   \n",
       "199      0.792  [values=[-0.041261364, -0.0025729102, 0.000523...   \n",
       "12       0.348  [values=[0.0064007128, -0.0034983447, -0.00495...   \n",
       "155      0.396  [values=[-0.01749955, -0.019419283, -0.0182948...   \n",
       "27       0.586  [values=[-0.013165958, -0.038608503, -0.008693...   \n",
       "212      0.708  [values=[-0.0019722884, 0.011153304, -0.023313...   \n",
       "133      0.354  [values=[0.0042716996, 0.021030126, 0.02605747...   \n",
       "25       0.429  [values=[-0.032807905, 0.002414791, -0.0038823...   \n",
       "253      0.700  [values=[-0.013635297, 0.0371389, -0.013098068...   \n",
       "285      0.625  [values=[-0.021350382, 0.01630431, 0.01198983,...   \n",
       "50       0.438  [values=[0.0007232955, -0.038711242, 0.0068611...   \n",
       "278      0.542  [values=[-0.0011776135, -0.010270097, -0.00675...   \n",
       "215      0.312  [values=[0.0005466202, 0.0077015567, 0.0056142...   \n",
       "333      0.708  [values=[-0.021822749, -0.0510384, 0.013038017...   \n",
       "146      0.360  [values=[0.0067699635, 0.0032178797, -0.025996...   \n",
       "156      0.312  [values=[-0.02468868, -0.015727378, -0.0265125...   \n",
       "107      0.583  [values=[0.00029141922, -0.038468916, 0.029741...   \n",
       "152      0.842  [values=[-0.0022556814, -0.012241578, 0.005042...   \n",
       "21       0.860  [values=[0.004565768, -0.010073113, -0.0132940...   \n",
       "128      0.417  [values=[0.008659948, -0.0070254644, -0.011189...   \n",
       "216      0.292  [values=[-0.010979394, 0.0126972, -0.029265268...   \n",
       "\n",
       "                                     embeddings_values  \n",
       "264  [-0.001733817, 0.023356104, 0.0031044893, -0.0...  \n",
       "189  [-0.025618004, 0.0014453683, 0.0045416863, -0....  \n",
       "30   [-0.016532253, -0.018671215, 0.0024112132, -0....  \n",
       "194  [-0.009851168, -0.0074269082, -0.004893037, -0...  \n",
       "78   [0.009859718, -0.009872029, 0.02174849, -0.054...  \n",
       "334  [0.0019100033, -0.004571983, 0.008498684, -0.0...  \n",
       "129  [-0.006811888, -0.007458425, -0.008265424, -0....  \n",
       "342  [0.0018189758, 0.023590546, -0.0067852526, -0....  \n",
       "209  [-0.021463713, -0.0071487995, -0.011631403, -0...  \n",
       "83   [0.013566949, -0.00450142, 0.004378448, -0.054...  \n",
       "237  [-0.021614783, -0.014422985, -0.017751982, -0....  \n",
       "112  [-0.0070301127, -0.0028043932, 0.014941143, -0...  \n",
       "154  [-0.0054168217, -0.010775616, -0.013928164, -0...  \n",
       "68   [0.006805829, 0.009590601, -0.0007955102, -0.0...  \n",
       "104  [0.00048812552, -0.009660845, -0.01429285, -0....  \n",
       "328  [0.015356449, -0.010983185, 0.0057421084, -0.0...  \n",
       "94   [0.0116475625, -0.010445656, -0.008240249, -0....  \n",
       "311  [0.0041351523, -0.0051084706, -0.028601801, -0...  \n",
       "335  [0.026134387, 0.0031602613, -0.0021065692, -0....  \n",
       "19   [0.00510301, -0.023113215, -0.0064000674, -0.0...  \n",
       "199  [-0.041261364, -0.0025729102, 0.00052370684, -...  \n",
       "12   [0.0064007128, -0.0034983447, -0.004954461, -0...  \n",
       "155  [-0.01749955, -0.019419283, -0.018294835, -0.0...  \n",
       "27   [-0.013165958, -0.038608503, -0.008693953, -0....  \n",
       "212  [-0.0019722884, 0.011153304, -0.023313131, -0....  \n",
       "133  [0.0042716996, 0.021030126, 0.026057476, -0.07...  \n",
       "25   [-0.032807905, 0.002414791, -0.0038823327, -0....  \n",
       "253  [-0.013635297, 0.0371389, -0.013098068, -0.062...  \n",
       "285  [-0.021350382, 0.01630431, 0.01198983, -0.0519...  \n",
       "50   [0.0007232955, -0.038711242, 0.0068611447, -0....  \n",
       "278  [-0.0011776135, -0.010270097, -0.0067513734, -...  \n",
       "215  [0.0005466202, 0.0077015567, 0.005614247, -0.1...  \n",
       "333  [-0.021822749, -0.0510384, 0.013038017, -0.066...  \n",
       "146  [0.0067699635, 0.0032178797, -0.025996458, -0....  \n",
       "156  [-0.02468868, -0.015727378, -0.026512522, -0.0...  \n",
       "107  [0.00029141922, -0.038468916, 0.029741589, -0....  \n",
       "152  [-0.0022556814, -0.012241578, 0.0050421893, -0...  \n",
       "21   [0.004565768, -0.010073113, -0.013294056, -0.0...  \n",
       "128  [0.008659948, -0.0070254644, -0.0111895, -0.04...  \n",
       "216  [-0.010979394, 0.0126972, -0.029265268, -0.051...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_new #We can see the new column with the embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save them to pickle files\n",
    "train_df_new.to_pickle(\"./data/train_df_sample_embeddings.pkl\") \n",
    "test_df_new.to_pickle(\"./data/test_df_sample_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# load the pickle files\n",
    "train_df_new = pd.read_pickle(\"./data/train_df_sample_embeddings.pkl\")\n",
    "test_df_new = pd.read_pickle(\"./data/test_df_sample_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df_new.iloc[0][\"embeddings_values\"]) # Gemini embedding dimension is 3072 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kuojouhsiang/Documents/DM2025-Lab2-Exercise/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/kuojouhsiang/Documents/DM2025-Lab2-Exercise/.venv/lib/python3.11/site-packages/umap/umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "@kitanoye Hell is hot and boiling, isi ewu",
           0.458
          ],
          [
           "@JuliaHB1 Bloody right #fume",
           0.5
          ],
          [
           "@RealJeffsdomain Wolfpack theme and trons and sting wore the wolf shirt",
           0.312
          ],
          [
           "Not giving a fuck is better than revenge.",
           0.625
          ],
          [
           "testing ",
           0.25
          ],
          [
           "@carefreeash_ id be fuming",
           0.583
          ],
          [
           "@RichardHBell Yes, I think he held a grudge ...",
           0.375
          ],
          [
           "Heading home to cut grass in the heat. All I wanna do is go out to eat somewhere air conditioned.  #AdultingIsTheWorst",
           0.354
          ],
          [
           "British humour should offend and challenge mainstream views. Hat off to Clarkeson. The ultra left should go and kneel before Allah!!",
           0.479
          ],
          [
           "@DeltaDomain @SawDraze @qurions dis dat nigga from fume right?",
           0.417
          ],
          [
           "@fireemblemlord it's the first expac since wrath that feels like a proper 'evolution' of the game for me",
           0.542
          ],
          [
           "#welfarereform should not be a 'model' for .",
           0.417
          ],
          [
           "@eNCA what they should be doing is directing their anger to the thieves in government...#corruption #FeesMustFall",
           0.542
          ],
          [
           "The majority of people irritate the fuck out of me, cba with people ahahah",
           0.862
          ],
          [
           "@oreillyfactor why dont #blm #thugs want #justice when its black on black #gang crime? They only #rage and cry #racism when its a #cop",
           0.646
          ],
          [
           "@l1ght__eyes u tried boiling em takes years too",
           0.354
          ],
          [
           "@LynneGarrison yeah, I've only seen that floated online as a theory, it was probably made up by a bitter stan. I ignore pets v vets crap too",
           0.562
          ],
          [
           "Worst juror ever? Michelle. You were Nicole's biggest threat. #bitter #bb18",
           0.729
          ],
          [
           "@CBSBigBrother never bring back Meech and Bridgette. Crying because someone looks at you? Ugh, and Bridgette. ",
           0.479
          ],
          [
           "Holding a grudge on someone will stop your blessings from God ,learn to forgive &amp; forget ",
           0.375
          ],
          [
           "@DFSCare apparently you are to contact me. Sofas were meant to be delivered today. Old ones gone. Sitting on floor. No sofas! ",
           0.583
          ],
          [
           "@DPD_UK I asked for my parcel to be delivered to a pick up store not my address #fuming #poorcustomerservice",
           0.896
          ],
          [
           "Y'all really insult coz of soccer???  Lmao, wow!!!!!!",
           0.396
          ],
          [
           "@RegalisAzura \\ngrasp the cobalt woman's own; which they did fairly easily. Fair cheeks would ignite into a fiery hue. Warm.. was the only",
           0.438
          ],
          [
           "@JustinRow10 dude the new madden 17? Haha",
           0.231
          ],
          [
           "If my luck the rest of Fall goes anything like today, I think I'm going to like this season. #bestdayever #magic #work ",
           0.375
          ],
          [
           "You can't fight the elephants until you have wrestled the pigs. #quoteoftheday #relentless",
           0.271
          ],
          [
           "@len_snart gives a frustrated growl, before stepping closer and putting his gun through the barrier. No alarms and nothing happened. He-",
           0.458
          ],
          [
           "Sometimes the best motivations come from 'proving them wrong' #energy  #MotivationalQuotes",
           0.25
          ],
          [
           "and apparently he's supposed to have a Scottish accent??? I'm ",
           0.375
          ],
          [
           "Puzzle investing opening portland feodal population is correlative straight a snorting infuriate: XLzjYhG",
           0.458
          ],
          [
           "doing some testing with my current earth burst team",
           0.375
          ],
          [
           "Now that @Jasmine_Wrn has snapchat back it's a constant battle to see who can get the ugliest snap of one another  #snap survival",
           0.458
          ],
          [
           "Inpouring this letter we are dying over against subsist checking quaint virtuoso ways toward fine huff yours l...",
           0.562
          ],
          [
           "Why does @dapperlaughs have to come to Glasgow on a night I am working. I am fucking gutted, been waiting for an appearance for ages ",
           0.733
          ],
          [
           "I really really resent having to go to bed at a sensible hour, you guys. I WANT TO TALK TO MY PEOPLE.",
           0.542
          ],
          [
           "I get embarrassed at the slightest things and then I'll fret about it all day I hate it",
           0.438
          ],
          [
           "All hell is breaking loose in Charlotte. #CharlotteProtest  #looting",
           0.625
          ],
          [
           "Everybody talking about 'the first day of fall' but summer '16 is never gonna die #revenge @Drake",
           0.417
          ],
          [
           "@TrevorHMoore @paget_old In Scotland, the right-wingers are the most rabid anti-nationalists. Socialists are mostly in favour.",
           0.604
          ],
          [
           "Lol little things like that make me so angry x",
           0.604
          ],
          [
           "Anger, resentment, and hatred are the destroyer of your fortune today.'",
           0.375
          ],
          [
           "Hate when guys cant control their anger ",
           0.646
          ],
          [
           "Me being on my dean really saving a lot of ppl, bc I don't snap nomore &amp; it take so much out of me..",
           0.348
          ],
          [
           "@RevTrevK @Wolfman93011 @Daraidernation @EROCKhd Take 2k out of it the numbers on madden are low and have dropped and people are unhappy",
           0.586
          ],
          [
           "It's the most magical time of the year......Xmas party announced and the #outrage commences. Gotta love Silicon Valley millennials.",
           0.429
          ],
          [
           "Just joined #pottermore and was sorted into HUFFLEPUFF  ",
           0.438
          ],
          [
           "Literally fuming fuck sake",
           0.86
          ]
         ],
         "hovertemplate": "emotion=anger<br>UMAP1=%{x}<br>UMAP2=%{y}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "anger",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "anger",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "hD6EQK97NEBrU2hAaO5AQOqfPkA7KhdAb3AYQARYjUCYVnFAnQZGQL/rY0CM/KNAJEUiQGBAP0DfQ4JATk1JQKfxI0AOu3dA5/1yQKx+RUClZOk/mcn+PzRkX0BKix9AWxBMQG1/rkA9rG9Ait8GQHpdmECPnBJAyOQeQJ8fREBI/2pAxDgpQIoTI0BCCJhAL1G9QCj6mEAVvWJAaeQLQFVtJECPKEJAVmMwQJ6AdkD/D1JA2XfAQFt9E0AONS1A",
          "dtype": "f4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "3l0ZPzPRQj+u6NM/fGiFP9uwQkD2BHw/Aiz2Py9QuD/HzPy8kKonP0T0T0DdYAe9Mb/tPnS9kT+Ctnm+UQMYQI0W7j/lPTO/no8dv3KV9j+SwQw/+xQlP+FoCz4M0DRAMsvYvo/VVED2LQ5Ao+oKQEeIIUD5Ibo/iONfQMGKSEAC6GY/hxNbQJLeXD8Xy7o/GnvgP/tcJj+WHiU/W8fcP77Ekz/LzuI/UU2sP/JkK0Cy6hy+ughUPwYlHT/cCmE/",
          "dtype": "f4"
         },
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "Haven't gotten one hour of sleep... Today is going to be a fun day  #restless",
           0.75
          ],
          [
           "@madihayousufzai Please DM your concern",
           0.271
          ],
          [
           "Obama admin rejects Texas plan to have refugees vetted for terrorism so Texas pulls of of fed refugee resettlement program. Aiding #terror.",
           0.475
          ],
          [
           "@RogueCoder250 We are in so much trouble!! I don't think the Rev will see the funny side of our project. ",
           0.616
          ],
          [
           "@ExpressScripts u shd b embrrssd. u jack up my bp meds twice and it will still take 3-5 days? Not express at all. #expressscripts ",
           0.542
          ],
          [
           "onus is on Pakistan' : @MEAIndia after #Uri #terror attack",
           0.583
          ],
          [
           "Start the convo...don't shy away..mental illness abounds in society including our workplace...be informed... #tsdoffsite",
           0.479
          ],
          [
           "Hennessey - dreadful. Mutch - is he even on the pitch? Fryers - out of his depth unfortunately. #CPFC",
           0.417
          ],
          [
           "Now #India is #afraid of #bad .",
           0.562
          ],
          [
           "@RogueCoder250 We are in so much trouble!! I don't think the Rev will see the funny side of our project. #nervous",
           0.896
          ],
          [
           "Howl at the moon with @HorrorSociety at @FatCatChicago next Wednesday the 28th for a FREE double feature of SILVER BULLET and CURSED ",
           0.333
          ],
          [
           "I Don't know what make #Pakistan fear more their #terrorist or their  #TerrorStatePak",
           0.562
          ],
          [
           "Study finds #awe &amp; #wonder of something greater than self, leads to #creative boosts of expansive thinking. @outsideonline #write #thoreau",
           0.146
          ],
          [
           "My interview went well today, I can't wait to find out what happens. #nervous #excited #interview #jobinterview",
           0.688
          ],
          [
           "@NinjaWorrier @ali_zimmer @m_pattison How long ago was that? (I shudder to think.)",
           0.625
          ],
          [
           "@falklands_utd @mauriciomacri \\nbecause distrust in life , Argentina has a lot of heart and this President is worth every vote.",
           0.312
          ],
          [
           "Ever been really lonely and your phone keeps blowing up, but you just cant pick it up and respond to people? #anxiety #recluse  #issues",
           0.893
          ],
          [
           "@Taniel @LOLGOP That'll be gosh darn terrific if they only check the brown people. Shucks, let's make a law to say only brown people.",
           0.458
          ],
          [
           "Watched tna for the first time in a long time what the hell happened to the #hardyboys #impactonpop #wwe ",
           0.292
          ],
          [
           "@realDonaldTrump @KellyannePolls New campaign slogan idea...'I know you are but what am I?' #bully #Trump2016 #yourefired #deflect",
           0.521
          ],
          [
           "STAY JADED everyone is ",
           0.3
          ],
          [
           "#hillaryclinton and their followers are #nervous of a #BernieSanders #millennials saying yes to a #woman #POTUS  #JillStein  not #warmonger",
           0.521
          ],
          [
           "I delete numbers so quick with no hesitation",
           0.288
          ],
          [
           "jimmy_dore: RaisingTheBoss we've already lost our country and our government to oligarchs, but their fear tactics still work it appears.",
           0.646
          ],
          [
           "If Monday had a face I would punch it #monday #horrible #face #punch #fight #joke #like #firstworldproblems #need #coffee #asap #follow",
           0.5
          ],
          [
           "^^^^^\\n//Don't worry if your character is already taken. The RP I'm looking for is a non couple forming RP. Just a fun loving haunting.//\\n^^^",
           0.188
          ],
          [
           "I seem to alternate between 'sleep-full' and sleepless nights. Tonight is a sleepless one.  #insomnia #anxiety #notfair",
           0.792
          ],
          [
           "@NandosSA just received order from @OrderInSA &amp; the chips are under cooked &amp; half raw!!! Usually best part of the meal #notcool #terrible",
           0.373
          ],
          [
           "Confiaejce comes not from always being right but from not fearing to be wrong.-Peter T. Mcintyre",
           0.333
          ],
          [
           "@Max_Kellerman  it also helps that the majority of NFL coaching is inept. Some of Bill O'Brien's play calling was wow, #awful! #GOPATS",
           0.438
          ],
          [
           "I really wanna go fright night at Thorpe Park next month ",
           0.229
          ],
          [
           "While we focus on issue of #IPCA @IHFOKids Indulges in #intimidation @BringRoshniHome @ChildrensIssues @MEAIndia @MinistryWCD #StopCruelty",
           0.562
          ],
          [
           "can only blame Jose ere why would you give Rojo another start after Sunday , fucking disaster waiting to happen &amp; it did shocking header !",
           0.583
          ],
          [
           "@officialShaky 'Operation Echoes' is gathering momentum ... #tense #nervous #feelsick #excited",
           0.875
          ],
          [
           "Ronaldo has been shocking. He's tried to do skill twice and he's nearly fallen over both times",
           0.5
          ],
          [
           "The Zika #Hoax Files: DEET is part of a binary chemical weapon targeting your brain: #Toxin #fear #neurological #USCitizens #Insect #mammal",
           0.667
          ],
          [
           "Did you know I specialise in #anxiety  and #panic attacks? Get in touch for all of my solutions for you. #Coventry",
           0.396
          ],
          [
           "@Joey7Barton I remember Joey slagging England player's off bringing out books after crap tournaments..same same..crap player #bully",
           0.461
          ],
          [
           "This is the first time I've written anything on this series in over two years, so I'm checking back in for one last nightmare.",
           0.688
          ],
          [
           "Just heard what happen at grandad hometown last night such a terrible news , hope everyone okay ",
           0.729
          ],
          [
           "Focusing primarily on the person youre talking to rather than yourself and the impression youre making lessens social anxiety.",
           0.458
          ],
          [
           "Let's not panic. Beat NYG who's atop the division, come home against Cleveland. Just like that you're 2-2 with a division win",
           0.417
          ],
          [
           "Can we start a 'get Chris Sutton off our tv campaign? Spread the work #terrible #pundit #noclue",
           0.433
          ],
          [
           "Forgot to plug the phone in overnight ",
           0.396
          ],
          [
           "@nigglydz lydiaaaa, we were the only ones that were supposed to know that you make me nervous ",
           0.75
          ],
          [
           "How had Matty Dawson not scored there!!!!! #terrible",
           0.375
          ],
          [
           "Everywhere I go, the air I breathe in tastes like home.' - @The_Currys ",
           0.229
          ],
          [
           "We're very busy #coding a whole network manager for #unity3d based on #steamworks networking. #gamedev #indiedev #3amDeadTime  #game",
           0.354
          ],
          [
           "The #500thTest match would have be a T20 or an ODI if @virendersehwag @B_McCullum42 been in their National Colors #nightmare #hitter  @BCCI",
           0.438
          ],
          [
           "Got to be up in 4 hours to go back to work #cantsleep #excited #nervous",
           0.7
          ],
          [
           "However the agent was inauthentic, my sister still loves me, &amp; I'm still alive. So I guess it wasn't that bad. #socialanxiety #anxiety",
           0.604
          ],
          [
           "Staff on @ryainair FR1005. Asked for info and told to look online. You get what you pay for. #Ryanair @STN_Airport #Compensation ",
           0.312
          ],
          [
           "And I cried in front of my guy last night. And it's just been a horrible week but it's only for a week",
           0.68
          ],
          [
           "@soozclifford Sure have... Sydney are too tough, too quick and their 'team' pressure is too much for the Cats to handle. Motlop/Cowan ",
           0.356
          ],
          [
           "@RyanAbe awe yay thank god I was so worried.",
           0.5
          ],
          [
           "@joey_coops yes Hun! Avoid at all costs!! #nightmare",
           0.667
          ],
          [
           "There goes the butterflies in my stomach.  #anxietyproblems",
           0.702
          ],
          [
           "About 7 weeks till I can pick up my camera again. Though I think there is a group cemetery shoot in october I can make! #photography #horror",
           0.396
          ],
          [
           "@CNNPolitics I can't wait to hear what he had to say about the brilliant Dr. Hawking... it should be rich... In the poorest of taste! #bully",
           0.354
          ],
          [
           "That's an awful miss from Rooney.",
           0.36
          ],
          [
           "About 7 weeks till I can pick up my camera again. Though I think there is a group cemetery shoot in october I can make! #photography ",
           0.312
          ],
          [
           "The Apocalypse has hit our gym and it's  nothing what I thought it would be...\\n\\nEveryone is wearing vests! What if it's contagious? ",
           0.583
          ],
          [
           "When you're scared to press send #bgoodthepoet #PrayForMe #ThisIsAGodDream #career #help #fear #heart #HeartRacing",
           0.842
          ],
          [
           "They'll be yo friend, shake your hand, then kick in yo door thas the way the game go.",
           0.417
          ]
         ],
         "hovertemplate": "emotion=fear<br>UMAP1=%{x}<br>UMAP2=%{y}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "fear",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "fear",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "fgutQMKysEA8x7tAT923QMPR+D8jHLpA0zHPQLg9E0BLusFAOWrHQOqTs0Dh5sJAae+zQLjex0CWMbxA/tYlQKG81UBie4FAa+I5QLCylEDr0m9AhsnKQCZ6PEAN98NA7yZoQNNFOEDfpMNA+xIFQAJLn0BWBi5ArMm2QIgEvUDfACFAvN/NQA2tEkA5WcdAV2vVQFGfLUA28q9AXPqjQMS70UD/G4dAFYwlQCgdo0DJQ8RAWZwmQKDPgED9sspAj1rAQFPAx0A/C81Ay9PmP2Xyj0BLtRdAvL3LQNFEqUC5XNNArLS2QL2CkECJKxpANbqvQAmmr0D6w9JAHa5uQA==",
          "dtype": "f4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "p/bLP0Nys71IFSs+7hB7PyVRGD9asrK+uPTFP7L8977XMUS+PR1rP98PAkB7YxS+2fNKQL/1GEA7C4A/DGMNQMm17z8nqQ49to+APRJd4r1kEwNATYkjP7Agwz+k+so+b6iSP4gAUEAEHek/w1SVPhztIEARikK/7bX+P1INar6WMIK+Me2JP4lG7r7kjZ8+1nfoP09AkL6Mnzg/Sp+kP3oYB0APnzY/1qAMv74L0D9Kj40/T9pGvyRD/j8XNn0/BGxHvoGB0D85PxJAoUrrPt08lz9cDDe/Q/UiQF9JBj9zm+Q/sSsJQKLAS74soRS/j3IUQHJGbz+DX4Q/DZIUQA==",
          "dtype": "f4"
         },
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "@sidviyer uff!! Look at your Arsenal fans cheering for every goal against United. haha",
           0.667
          ],
          [
           "Trying to loveee somebody, just wanna love somebody right now, guess there's just no pleasing me",
           0.354
          ],
          [
           "@OrbsOfJoy plan a date... like a date u find pleasing or smth. fuckign\\n\\n10/10. because the child will grow to be a ten out of ten",
           0.311
          ],
          [
           "don't put famous dex in a tweet with breezy lol chris is that guy dex a bitch lmao n music ass",
           0.354
          ],
          [
           "Aw there's a young fox outside on the grass just jumping around all playful and having a little stretch  soo cute ",
           0.75
          ],
          [
           "Miami proficiency is like pleasing by what name miami beaches: pIkxb",
           0.34
          ],
          [
           "@88Palouseriver @ABC @NRA I rejoice everything time some moron is taken out of the genetics pool.",
           0.417
          ],
          [
           "I think what 2016 to really needs to round it out is a @cthulhu4america vs @smod2016 twitter debate. End on something joyful, ya know?.",
           0.42
          ],
          [
           "myself that despite the absolute delight my children and I would feel having a kitten in our home, the misery my husband would feel is more.",
           0.327
          ],
          [
           "@PeanutRD @MelissaJoyRD @SarahKoszykRD @eat4performance @rustnutrition @jenhaugen  hey #sparkling is the word I just picked 4 my biz card",
           0.417
          ],
          [
           "Watch this amazing live.ly broadcast by @thebrandonrobert  #musically",
           0.48
          ],
          [
           "cluck cluck cluck, wolf wolf wolf , chirp chirp chirp is all I ever hear.",
           0.292
          ],
          [
           "Thank you @twitter for the balloons today.  #goodday #48",
           0.562
          ],
          [
           "Watch this amazing live.ly broadcast by @brooke_bridges #lively #musically",
           0.5
          ],
          [
           "Watch this amazing live.ly broadcast by @matt.boss #lively #musicallyjh",
           0.479
          ],
          [
           "@DanLanthier That was exhilarating hockey. They're still out if Russia wins in regulation I'm reading. #fuck",
           0.396
          ],
          [
           "@__Dayo yall dont feel bad.. you are rejoicing... it is what itnis... its always #ColtsNation even when we have 6th string DBs playing ",
           0.18
          ],
          [
           "Stack up with porthole under way heyday through worthy of faith bull's-eye transportation services: moM",
           0.32
          ],
          [
           "Wishing a very Happy Birthday to our awesome dancer, Ruthann!!! We hope your day is magical! #bday #happy #eatcake",
           0.75
          ],
          [
           "Watch this amazing live.ly broadcast by @iamjustinburke  #musically",
           0.542
          ],
          [
           "@mediacrooks @thenewshour @LodhiMaleeha @ndtv @IndiaToday This is hilarious ! Not a Freudian slip, eh !",
           0.667
          ],
          [
           "#BridgetJonesBaby is the best thing I've seen in ages! So funny, I've missed Bridget! #love  #TeamMark",
           0.922
          ],
          [
           "It has been medically proven that laughter is an effective pain killer.",
           0.48
          ],
          [
           "@musicfae15 [He grumbled as he sat atop the sushi bar stool, crossing his arms defiantly, in a playful gesture, though he gave anyone who &gt;",
           0.271
          ],
          [
           "@smoothkobra after such a heavy 2 days this has given much needed levity. Thanks bro",
           0.438
          ],
          [
           "Riggs dumb ass hell lolol  #LethalWeapon",
           0.396
          ],
          [
           "I truly believe in my heart right now that Satan is rejoicing because we are all against one another",
           0.204
          ],
          [
           "Of cheerfulness, or a good temper - the more it is spent, the more of it remains.",
           0.56
          ],
          [
           "I love when my dog is playful, but he really just scratched my face while flailing his paws in excitement and almost tore my nose ring out",
           0.333
          ],
          [
           "tfw you're en-route to your future :) !! @HUCJIR i'm coming for ya! #openhouse #futurecantor #exhilarating #NYCletsgo",
           0.657
          ],
          [
           "@UKLittleKitchen Defo a hearty root veg gratin. Nice comfort food as Autumn kicks in",
           0.48
          ],
          [
           "I am so happy I have come across @HilltopBindery notebooks! #handmade would love to talk to you! #musthave #want #need #happy #amazing ",
           0.812
          ],
          [
           "Why have I only just started watching glee this week I am now addicted  #glee #GLEEK",
           0.625
          ],
          [
           "Well look at the bright side. You found a use for that rope #TipsToSurviveAPowerOutage",
           0.312
          ],
          [
           "Yeah PAUL  #glorious #BB18",
           0.917
          ],
          [
           "Method into thin out assault corridor thine liveliness: cHd",
           0.32
          ],
          [
           "Tutoring gives me such an exhilarating feeling. I love helping people ",
           0.896
          ],
          [
           "@theclobra lol I thought maybe, couldn't decide if there was levity or not",
           0.312
          ],
          [
           "i was so embarrassed when she saw us i was like knvfkkjg she thinks we're stalkers n then she starts waving all cheerfully inviting us in ",
           0.25
          ],
          [
           "A #new day to #live and #smile. Hope all the #followers a nice #night or #day. :D",
           0.688
          ],
          [
           "I love my family so much #lucky #grateful #smartassfamily #hilarious #love",
           0.792
          ],
          [
           "I turn 25 in two weeks. I am so happy. 24 was my darkest year yet. I am elated that I survived",
           0.708
          ],
          [
           "@chencouture LMAO Is it that 'so slutty' hater girl? That video was hilarious. ",
           0.7
          ],
          [
           "@NateBLoL no it was that clear American naturally flavored sparkling water",
           0.312
          ],
          [
           "A cheerful heart is good medicine, but a broken spirit saps a person's strength.' {Proverbs 17:22} #WednesdayWisdom",
           0.292
          ]
         ],
         "hovertemplate": "emotion=joy<br>UMAP1=%{x}<br>UMAP2=%{y}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "joy",
         "marker": {
          "color": "#00cc96",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "joy",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "43FeQCrkjkCl4lNAmIJVQBn+oUDGJhRAK4Z/QItikkCb1IZAjoevQBJSeEDE1nJAL9evQG42f0Aml3VAJH86QMhRjUCg+SBAQte1QGgpdED3BLFAiWmqQDdqg0DJ2AZAZ0ZyQPmGckBRA5pAlMqHQIqIl0AG8cFAhj6RQLONtUA5qaVA4WeYQM8Og0CGSyFA2hC5QMFARUC38rhAZh2hQERupkCgW7tAXsMmQHlHWEDa541A",
          "dtype": "f4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "q29UvjU8BkDqPlU/rN24PnwePUB5SW5AYDHqvaqYPj4ray9A6XlrQHator+Sw/E/1yZjQApTmb84Kae/cUmsPktBLT+93GFACQpmQEUBq7/aOaK+ghpaQBleV0DBoBBAiaFJQN02gj5l7mI/H9ZWQEhcJkDLf0NAtQw0QEnPWkBPf2JADTUWQI/CSb+JHmBAy0xSQLkjMkAG568/ekloQOf/T0Ao+FFAv5u+PwuZOEDlAFhA",
          "dtype": "f4"
         },
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "Back to forest drama -\\nfrom my #Forest #music - series, 2016\\n#nature #dark #art #photography #Finland",
           0.271
          ],
          [
           "But When it come to a serious situation, I be glad I gave it deep thought ",
           0.375
          ],
          [
           "I'm slugging vitamin D pills by the handful, like they were m&amp;ms. When will this eternal winter end?! #Melbourne #grim #overit",
           0.675
          ],
          [
           "[My teeth were sunk down into the vein of the poor woman who had 'accidentally' had a small problem with her engine, just outside of --",
           0.479
          ],
          [
           "@gagasklaine it's old sadly",
           0.667
          ],
          [
           "the rappers who stayed true to the game is rich.",
           0.208
          ],
          [
           "so lost i'm faded",
           0.729
          ],
          [
           "So depressing that it's darker so much earlier now",
           0.75
          ],
          [
           "there are #serious #chinks in #Indias #armour'\\n#protein\\n#malnutrition\\n#feedingIndia\\n#skillingIndia\\n#cognitive #deficit\\n@Abhijit_Iyer",
           0.354
          ],
          [
           "Do not be discouraged by a slowing sales market. This will test your business model and pinpoint #strengths and #weaknesses.' @Ken_Dunn",
           0.271
          ],
          [
           "@janhopis I found the first few episodes of Bojack incredibly funny. Then it got less funny but I stayed for the #drama",
           0.354
          ],
          [
           "@Jacqueline_69 haha! She did well today. I can't get beyond her pout annoying me I'm afraid.",
           0.562
          ],
          [
           "How brave are the young individuals that have opened up to us about their #depression and #anxiety to help raise awareness!! @beyondblue",
           0.479
          ],
          [
           "@everton_de_leon @sterushton Genuinely grim stuff. Over a century of history sold off by some porn baron twats for a minty new stadium. Urgh",
           0.624
          ],
          [
           "@6itmap I can't help but feel melancholic!",
           0.75
          ],
          [
           "@patthemanager how could I work with @chancetherapper . ? #serious",
           0.354
          ],
          [
           "It's sad when your man leaves work a little bit late and your worst fear is 'Oh no!! Did he get stopped by the police?!?! ' #sad #ourworld",
           0.688
          ],
          [
           "Having holiday blues! #WantToGoBackToMinehead.",
           0.661
          ],
          [
           "Tell me how I'm supposed to feel. #broken #hateful #guilty #love #sadness",
           0.729
          ],
          [
           "@ArcadianLuthier -- taking out his feelings on Kei unfairly. His lips form a frown as he tries to walk away.",
           0.521
          ],
          [
           "@alisontis otherwise you're committing a crime against your soul only sober ppl know what is good or bad for themselves",
           0.438
          ],
          [
           "What's good is that we already hit rock bottom, even though I'm about two more seasons away from new depths of despair. #playoffs? #NJDevils",
           0.542
          ],
          [
           "Fucking gutted, disheartened &amp; so pissed off.Gone from 1 off the toughest most resolute defences to the worst &amp; most shambolic #SCFC #STOHUL",
           0.729
          ],
          [
           "Beats is accurately all-powerful with respect to high-quality high-frequency speaker in re the extra desolate relating to fire-ea:",
           0.271
          ],
          [
           "I wanna see you smile I don't wanna see you make a frown",
           0.333
          ],
          [
           "Interview preparation, I hate talking about myself, one dull subject matter! #yawnoff",
           0.396
          ],
          [
           "@Hayles_101 The three R's depress me.",
           0.792
          ],
          [
           "Having a nail half hanging off is absolutely fucking grim, even with my acrylic holding it on ",
           0.604
          ],
          [
           "The word happiness would lose its meaning if it were not balanced by sadness.",
           0.479
          ],
          [
           "went to Pet Supplies Plus tonight but @neitzkeamara was not working I feel #lost and #confused",
           0.458
          ],
          [
           "@kikibug13 Don't look. You'll only be very, very unhappy. \\n\\n(NNGH. I got the email notif THANK YOU.)",
           0.438
          ],
          [
           "All the 'juniors' are now wearing purple at ollafest while I'm here fighting with my alarm about when I need to wake up for German #sadness",
           0.646
          ],
          [
           "It's a gloomy ass day",
           0.888
          ],
          [
           "ya boy gets mad tired of pine trees",
           0.292
          ],
          [
           "Mmmm #coffee and a good #book on a dreary day! Who can beat that?",
           0.25
          ],
          [
           "Chalk dance notation entree manchester inasmuch as corinthian products that discourage drag branding: ARwuEVfqv",
           0.188
          ],
          [
           "Common app just randomly logged me out as I was writing the last part of my college essay and lost all of it ",
           0.833
          ],
          [
           "I can't WAIT to go to work tomorrow with a high as fuck fever. [sarcasm]\\nHopefully I'll feel better tomorrow.\\nBut I doubt it. #pessimism",
           0.646
          ],
          [
           "On bedrest since I got out of the hospital. U find in unopened beer.. what do I do. Pour that shit out! No alcohol at all for me #sober",
           0.44
          ],
          [
           "It's basically a dead skin peel which sounds grim. But it literally gets rid of so much dead skin from your pores.",
           0.354
          ],
          [
           "@kayleighmcenany  @DonaldJTrumpJr Is that really all you can offer for those who sacrifice daily to keep you safe...? @kayleighmcenany #sad",
           0.625
          ],
          [
           "Buddha doesn't possess enough power to deliver you from your affliction!",
           0.542
          ],
          [
           "Should of stayed in Dubai ",
           0.708
          ]
         ],
         "hovertemplate": "emotion=sadness<br>UMAP1=%{x}<br>UMAP2=%{y}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "sadness",
         "marker": {
          "color": "#ab63fa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "sadness",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "YeStQD2ogUAKiHlAnsAjQIcbOUAzEGlAhriHQMtXkkB4a79AXiKQQFTybUAZKi9A817YQPGgF0DVg5BAVNhMQO7WoEBNm5BA2mySQEsGCEDFkWFAAp2HQNqmFEAsaRFAZHGQQNwPxkDeK4VADSRcQCy3hkDCjZxAICKnQP4YoEBoOX9ARwJjQAxEnUAB1BJALHCpQGrXgEDaEkpAqTtJQGUnl0AF70tAn8CUQA==",
          "dtype": "f4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "LOgMQJZHKEBaR5E/KTQzQHnZH0AMqhVAqon7P6OcsD8TOv+9AEQrQE/+RkCe6hRA1vzgP4t4D74Ah80/+5N5vr13kT8AQ+E/WcfQPysnDEAORM4/PEuMP1fFJz3qE3JAqt1dQJ+KB0ADhso/vcaEP3xAS0AMgu8/UZA0P8U+zz/Po6Q/UaUMQBjQNUDwW25As3WoP5gJhj+hk6A/eVbtPzngDz2Sy80/cDHUPw==",
          "dtype": "f4"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "emotion"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "2D UMAP Projection of Text Embeddings"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "UMAP1"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "UMAP2"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import umap\n",
    "import plotly.express as px\n",
    "\n",
    "# Concatenate the training and test data\n",
    "combined_df = pd.concat([train_df_new, test_df_new], ignore_index=True)\n",
    "\n",
    "# Prepare the embeddings for UMAP\n",
    "# Convert the list of embeddings into a 2D numpy array\n",
    "X_embeddings = np.array(combined_df['embeddings_values'].tolist())\n",
    "\n",
    "# Apply UMAP for dimensionality reduction\n",
    "reducer = umap.UMAP(n_components=2, metric='cosine', random_state=28) \n",
    "embedding_2d = reducer.fit_transform(X_embeddings)\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "df_plot = pd.DataFrame(embedding_2d, columns=['UMAP1', 'UMAP2'])\n",
    "df_plot['emotion'] = combined_df['emotion']\n",
    "df_plot['intensity'] = combined_df['intensity']\n",
    "df_plot['text'] = combined_df['text']\n",
    "\n",
    "\n",
    "# Visualize the embeddings with Plotly\n",
    "fig = px.scatter(\n",
    "    df_plot,\n",
    "    x='UMAP1',\n",
    "    y='UMAP2',\n",
    "    color='emotion',  # Color points by the 'emotion' column\n",
    "    hover_data=['text', 'intensity'],  # Show text and intensity on hover\n",
    "    title='2D UMAP Projection of Text Embeddings'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that even with Gemini's embeddings there doesn't seem to be a clear 2D separation of clusters with our data classes. It could be because emotions are often not discrete. Texts can contain mixed feelings (e.g., \"bittersweet\") or use similar language to express different emotions, causing their embeddings to be naturally close in semantic space. And also the process of projecting high-dimensional embeddings down to a 2D visualization inevitably loses some information, which can make distinct clusters appear to overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_8_1_1_'></a>[**>>> Exercise 4 (Take home):**](#toc0_)\n",
    "\n",
    "Apply UMAP to the same embeddings to reduce the dimensionality to 3D vectors and plot the 3D graph, discuss the differences and similarities with the 2D graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kuojouhsiang/Documents/DM2025-Lab2-Exercise/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:132: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/kuojouhsiang/Documents/DM2025-Lab2-Exercise/.venv/lib/python3.11/site-packages/umap/umap_.py:1945: UserWarning:\n",
      "\n",
      "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "@kitanoye Hell is hot and boiling, isi ewu",
           0.458
          ],
          [
           "@JuliaHB1 Bloody right #fume",
           0.5
          ],
          [
           "@RealJeffsdomain Wolfpack theme and trons and sting wore the wolf shirt",
           0.312
          ],
          [
           "Not giving a fuck is better than revenge.",
           0.625
          ],
          [
           "testing ",
           0.25
          ],
          [
           "@carefreeash_ id be fuming",
           0.583
          ],
          [
           "@RichardHBell Yes, I think he held a grudge ...",
           0.375
          ],
          [
           "Heading home to cut grass in the heat. All I wanna do is go out to eat somewhere air conditioned.  #AdultingIsTheWorst",
           0.354
          ],
          [
           "British humour should offend and challenge mainstream views. Hat off to Clarkeson. The ultra left should go and kneel before Allah!!",
           0.479
          ],
          [
           "@DeltaDomain @SawDraze @qurions dis dat nigga from fume right?",
           0.417
          ],
          [
           "@fireemblemlord it's the first expac since wrath that feels like a proper 'evolution' of the game for me",
           0.542
          ],
          [
           "#welfarereform should not be a 'model' for .",
           0.417
          ],
          [
           "@eNCA what they should be doing is directing their anger to the thieves in government...#corruption #FeesMustFall",
           0.542
          ],
          [
           "The majority of people irritate the fuck out of me, cba with people ahahah",
           0.862
          ],
          [
           "@oreillyfactor why dont #blm #thugs want #justice when its black on black #gang crime? They only #rage and cry #racism when its a #cop",
           0.646
          ],
          [
           "@l1ght__eyes u tried boiling em takes years too",
           0.354
          ],
          [
           "@LynneGarrison yeah, I've only seen that floated online as a theory, it was probably made up by a bitter stan. I ignore pets v vets crap too",
           0.562
          ],
          [
           "Worst juror ever? Michelle. You were Nicole's biggest threat. #bitter #bb18",
           0.729
          ],
          [
           "@CBSBigBrother never bring back Meech and Bridgette. Crying because someone looks at you? Ugh, and Bridgette. ",
           0.479
          ],
          [
           "Holding a grudge on someone will stop your blessings from God ,learn to forgive &amp; forget ",
           0.375
          ],
          [
           "@DFSCare apparently you are to contact me. Sofas were meant to be delivered today. Old ones gone. Sitting on floor. No sofas! ",
           0.583
          ],
          [
           "@DPD_UK I asked for my parcel to be delivered to a pick up store not my address #fuming #poorcustomerservice",
           0.896
          ],
          [
           "Y'all really insult coz of soccer???  Lmao, wow!!!!!!",
           0.396
          ],
          [
           "@RegalisAzura \\ngrasp the cobalt woman's own; which they did fairly easily. Fair cheeks would ignite into a fiery hue. Warm.. was the only",
           0.438
          ],
          [
           "@JustinRow10 dude the new madden 17? Haha",
           0.231
          ],
          [
           "If my luck the rest of Fall goes anything like today, I think I'm going to like this season. #bestdayever #magic #work ",
           0.375
          ],
          [
           "You can't fight the elephants until you have wrestled the pigs. #quoteoftheday #relentless",
           0.271
          ],
          [
           "@len_snart gives a frustrated growl, before stepping closer and putting his gun through the barrier. No alarms and nothing happened. He-",
           0.458
          ],
          [
           "Sometimes the best motivations come from 'proving them wrong' #energy  #MotivationalQuotes",
           0.25
          ],
          [
           "and apparently he's supposed to have a Scottish accent??? I'm ",
           0.375
          ],
          [
           "Puzzle investing opening portland feodal population is correlative straight a snorting infuriate: XLzjYhG",
           0.458
          ],
          [
           "doing some testing with my current earth burst team",
           0.375
          ],
          [
           "Now that @Jasmine_Wrn has snapchat back it's a constant battle to see who can get the ugliest snap of one another  #snap survival",
           0.458
          ],
          [
           "Inpouring this letter we are dying over against subsist checking quaint virtuoso ways toward fine huff yours l...",
           0.562
          ],
          [
           "Why does @dapperlaughs have to come to Glasgow on a night I am working. I am fucking gutted, been waiting for an appearance for ages ",
           0.733
          ],
          [
           "I really really resent having to go to bed at a sensible hour, you guys. I WANT TO TALK TO MY PEOPLE.",
           0.542
          ],
          [
           "I get embarrassed at the slightest things and then I'll fret about it all day I hate it",
           0.438
          ],
          [
           "All hell is breaking loose in Charlotte. #CharlotteProtest  #looting",
           0.625
          ],
          [
           "Everybody talking about 'the first day of fall' but summer '16 is never gonna die #revenge @Drake",
           0.417
          ],
          [
           "@TrevorHMoore @paget_old In Scotland, the right-wingers are the most rabid anti-nationalists. Socialists are mostly in favour.",
           0.604
          ],
          [
           "Lol little things like that make me so angry x",
           0.604
          ],
          [
           "Anger, resentment, and hatred are the destroyer of your fortune today.'",
           0.375
          ],
          [
           "Hate when guys cant control their anger ",
           0.646
          ],
          [
           "Me being on my dean really saving a lot of ppl, bc I don't snap nomore &amp; it take so much out of me..",
           0.348
          ],
          [
           "@RevTrevK @Wolfman93011 @Daraidernation @EROCKhd Take 2k out of it the numbers on madden are low and have dropped and people are unhappy",
           0.586
          ],
          [
           "It's the most magical time of the year......Xmas party announced and the #outrage commences. Gotta love Silicon Valley millennials.",
           0.429
          ],
          [
           "Just joined #pottermore and was sorted into HUFFLEPUFF  ",
           0.438
          ],
          [
           "Literally fuming fuck sake",
           0.86
          ]
         ],
         "hovertemplate": "emotion=anger<br>UMAP1=%{x}<br>UMAP2=%{y}<br>UMAP3=%{z}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "anger",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "anger",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": {
          "bdata": "k9WvQDf8ykDjhqJAihm+QNbVlEAt+sZAQgK0QHcqmEA6ALBAiTjIQKEmikBl0KBAeMfPQISnvkBzSMhAQlWlQPuXrkC2171AOLO5QLShqUCkj9NAQunSQLK+skB1qKZA4HqnQDetPUA8T5pALP+5QKQtdkA7K7RAoD2iQCK+kEBJzplAxcucQBe6vECGlYJA4nRlQBxyqkDNhKxA77C8QCnIxkAYl69Ay0TAQIfEj0DxP59A2OpnQL1pwkCKmMhA",
          "dtype": "f4"
         },
         "y": {
          "bdata": "jHCoQCxTrkAt8LJAebqqQIYz00B/8bFAIYbLQDeuhkBnIMJAEW+6QGfXzECUWqhATqqqQCkarUCK4rFA7Fa0QFuTyEAbF61Ah3+rQCGpwUBvrYpA4nSPQM8HzECb5txAG5zBQOkDxUCbLrhAPL3UQGMNvkAEB5BANVXoQG6E0EC+Z9FAJN7iQPxSjEAtdolAMz+bQHfOnEDBT7hAioTEQFUjt0AqzblAaYO5QEy8vkDOErNA7NemQKjbh0DrlKpA",
          "dtype": "f4"
         },
         "z": {
          "bdata": "nj8lQZjIJkFbEStBCKMeQefsH0GA4CJBEBUjQak1H0EgjDtB+PEmQfJOKkF6bj9BXpsrQXZMHEGduTVBVZwiQSXYJkF5DThBvJk1QYpYGkGiXiZBWm8mQRYvNEE6Uh9BGyYxQToGKkFnRhZB4zsfQQ97H0FwZidBnfcQQSbqIkGQRC1BZhAVQdkEJkE3jB1B9iEnQRk9KkH7yCpBFdkoQR2jIEEv3hZB0ekbQTYvH0EJoC5Bx9Y3QT1dKkF+Tx9B",
          "dtype": "f4"
         }
        },
        {
         "customdata": [
          [
           "Haven't gotten one hour of sleep... Today is going to be a fun day  #restless",
           0.75
          ],
          [
           "@madihayousufzai Please DM your concern",
           0.271
          ],
          [
           "Obama admin rejects Texas plan to have refugees vetted for terrorism so Texas pulls of of fed refugee resettlement program. Aiding #terror.",
           0.475
          ],
          [
           "@RogueCoder250 We are in so much trouble!! I don't think the Rev will see the funny side of our project. ",
           0.616
          ],
          [
           "@ExpressScripts u shd b embrrssd. u jack up my bp meds twice and it will still take 3-5 days? Not express at all. #expressscripts ",
           0.542
          ],
          [
           "onus is on Pakistan' : @MEAIndia after #Uri #terror attack",
           0.583
          ],
          [
           "Start the convo...don't shy away..mental illness abounds in society including our workplace...be informed... #tsdoffsite",
           0.479
          ],
          [
           "Hennessey - dreadful. Mutch - is he even on the pitch? Fryers - out of his depth unfortunately. #CPFC",
           0.417
          ],
          [
           "Now #India is #afraid of #bad .",
           0.562
          ],
          [
           "@RogueCoder250 We are in so much trouble!! I don't think the Rev will see the funny side of our project. #nervous",
           0.896
          ],
          [
           "Howl at the moon with @HorrorSociety at @FatCatChicago next Wednesday the 28th for a FREE double feature of SILVER BULLET and CURSED ",
           0.333
          ],
          [
           "I Don't know what make #Pakistan fear more their #terrorist or their  #TerrorStatePak",
           0.562
          ],
          [
           "Study finds #awe &amp; #wonder of something greater than self, leads to #creative boosts of expansive thinking. @outsideonline #write #thoreau",
           0.146
          ],
          [
           "My interview went well today, I can't wait to find out what happens. #nervous #excited #interview #jobinterview",
           0.688
          ],
          [
           "@NinjaWorrier @ali_zimmer @m_pattison How long ago was that? (I shudder to think.)",
           0.625
          ],
          [
           "@falklands_utd @mauriciomacri \\nbecause distrust in life , Argentina has a lot of heart and this President is worth every vote.",
           0.312
          ],
          [
           "Ever been really lonely and your phone keeps blowing up, but you just cant pick it up and respond to people? #anxiety #recluse  #issues",
           0.893
          ],
          [
           "@Taniel @LOLGOP That'll be gosh darn terrific if they only check the brown people. Shucks, let's make a law to say only brown people.",
           0.458
          ],
          [
           "Watched tna for the first time in a long time what the hell happened to the #hardyboys #impactonpop #wwe ",
           0.292
          ],
          [
           "@realDonaldTrump @KellyannePolls New campaign slogan idea...'I know you are but what am I?' #bully #Trump2016 #yourefired #deflect",
           0.521
          ],
          [
           "STAY JADED everyone is ",
           0.3
          ],
          [
           "#hillaryclinton and their followers are #nervous of a #BernieSanders #millennials saying yes to a #woman #POTUS  #JillStein  not #warmonger",
           0.521
          ],
          [
           "I delete numbers so quick with no hesitation",
           0.288
          ],
          [
           "jimmy_dore: RaisingTheBoss we've already lost our country and our government to oligarchs, but their fear tactics still work it appears.",
           0.646
          ],
          [
           "If Monday had a face I would punch it #monday #horrible #face #punch #fight #joke #like #firstworldproblems #need #coffee #asap #follow",
           0.5
          ],
          [
           "^^^^^\\n//Don't worry if your character is already taken. The RP I'm looking for is a non couple forming RP. Just a fun loving haunting.//\\n^^^",
           0.188
          ],
          [
           "I seem to alternate between 'sleep-full' and sleepless nights. Tonight is a sleepless one.  #insomnia #anxiety #notfair",
           0.792
          ],
          [
           "@NandosSA just received order from @OrderInSA &amp; the chips are under cooked &amp; half raw!!! Usually best part of the meal #notcool #terrible",
           0.373
          ],
          [
           "Confiaejce comes not from always being right but from not fearing to be wrong.-Peter T. Mcintyre",
           0.333
          ],
          [
           "@Max_Kellerman  it also helps that the majority of NFL coaching is inept. Some of Bill O'Brien's play calling was wow, #awful! #GOPATS",
           0.438
          ],
          [
           "I really wanna go fright night at Thorpe Park next month ",
           0.229
          ],
          [
           "While we focus on issue of #IPCA @IHFOKids Indulges in #intimidation @BringRoshniHome @ChildrensIssues @MEAIndia @MinistryWCD #StopCruelty",
           0.562
          ],
          [
           "can only blame Jose ere why would you give Rojo another start after Sunday , fucking disaster waiting to happen &amp; it did shocking header !",
           0.583
          ],
          [
           "@officialShaky 'Operation Echoes' is gathering momentum ... #tense #nervous #feelsick #excited",
           0.875
          ],
          [
           "Ronaldo has been shocking. He's tried to do skill twice and he's nearly fallen over both times",
           0.5
          ],
          [
           "The Zika #Hoax Files: DEET is part of a binary chemical weapon targeting your brain: #Toxin #fear #neurological #USCitizens #Insect #mammal",
           0.667
          ],
          [
           "Did you know I specialise in #anxiety  and #panic attacks? Get in touch for all of my solutions for you. #Coventry",
           0.396
          ],
          [
           "@Joey7Barton I remember Joey slagging England player's off bringing out books after crap tournaments..same same..crap player #bully",
           0.461
          ],
          [
           "This is the first time I've written anything on this series in over two years, so I'm checking back in for one last nightmare.",
           0.688
          ],
          [
           "Just heard what happen at grandad hometown last night such a terrible news , hope everyone okay ",
           0.729
          ],
          [
           "Focusing primarily on the person youre talking to rather than yourself and the impression youre making lessens social anxiety.",
           0.458
          ],
          [
           "Let's not panic. Beat NYG who's atop the division, come home against Cleveland. Just like that you're 2-2 with a division win",
           0.417
          ],
          [
           "Can we start a 'get Chris Sutton off our tv campaign? Spread the work #terrible #pundit #noclue",
           0.433
          ],
          [
           "Forgot to plug the phone in overnight ",
           0.396
          ],
          [
           "@nigglydz lydiaaaa, we were the only ones that were supposed to know that you make me nervous ",
           0.75
          ],
          [
           "How had Matty Dawson not scored there!!!!! #terrible",
           0.375
          ],
          [
           "Everywhere I go, the air I breathe in tastes like home.' - @The_Currys ",
           0.229
          ],
          [
           "We're very busy #coding a whole network manager for #unity3d based on #steamworks networking. #gamedev #indiedev #3amDeadTime  #game",
           0.354
          ],
          [
           "The #500thTest match would have be a T20 or an ODI if @virendersehwag @B_McCullum42 been in their National Colors #nightmare #hitter  @BCCI",
           0.438
          ],
          [
           "Got to be up in 4 hours to go back to work #cantsleep #excited #nervous",
           0.7
          ],
          [
           "However the agent was inauthentic, my sister still loves me, &amp; I'm still alive. So I guess it wasn't that bad. #socialanxiety #anxiety",
           0.604
          ],
          [
           "Staff on @ryainair FR1005. Asked for info and told to look online. You get what you pay for. #Ryanair @STN_Airport #Compensation ",
           0.312
          ],
          [
           "And I cried in front of my guy last night. And it's just been a horrible week but it's only for a week",
           0.68
          ],
          [
           "@soozclifford Sure have... Sydney are too tough, too quick and their 'team' pressure is too much for the Cats to handle. Motlop/Cowan ",
           0.356
          ],
          [
           "@RyanAbe awe yay thank god I was so worried.",
           0.5
          ],
          [
           "@joey_coops yes Hun! Avoid at all costs!! #nightmare",
           0.667
          ],
          [
           "There goes the butterflies in my stomach.  #anxietyproblems",
           0.702
          ],
          [
           "About 7 weeks till I can pick up my camera again. Though I think there is a group cemetery shoot in october I can make! #photography #horror",
           0.396
          ],
          [
           "@CNNPolitics I can't wait to hear what he had to say about the brilliant Dr. Hawking... it should be rich... In the poorest of taste! #bully",
           0.354
          ],
          [
           "That's an awful miss from Rooney.",
           0.36
          ],
          [
           "About 7 weeks till I can pick up my camera again. Though I think there is a group cemetery shoot in october I can make! #photography ",
           0.312
          ],
          [
           "The Apocalypse has hit our gym and it's  nothing what I thought it would be...\\n\\nEveryone is wearing vests! What if it's contagious? ",
           0.583
          ],
          [
           "When you're scared to press send #bgoodthepoet #PrayForMe #ThisIsAGodDream #career #help #fear #heart #HeartRacing",
           0.842
          ],
          [
           "They'll be yo friend, shake your hand, then kick in yo door thas the way the game go.",
           0.417
          ]
         ],
         "hovertemplate": "emotion=fear<br>UMAP1=%{x}<br>UMAP2=%{y}<br>UMAP3=%{z}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "fear",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "fear",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": {
          "bdata": "Lj10QISAk0C+lodAWS2DQHyjzkAvF4xAHz5WQDUYz0A5WIxAgpFzQLL2ekAHfIZAk0gsQFyFQEDvCo5AIm2lQAjKREARjb9AJweuQA2UrkBSlZZAoFRpQOJgtkCu2n5AIfGvQP48nUCKsV5A1abUQNnkakCkE9JArWhyQDM3kEASPdJA6DFcQNMX2EB4d3pApaU+QMXly0Azi5NAku6KQAPbREBW/ZlAW3zUQItsekAutW9AgT3QQGILjkBvjnFAsYuOQJaXVEAKuE9AMPPSQMygkkByU8hAmn5dQBoMm0Ciik1AeK5vQK4ItUCmudRAbr1vQCVykEBZq1VAUoyWQA==",
          "dtype": "f4"
         },
         "y": {
          "bdata": "lQqMQLY+sUCXLKlA90OYQMuZiUDLOqlASHCQQDc9kUAFA6JAFmOUQDpwgkCk5KVAEY3DQL0NokCb659AlY7OQOOXmUCXfr5A1LCpQJ8MskCKHbRAfj2eQBiutkAOfZ1ArsCaQMtJ2UARcYtAXP+WQNnftEBp7ZdAbPN7QMzyrEAWI5hAOQKUQH0rlUAGVaBAnNqXQPGdo0Dm4ppAzWmJQAaBokB2V6ZAgbmYQHF1ikA0fJpAnBWVQMO0s0B3MI9AnaGjQNdKkED+fahAg6qKQElPh0DNro1AHcOwQM2NnECk0pxAFLF/QN9Nt0D40JNAvKt+QL1KjkDoaZdAvgG6QA==",
          "dtype": "f4"
         },
         "z": {
          "bdata": "mrofQS2ZQ0EFy0NB3MszQfJuJUFlMEhBoBkuQS+4NUFZxEZBf9E2QeAIMEEc/kVBTwgoQUKDMkHQZjdBtV0qQRVVLkGAWDVBVckwQSHEPkEPHRlBuHM9QcPMGUFcnj9BXwMcQdynGkFf7CVBEZorQVMQIUE/ljpBOhMuQd8GR0FW4zRBa005QSmwN0GrfkJBbWUwQRhROUHqVDZB5r8mQfZeK0FINylBlO01QaBoHkF2+zVBDnk6QUTtHEFsnjZB/wxHQUrjMkGcNC1BfD4oQbKzGkHwxjZBHgIxQb4xOEFqmjNBPYIvQSdBQEG5WTpB+hAuQVZVL0EMtjhB5Z8WQQ==",
          "dtype": "f4"
         }
        },
        {
         "customdata": [
          [
           "@sidviyer uff!! Look at your Arsenal fans cheering for every goal against United. haha",
           0.667
          ],
          [
           "Trying to loveee somebody, just wanna love somebody right now, guess there's just no pleasing me",
           0.354
          ],
          [
           "@OrbsOfJoy plan a date... like a date u find pleasing or smth. fuckign\\n\\n10/10. because the child will grow to be a ten out of ten",
           0.311
          ],
          [
           "don't put famous dex in a tweet with breezy lol chris is that guy dex a bitch lmao n music ass",
           0.354
          ],
          [
           "Aw there's a young fox outside on the grass just jumping around all playful and having a little stretch  soo cute ",
           0.75
          ],
          [
           "Miami proficiency is like pleasing by what name miami beaches: pIkxb",
           0.34
          ],
          [
           "@88Palouseriver @ABC @NRA I rejoice everything time some moron is taken out of the genetics pool.",
           0.417
          ],
          [
           "I think what 2016 to really needs to round it out is a @cthulhu4america vs @smod2016 twitter debate. End on something joyful, ya know?.",
           0.42
          ],
          [
           "myself that despite the absolute delight my children and I would feel having a kitten in our home, the misery my husband would feel is more.",
           0.327
          ],
          [
           "@PeanutRD @MelissaJoyRD @SarahKoszykRD @eat4performance @rustnutrition @jenhaugen  hey #sparkling is the word I just picked 4 my biz card",
           0.417
          ],
          [
           "Watch this amazing live.ly broadcast by @thebrandonrobert  #musically",
           0.48
          ],
          [
           "cluck cluck cluck, wolf wolf wolf , chirp chirp chirp is all I ever hear.",
           0.292
          ],
          [
           "Thank you @twitter for the balloons today.  #goodday #48",
           0.562
          ],
          [
           "Watch this amazing live.ly broadcast by @brooke_bridges #lively #musically",
           0.5
          ],
          [
           "Watch this amazing live.ly broadcast by @matt.boss #lively #musicallyjh",
           0.479
          ],
          [
           "@DanLanthier That was exhilarating hockey. They're still out if Russia wins in regulation I'm reading. #fuck",
           0.396
          ],
          [
           "@__Dayo yall dont feel bad.. you are rejoicing... it is what itnis... its always #ColtsNation even when we have 6th string DBs playing ",
           0.18
          ],
          [
           "Stack up with porthole under way heyday through worthy of faith bull's-eye transportation services: moM",
           0.32
          ],
          [
           "Wishing a very Happy Birthday to our awesome dancer, Ruthann!!! We hope your day is magical! #bday #happy #eatcake",
           0.75
          ],
          [
           "Watch this amazing live.ly broadcast by @iamjustinburke  #musically",
           0.542
          ],
          [
           "@mediacrooks @thenewshour @LodhiMaleeha @ndtv @IndiaToday This is hilarious ! Not a Freudian slip, eh !",
           0.667
          ],
          [
           "#BridgetJonesBaby is the best thing I've seen in ages! So funny, I've missed Bridget! #love  #TeamMark",
           0.922
          ],
          [
           "It has been medically proven that laughter is an effective pain killer.",
           0.48
          ],
          [
           "@musicfae15 [He grumbled as he sat atop the sushi bar stool, crossing his arms defiantly, in a playful gesture, though he gave anyone who &gt;",
           0.271
          ],
          [
           "@smoothkobra after such a heavy 2 days this has given much needed levity. Thanks bro",
           0.438
          ],
          [
           "Riggs dumb ass hell lolol  #LethalWeapon",
           0.396
          ],
          [
           "I truly believe in my heart right now that Satan is rejoicing because we are all against one another",
           0.204
          ],
          [
           "Of cheerfulness, or a good temper - the more it is spent, the more of it remains.",
           0.56
          ],
          [
           "I love when my dog is playful, but he really just scratched my face while flailing his paws in excitement and almost tore my nose ring out",
           0.333
          ],
          [
           "tfw you're en-route to your future :) !! @HUCJIR i'm coming for ya! #openhouse #futurecantor #exhilarating #NYCletsgo",
           0.657
          ],
          [
           "@UKLittleKitchen Defo a hearty root veg gratin. Nice comfort food as Autumn kicks in",
           0.48
          ],
          [
           "I am so happy I have come across @HilltopBindery notebooks! #handmade would love to talk to you! #musthave #want #need #happy #amazing ",
           0.812
          ],
          [
           "Why have I only just started watching glee this week I am now addicted  #glee #GLEEK",
           0.625
          ],
          [
           "Well look at the bright side. You found a use for that rope #TipsToSurviveAPowerOutage",
           0.312
          ],
          [
           "Yeah PAUL  #glorious #BB18",
           0.917
          ],
          [
           "Method into thin out assault corridor thine liveliness: cHd",
           0.32
          ],
          [
           "Tutoring gives me such an exhilarating feeling. I love helping people ",
           0.896
          ],
          [
           "@theclobra lol I thought maybe, couldn't decide if there was levity or not",
           0.312
          ],
          [
           "i was so embarrassed when she saw us i was like knvfkkjg she thinks we're stalkers n then she starts waving all cheerfully inviting us in ",
           0.25
          ],
          [
           "A #new day to #live and #smile. Hope all the #followers a nice #night or #day. :D",
           0.688
          ],
          [
           "I love my family so much #lucky #grateful #smartassfamily #hilarious #love",
           0.792
          ],
          [
           "I turn 25 in two weeks. I am so happy. 24 was my darkest year yet. I am elated that I survived",
           0.708
          ],
          [
           "@chencouture LMAO Is it that 'so slutty' hater girl? That video was hilarious. ",
           0.7
          ],
          [
           "@NateBLoL no it was that clear American naturally flavored sparkling water",
           0.312
          ],
          [
           "A cheerful heart is good medicine, but a broken spirit saps a person's strength.' {Proverbs 17:22} #WednesdayWisdom",
           0.292
          ]
         ],
         "hovertemplate": "emotion=joy<br>UMAP1=%{x}<br>UMAP2=%{y}<br>UMAP3=%{z}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "joy",
         "marker": {
          "color": "#00cc96",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "joy",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": {
          "bdata": "A4CuQPRSh0BsmL1ASlnCQD8MVEDiSp5AwELEQDfxjUDhcndAWh1NQFieiUBOnZZApg1DQNzIikB5nYxAaIjIQFj5lkCY2Z5A3hZFQLfMh0AHxpdAkqo9QEh8YUD2/7RAOD6EQIu2xUCbPotAuzNmQA9NbUDm/SlAYw1tQOO4NEASdztACgdtQHTBoUDAQZ1A210sQH5qkECioG9A64dFQNNDVEDVOzRAHvKeQEEYhUD6aVlA",
          "dtype": "f4"
         },
         "y": {
          "bdata": "6WbIQB2xj0BpPaRA//HAQMZIvUDvB+9A9826QGW5x0Cc4axAbgrLQJ675UBPXqtAw/PGQN9M50Am0uRAoiqgQMwsp0CbxexAOdTKQFR35EDgNrRAcI7RQOQavUCmydhAtH7PQN6awEBlKaVAq2+5QIM1sUAIB7ZAOWvKQLcdykBxdNNAH82/QD1xxEAO7+dAvY69QA0z1kBod5xAY0HBQCsY0kCAYL9AO7TUQGtl10B6RsBA",
          "dtype": "f4"
         },
         "z": {
          "bdata": "YXo1Qd3lFEFAbB5BNzEvQeu2IkGNmhNBoeg2QYKdM0FW8hlB5n0xQX+oOUHnyR9BHvYtQdjfOUGCCDtBqpspQTKKJ0Gx1BJBD7MwQT2hOUHQX0VBLx0qQbyVFkGL4h5Bg+suQWO4MkFxZh1BzT4VQQomHkHMfS5B0HsnQcIkKkEgnilB2HYqQdn0OEH0IhJBUGgrQZxcK0GvCSpB4XYgQS8nK0ELiCtBhxExQRfDLEEDxRhB",
          "dtype": "f4"
         }
        },
        {
         "customdata": [
          [
           "Back to forest drama -\\nfrom my #Forest #music - series, 2016\\n#nature #dark #art #photography #Finland",
           0.271
          ],
          [
           "But When it come to a serious situation, I be glad I gave it deep thought ",
           0.375
          ],
          [
           "I'm slugging vitamin D pills by the handful, like they were m&amp;ms. When will this eternal winter end?! #Melbourne #grim #overit",
           0.675
          ],
          [
           "[My teeth were sunk down into the vein of the poor woman who had 'accidentally' had a small problem with her engine, just outside of --",
           0.479
          ],
          [
           "@gagasklaine it's old sadly",
           0.667
          ],
          [
           "the rappers who stayed true to the game is rich.",
           0.208
          ],
          [
           "so lost i'm faded",
           0.729
          ],
          [
           "So depressing that it's darker so much earlier now",
           0.75
          ],
          [
           "there are #serious #chinks in #Indias #armour'\\n#protein\\n#malnutrition\\n#feedingIndia\\n#skillingIndia\\n#cognitive #deficit\\n@Abhijit_Iyer",
           0.354
          ],
          [
           "Do not be discouraged by a slowing sales market. This will test your business model and pinpoint #strengths and #weaknesses.' @Ken_Dunn",
           0.271
          ],
          [
           "@janhopis I found the first few episodes of Bojack incredibly funny. Then it got less funny but I stayed for the #drama",
           0.354
          ],
          [
           "@Jacqueline_69 haha! She did well today. I can't get beyond her pout annoying me I'm afraid.",
           0.562
          ],
          [
           "How brave are the young individuals that have opened up to us about their #depression and #anxiety to help raise awareness!! @beyondblue",
           0.479
          ],
          [
           "@everton_de_leon @sterushton Genuinely grim stuff. Over a century of history sold off by some porn baron twats for a minty new stadium. Urgh",
           0.624
          ],
          [
           "@6itmap I can't help but feel melancholic!",
           0.75
          ],
          [
           "@patthemanager how could I work with @chancetherapper . ? #serious",
           0.354
          ],
          [
           "It's sad when your man leaves work a little bit late and your worst fear is 'Oh no!! Did he get stopped by the police?!?! ' #sad #ourworld",
           0.688
          ],
          [
           "Having holiday blues! #WantToGoBackToMinehead.",
           0.661
          ],
          [
           "Tell me how I'm supposed to feel. #broken #hateful #guilty #love #sadness",
           0.729
          ],
          [
           "@ArcadianLuthier -- taking out his feelings on Kei unfairly. His lips form a frown as he tries to walk away.",
           0.521
          ],
          [
           "@alisontis otherwise you're committing a crime against your soul only sober ppl know what is good or bad for themselves",
           0.438
          ],
          [
           "What's good is that we already hit rock bottom, even though I'm about two more seasons away from new depths of despair. #playoffs? #NJDevils",
           0.542
          ],
          [
           "Fucking gutted, disheartened &amp; so pissed off.Gone from 1 off the toughest most resolute defences to the worst &amp; most shambolic #SCFC #STOHUL",
           0.729
          ],
          [
           "Beats is accurately all-powerful with respect to high-quality high-frequency speaker in re the extra desolate relating to fire-ea:",
           0.271
          ],
          [
           "I wanna see you smile I don't wanna see you make a frown",
           0.333
          ],
          [
           "Interview preparation, I hate talking about myself, one dull subject matter! #yawnoff",
           0.396
          ],
          [
           "@Hayles_101 The three R's depress me.",
           0.792
          ],
          [
           "Having a nail half hanging off is absolutely fucking grim, even with my acrylic holding it on ",
           0.604
          ],
          [
           "The word happiness would lose its meaning if it were not balanced by sadness.",
           0.479
          ],
          [
           "went to Pet Supplies Plus tonight but @neitzkeamara was not working I feel #lost and #confused",
           0.458
          ],
          [
           "@kikibug13 Don't look. You'll only be very, very unhappy. \\n\\n(NNGH. I got the email notif THANK YOU.)",
           0.438
          ],
          [
           "All the 'juniors' are now wearing purple at ollafest while I'm here fighting with my alarm about when I need to wake up for German #sadness",
           0.646
          ],
          [
           "It's a gloomy ass day",
           0.888
          ],
          [
           "ya boy gets mad tired of pine trees",
           0.292
          ],
          [
           "Mmmm #coffee and a good #book on a dreary day! Who can beat that?",
           0.25
          ],
          [
           "Chalk dance notation entree manchester inasmuch as corinthian products that discourage drag branding: ARwuEVfqv",
           0.188
          ],
          [
           "Common app just randomly logged me out as I was writing the last part of my college essay and lost all of it ",
           0.833
          ],
          [
           "I can't WAIT to go to work tomorrow with a high as fuck fever. [sarcasm]\\nHopefully I'll feel better tomorrow.\\nBut I doubt it. #pessimism",
           0.646
          ],
          [
           "On bedrest since I got out of the hospital. U find in unopened beer.. what do I do. Pour that shit out! No alcohol at all for me #sober",
           0.44
          ],
          [
           "It's basically a dead skin peel which sounds grim. But it literally gets rid of so much dead skin from your pores.",
           0.354
          ],
          [
           "@kayleighmcenany  @DonaldJTrumpJr Is that really all you can offer for those who sacrifice daily to keep you safe...? @kayleighmcenany #sad",
           0.625
          ],
          [
           "Buddha doesn't possess enough power to deliver you from your affliction!",
           0.542
          ],
          [
           "Should of stayed in Dubai ",
           0.708
          ]
         ],
         "hovertemplate": "emotion=sadness<br>UMAP1=%{x}<br>UMAP2=%{y}<br>UMAP3=%{z}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "sadness",
         "marker": {
          "color": "#ab63fa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "sadness",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": {
          "bdata": "Erp4QAU3gkAjjKZA6umgQCaAnEBhBpdApb2PQHvikEAJ1Y1AJap6QC0mh0BPeJlA6K48QB9wyUA++45AGCS4QMzHh0A24I9AcSyOQJ9KtkCbIqZArK+dQEHrzEB1wZtAQf9hQEFwUUB8nJxAQYS4QKeOa0DDr4VAC8+IQNoWhUDBiKRA0CWaQAS1S0Dbt55ADTaoQIKEqEATDLdA7dawQKKXrkD1Ga1Ahk2SQA==",
          "dtype": "f4"
         },
         "y": {
          "bdata": "DZyBQB3jv0B024hAI9rbQDwUxEB/scFAHNiTQDjJikAyRaJAggy/QKdh10DDktVAA3yWQJBsmEBk7pBAUIHEQC3chUBl741AgTeLQCIQ00CEbLBAQsScQIxjkUA5PuxA0bG6QJQwlUD4FZdAOeqNQKA/sUCCJYhAjvGoQK4Xh0CpFo5A64qeQEtBykD54OpApOl9QFrfkEC9EKNAU/mNQAVTsUBr8LdAa2iKQA==",
          "dtype": "f4"
         },
         "z": {
          "bdata": "uHoqQUlJJUHuJSJBZXMdQVO/KEFhgxdB1yEZQVL1IEGJ10ZBkaYjQT8sKkH9VClBkBwxQRSIMkGB/x5BKe4vQTyiIkHUjiFBmlQXQZUGHkEEkBpBtsIlQTFSL0HwmhJBmM4VQQ1TKEHb2ilBWfEgQWErFkHi/xpBfI8wQb/qH0GuNhtBvFgbQZQ9JEFhuBBB4AIoQVo/HUEXBxtBeqUgQVUhPkFsfRVBrc4jQQ==",
          "dtype": "f4"
         }
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "emotion"
         },
         "tracegroupgap": 0
        },
        "scene": {
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "xaxis": {
          "title": {
           "text": "UMAP1"
          }
         },
         "yaxis": {
          "title": {
           "text": "UMAP2"
          }
         },
         "zaxis": {
          "title": {
           "text": "UMAP3"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "3D UMAP Projection of Text Embeddings"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Answer here\n",
    "reducer_3d = umap.UMAP(n_components=3, metric='cosine', random_state=28)\n",
    "embedding_3d = reducer_3d.fit_transform(X_embeddings)\n",
    "\n",
    "df_plot_3d = pd.DataFrame(embedding_3d, columns=['UMAP1', 'UMAP2', 'UMAP3'])\n",
    "df_plot_3d['emotion'] = combined_df['emotion']\n",
    "df_plot_3d['intensity'] = combined_df['intensity']\n",
    "df_plot_3d['text'] = combined_df['text']\n",
    "\n",
    "fig_3d = px.scatter_3d(\n",
    "    df_plot_3d,\n",
    "    x='UMAP1',\n",
    "    y='UMAP2',\n",
    "    z='UMAP3',\n",
    "    color='emotion',\n",
    "    hover_data=['text', 'intensity'],\n",
    "    title='3D UMAP Projection of Text Embeddings'\n",
    ")\n",
    "fig_3d.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Similarities**\n",
    "\n",
    "Both the 2D and 3D UMAP projections are computed from the same set of embeddings, so the overall cluster structure remains similar, points with the same emotion tend to group together, and the relative positions between different emotion clusters are broadly preserved.\n",
    "\n",
    "### **Differences**\n",
    "\n",
    "3D making certain boundaries between emotions clearer. This happens because 3D preserves slightly more of the original high-dimensional structure.\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "Both the 2D and 3D UMAP projections preserve the main clustering structure of the original embeddings, so emotion categories remain grouped in similar patterns across both views. However, points that overlap or appear compressed in 2D often become more separable along the third axis in 3D, revealing clearer boundaries between some emotions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_9_'></a>[**2.5 Retrieval-Augmented Generation (RAG)**](#toc0_)\n",
    "\n",
    "`NOTE: This whole section including the exercise is now considered a bonus section, not counted for the main grade.`\n",
    "\n",
    "RAG (Retrieval-Augmented Generation) is a technique where a language model combines document retrieval with text generation. In RAG, a retrieval system first finds relevant documents or text chunks, and then the language model uses this retrieved information to generate a more informed and accurate response. This method enhances the model's ability to answer questions by grounding its responses in real, external data.\n",
    "\n",
    "In the following code, we will load a webpage as a document, which allows us to retrieve text from a URL. After loading the content, we will split the document into smaller, manageable chunks, making it easier for our model to process. Then, we'll generate embeddings for these chunks with a specified LLM model (Gemini Embedding Model). These embeddings will be stored in a vector database, which enables us to perform similarity searches. By setting up this retrieval system, we can use a RAG chain to answer questions. The retriever finds relevant text chunks from the document based on a query, and the LLM generates a response by incorporating this retrieved information, making the answers more grounded and accurate.\n",
    "\n",
    "In this example we use the library langchain, for documentation on more functions of the library you can check the following link: [LangChain Tutorials](https://python.langchain.com/docs/tutorials/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "# Function to load, split, and retrieve documents\n",
    "def load_and_retrieve_docs(url):\n",
    "    loader = WebBaseLoader(\n",
    "        web_paths=(url,),\n",
    "        bs_kwargs=dict() \n",
    "    ) \n",
    "    docs = loader.load() #We will load the URL that will serve as our data source\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150) #We will divide the URL in chunks of text for easier comparison in the vector space\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    #print(splits) #You can print this to see how the chunks in the url where split\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
    "    vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings) #Our vector space for comparison\n",
    "    return vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs) #Format the retrieved docs in an orderly manner for prompting\n",
    "\n",
    "# Define the Gemini LLM function\n",
    "def gemini_llm(question, context):\n",
    "    system_prompt = \"You are a RAG Agent that needs to provide a well structured answer based on the provided question and context.\"\n",
    "    formatted_prompt = f\"Question: {question}\\n\\nContext: {context}\"\n",
    "    response, logs = prompt_gemini(input_prompt = formatted_prompt, system_instruction = system_prompt, with_tokens_info = True)\n",
    "    print(f\"logs: \\n{logs}\")\n",
    "    # print(f\"Retrieved context: \\n{context}\\n\\n\") # You can print this to observe the retrieved context\n",
    "    return response\n",
    "\n",
    "\n",
    "# Define the RAG chain\n",
    "def rag_chain(question, retriever):\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    formatted_context = format_docs(retrieved_docs)\n",
    "    return gemini_llm(question, formatted_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs: \n",
      "{'model': 'gemini-2.5-flash-lite', 'input_tokens': 726, 'output_tokens': 190}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The key challenges in realizing AGI's full potential stem from its fundamental requirements and the ethical considerations surrounding its development. These include:\n",
       "\n",
       "*   **Learning from Diverse Data:** Unlike narrow AI, which is trained on structured data, AGI needs to learn from a wide variety of unstructured data sources.\n",
       "*   **Computational Power:** The sheer amount of computational resources needed to process and learn from these vast and diverse datasets presents a significant hurdle.\n",
       "*   **Ethical Concerns:** Developing AGI responsibly requires addressing critical ethical issues such as:\n",
       "    *   **Bias and Fairness:** Ensuring algorithms are unbiased and treat everyone equally by training on diverse datasets and continuously monitoring performance.\n",
       "    *   **Privacy:** Prioritizing user data protection through robust privacy measures and transparent data usage policies.\n",
       "    *   **Accountability:** Establishing clear guidelines and legal frameworks to determine responsibility for decisions made by AGI systems and address any harm caused."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url=\"https://qbotica.com/understanding-artificial-general-intelligence-agi-an-in-depth-overview/\"\n",
    "# Create the retriever\n",
    "retriever = load_and_retrieve_docs(url)\n",
    "\n",
    "# Use the RAG chain\n",
    "result = rag_chain(question=\"What are the Key Challenges in Realizing AGIs Full Potential\", retriever=retriever)\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### <a id='toc1_5_9_1_1_'></a>[**Actual answer in the URL:**](#toc0_)\n",
    "\n",
    "![pic11.png](pics/pic11.png)\n",
    "\n",
    "##### <a id='toc1_5_9_1_2_'></a>[**Content in the URL that might get into the generated answer because of similar semantic meaning:**](#toc0_)\n",
    "\n",
    "![pic12.png](pics/pic12.png)\n",
    "\n",
    "source: https://qbotica.com/understanding-artificial-general-intelligence-agi-an-in-depth-overview/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_9_1_3_'></a>[**>>> Bonus Exercise 5 (Take home):**](#toc0_)\n",
    "\n",
    "`NOTE: This exercise is now considered a bonus one, not counted for the main grade, only as extra points.`\n",
    "\n",
    "Your task is to test the RAG system with your own chosen URL and analyze its performance.\n",
    "\n",
    "1. Find a URL of a webpage with interesting text content to test the RAG pipeline.\n",
    "2. Make a question about the content in the webpage you chose.\n",
    "3. Discuss how good the question was answered by the model, if the model missed important information related to your question.\n",
    "4. Display a screenshot of the real answer in the webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs: \n",
      "{'model': 'gemini-2.5-flash-lite', 'input_tokens': 809, 'output_tokens': 52}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The provided text does not contain information about NYCU relocating its earlier campus to the Guangfu site in Hsinchu. It only describes the Guangfu Campus as NYCU's main campus and official address, highlighting its strategic location and the colleges it houses."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Answer here\n",
    "url=\"https://en.wikipedia.org/wiki/National_Yang_Ming_Chiao_Tung_University\"\n",
    "# Create the retriever\n",
    "retriever = load_and_retrieve_docs(url)\n",
    "\n",
    "# Use the RAG chain\n",
    "result = rag_chain(question=\"Why did NYCU decide to relocate its earlier campus to the Guangfu site in Hsinchu?\", retriever=retriever)\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Results**\n",
    "\n",
    "The model responded that the document did not mention any information about NYCU relocating its earlier campus to the Guangfu site. However, the source text clearly includes a detailed description of the universitys relocation historyfrom the original Boai Campus, to the consideration of Chengcing Lake in Kaohsiung, and finally to the Weiwuying military base, which later became the Guangfu Campus. The models answer was incorrect, the RAG system failed to retrieve the paragraph containing the relocation history.\n",
    "\n",
    "The likely reason the retriever failed to retrieve the relocation passage is the lack of direct keyword alignment. The question explicitly used the term relocated, but the document never used this word. Instead, the relocation history was described narratively, mentioning Boai Campus, the consideration of Chengcing Lake, and the militarys offer of the Weiwuying site, without explicitly using terms such as relocation, move, or transfer. Because embedding-based retrieval still relies heavily on semantic similarity, the absence of these direct keywords reduced the match score, causing the retriever to overlook the relevant chunk despite the information being present.\n",
    "\n",
    "\n",
    "#### **Actual answer in wiki:**\n",
    "![screenshot](<pics/screenshot.png>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_10_'></a>[**2.6 Few-Shot Prompting Classification:**](#toc0_)\n",
    "\n",
    "Few-shot prompting is a technique where a Large Language Model (LLM) is given a small number of labeled examples within a prompt to guide its classification. This allows the model to perform a new task with minimal data, avoiding the need for extensive fine-tuning.\n",
    "\n",
    "In this lab, we will use the Gemini API to perform zero-shot, 1-shot, and 5-shot emotion classification:\n",
    "\n",
    "*   **Zero-shot:** The model classifies text without any prior examples.\n",
    "*   **1-shot:** The model is given one example for each emotion before classifying.\n",
    "*   **5-shot:** The model is given five examples per emotion for better context.\n",
    "\n",
    "To make our implementation robust and efficient, we are incorporating two key features:\n",
    "\n",
    "1.  **Structured Output:** We provide the Gemini model with a specific output schema (`Emotions` class). This instructs the model to return *only* a valid emotion label (e.g., `joy`), which makes the output predictable and reliable, minimizing errors.\n",
    "2.  **API Rate Handling:** The code includes a function to manage the requests-per-minute limit of the Gemini API.\n",
    "\n",
    "We will test the model's performance on a small sample of 20 texts per emotion to ensure the process runs quickly. If the model provides an invalid response, the code will automatically retry the request until a valid classification is received.\n",
    "\n",
    "**Prompt Structure:**\n",
    "`System Instruction -> Task Description -> Examples (if not zero-shot) -> Text to Classify`\n",
    "\n",
    "\n",
    "<span style=\"color:green\">For the exercises in this section there is no need to re-run the cells, you can use the data that has been saved previously to the corresponding directory.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciton for visualizing confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix',\n",
    "                          cmap=sns.cubehelix_palette(as_cmap=True)):\n",
    "    \"\"\"\n",
    "    This function is modified from: \n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \"\"\"\n",
    "    classes.sort()\n",
    "    tick_marks = np.arange(len(classes))    \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels = classes,\n",
    "           yticklabels = classes,\n",
    "           title = title,\n",
    "           xlabel = 'Predicted label',\n",
    "           ylabel = 'True label')\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    ylim_top = len(classes) - 0.5\n",
    "    plt.ylim([ylim_top, -.5])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import enum\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import time\n",
    "# Define the emotion labels\n",
    "emotions = ['anger', 'fear', 'joy', 'sadness']\n",
    "# Define the model to use for few-shot prompting\n",
    "\n",
    "# Schema for the output, the type enum can be used to make a pool of options if what we want is to classify our text selecting only one of them\n",
    "class Emotions(enum.StrEnum):\n",
    "    ANGER = 'anger'\n",
    "    FEAR = 'fear'\n",
    "    JOY = 'joy'\n",
    "    SADNESS = 'sadness'\n",
    "\n",
    "\n",
    "# Function to handle the rate limits of gemini models\n",
    "def handle_rate_limit(request_count, first_request_time, max_calls_per_min):\n",
    "    current_time = time.time()\n",
    "\n",
    "    # Initialize timer on the first request of a new window\n",
    "    if request_count == 0:\n",
    "        first_request_time = current_time\n",
    "\n",
    "    request_count += 1\n",
    "\n",
    "    # If the rate limit is reached\n",
    "    if request_count > max_calls_per_min:\n",
    "        elapsed_time = current_time - first_request_time\n",
    "        if elapsed_time < 60:\n",
    "            wait_time = 60 - elapsed_time\n",
    "            print(f\"Rate limit of {max_calls_per_min} requests per minute reached. Waiting for {wait_time:.2f} seconds.\")\n",
    "            time.sleep(wait_time)\n",
    "\n",
    "        # Reset for the new window\n",
    "        request_count = 1\n",
    "        first_request_time = time.time()\n",
    "    \n",
    "    return request_count, first_request_time, max_calls_per_min\n",
    "\n",
    "# Function to sample examples per emotion category\n",
    "def sample_few_shots(df, emotions, num_samples=5):\n",
    "    few_shot_examples = {}\n",
    "    for emotion in emotions:\n",
    "        few_shot_examples[emotion] = df[df['emotion'] == emotion].sample(n=num_samples, random_state=42)\n",
    "    return few_shot_examples\n",
    "\n",
    "# Function to build the prompt based on the number of examples (few-shot, 1-shot, zero-shot)\n",
    "def build_prompt(examples, emotions, num_shots=5):\n",
    "    classification_instructions = \"\"\"\n",
    "You will be given a text extracted from social media and your task is to classify the text into one of the following emotion categories: \n",
    "\"anger\" | \"fear\" | \"joy\" | \"sadness\"\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = classification_instructions + \"\\n\\n\"\n",
    "    \n",
    "    if num_shots > 0:\n",
    "        prompt += f\"Examples: \\n\"\n",
    "        for emotion in emotions:\n",
    "            for _, row in examples[emotion].iterrows():\n",
    "                prompt += f\"Text: {row['text']}\\nClass: {emotion}\\n\\n\" #Show the examples in the same format it will be shown for the classification text\n",
    "                if num_shots == 1:  # If 1-shot, break after the first example for each emotion\n",
    "                    break\n",
    "    return prompt\n",
    "\n",
    "# Function to classify using the LLM with retry for incorrect responses\n",
    "def classify_with_llm(test_text, prompt_base, system_prompt, classes, schema):\n",
    "    response = None\n",
    "    while not response or response not in classes:\n",
    "        full_prompt = f\"{prompt_base}\\nClassification:\\nText: {test_text}\\nClass: \" #The classification text will leave the emotion label to be filled in by the LLM\n",
    "        try:\n",
    "            result = prompt_gemini(input_prompt = [full_prompt], schema = schema, system_instruction = system_prompt)\n",
    "            # print(f\"result: {result} \\n\")\n",
    "            # print(f\"type: {type(result)}\")\n",
    "            if not result:\n",
    "                # In case of giving empty responses with temperature 0.0, we set a higher temperature to seek for different responses\n",
    "                result = prompt_gemini(input_prompt = [full_prompt], schema = schema, system_instruction = system_prompt, temperature=1.0)\n",
    "\n",
    "            try:\n",
    "                # If the result is in the correct format it can be parsed using json\n",
    "                response = json.load(result)\n",
    "            except:\n",
    "                # In case it's not in a json friendly format\n",
    "                # Deleting characters \" and ' in case they appear in our response with the class of the text \n",
    "                response = result.replace('\"', '')    \n",
    "                response = response.replace(\"'\", \"\")  \n",
    "\n",
    "                \n",
    "        # except exceptions.ResourceExhausted as e:\n",
    "        except Exception as e:\n",
    "            print(f\"Waiting to retry... Error: {e}\")\n",
    "            time.sleep(15)\n",
    "            print(f\"test_text: {test_text}\")\n",
    "            return classify_with_llm(test_text, prompt_base, system_prompt, classes, schema) # Retry the request\n",
    "\n",
    "\n",
    "        if response not in classes:  # Retry if not a valid response\n",
    "            print(f\"Invalid response: {response}. Asking for reclassification.\")\n",
    "    return response\n",
    "\n",
    "# Main function to run the experiment with the option for zero-shot, 1-shot, or 5-shot prompting\n",
    "def run_experiment(df_train, df_test, num_test_samples=5, num_shots=5):\n",
    "    # Sample examples for few-shot prompting based on num_shots\n",
    "    if num_shots > 0:\n",
    "        few_shot_examples = sample_few_shots(df_train, emotions, num_samples=num_shots) \n",
    "        prompt_base = build_prompt(few_shot_examples, emotions, num_shots=num_shots)\n",
    "    else:\n",
    "        prompt_base = build_prompt(None, emotions, num_shots=0)  # Zero-shot has no examples\n",
    "\n",
    "    # System prompt for our classification model:\n",
    "    system_prompt = \"You are an emotion classification model for text data. Do not give empty responses, classify according to the list of possible classes.\"\n",
    "\n",
    "    # Prepare to classify the test set\n",
    "    results_data = []\n",
    "\n",
    "    print(prompt_base)\n",
    "    # Sample 20 examples per emotion for the test set to classify\n",
    "    test_samples = sample_few_shots(df_test, emotions, num_samples=num_test_samples)\n",
    "\n",
    "    # Variables to handle rate limit of gemini\n",
    "    request_count = 0\n",
    "    max_calls_per_min = 15 # Gemini 2.5 Flash Lite has this maximum set in the documentation\n",
    "    first_request_time = None\n",
    "\n",
    "    # Classify 20 test examples (5 from each category) and save predictions\n",
    "    for emotion in emotions:\n",
    "        for _, test_row in tqdm(test_samples[emotion].iterrows(), desc=f\"Processing samples for emotion: {emotion}...\", total=num_test_samples):\n",
    "            test_text = test_row['text']\n",
    "            request_count, first_request_time, max_calls_per_min = handle_rate_limit(request_count, first_request_time, max_calls_per_min)  # Check and handle rate limit before each API call\n",
    "            predicted_emotion = classify_with_llm(test_text = test_text, prompt_base = prompt_base, system_prompt = system_prompt, classes = emotions, schema = Emotions)\n",
    "            # Append the results data:\n",
    "            results_data.append({\n",
    "                    'text': test_text,\n",
    "                    'true_emotion': emotion,\n",
    "                    'predicted_emotion': predicted_emotion\n",
    "                })\n",
    "\n",
    "    # Create dataframe to save the results data\n",
    "    results_df = pd.DataFrame(results_data)\n",
    "    \n",
    "    # Extract just the true and predicted labels for metrics calculations\n",
    "    true_labels = results_df['true_emotion']\n",
    "    predictions = results_df['predicted_emotion']\n",
    "\n",
    "    output_dir = \"./results/llm_classification_results\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # Save the results\n",
    "    filename = f\"{output_dir}/results_samples_{num_test_samples}_shots_{num_shots}.csv\"\n",
    "    \n",
    "    # Save the DataFrame to CSV\n",
    "    results_df.to_csv(filename, index=False)\n",
    "    print(f\"\\nResults saved to {filename}\")\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(classification_report(y_true=true_labels, y_pred=predictions))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(y_true=true_labels, y_pred=predictions) \n",
    "    my_tags = ['anger', 'fear', 'joy', 'sadness']\n",
    "    plot_confusion_matrix(cm, classes=my_tags, title=f'Confusion matrix for classification with \\n{num_shots}-shot prompting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important: The next part should take around 16 minutes to finish running due to API Rate Limits**\n",
    "\n",
    "**Note:** You might see an `429 RESOURCE_EXHAUSTED` error when running the following code all at once, this is because the `current API Rate Limit handling cannot reliably find out how many requests we have left per minute` from cell to cell, there is no Gemini feature created for it to get the information from their servers. So, `if you don't want to see the error you can just wait 1 minute` after one cell finished processing. But `even if there is an error showing it is fine`, internally in the code `there is a retry that happens every 15 seconds` until we finish processing our sampled data. `The lab is designed to never reach the total rate limit per day quota.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You will be given a text extracted from social media and your task is to classify the text into one of the following emotion categories: \n",
      "\"anger\" | \"fear\" | \"joy\" | \"sadness\"\n",
      "    \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:  75%|  | 15/20 [00:11<00:03,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 48.47 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...: 100%|| 20/20 [01:03<00:00,  3.17s/it]\n",
      "Processing samples for emotion: fear...:  50%|     | 10/20 [00:07<00:07,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 49.18 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: fear...: 100%|| 20/20 [01:03<00:00,  3.19s/it]\n",
      "Processing samples for emotion: joy...:  25%|       | 5/20 [00:03<00:11,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 48.99 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...: 100%|| 20/20 [01:02<00:00,  3.14s/it]\n",
      "Processing samples for emotion: sadness...:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 49.80 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...:  75%|  | 15/20 [00:59<00:03,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 49.81 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...: 100%|| 20/20 [01:53<00:00,  5.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to ./results/llm_classification_results/results_samples_20_shots_0.csv\n",
      "Accuracy: 51.25%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.41      0.55      0.47        20\n",
      "        fear       0.86      0.30      0.44        20\n",
      "         joy       0.50      0.85      0.63        20\n",
      "     sadness       0.58      0.35      0.44        20\n",
      "\n",
      "    accuracy                           0.51        80\n",
      "   macro avg       0.59      0.51      0.49        80\n",
      "weighted avg       0.59      0.51      0.49        80\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If you see '429 RESOURCE_EXHAUSTED' errors it's fine, wait until the data gets processed, it will keep retrying until it finishes\n",
    "\n",
    "# Example of running the experiment with zero-shot prompting\n",
    "run_experiment(train_df, test_df, num_test_samples=20, num_shots=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You will be given a text extracted from social media and your task is to classify the text into one of the following emotion categories: \n",
      "\"anger\" | \"fear\" | \"joy\" | \"sadness\"\n",
      "    \n",
      "\n",
      "Examples: \n",
      "Text: @TDsNation I blame how broken madden is this year\n",
      "Class: anger\n",
      "\n",
      "Text: @MichaelSalfino It still destroys Fear The Walking Dead. That show is horrible\n",
      "Class: fear\n",
      "\n",
      "Text: Thinking about trying some comedy on youtube. Always been fond of it. Time to nut up.  #comedy #maybeoneday #hopefullyfunny #LOL\n",
      "Class: joy\n",
      "\n",
      "Text: The voice is all about Miley and Alicia this year. No longer about the contestants. #sad @thevoice\n",
      "Class: sadness\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:  55%|    | 11/20 [00:08<00:06,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 58.378322211s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '58s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 58.346913267s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '58s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: I think @Sam_Canaday &amp; @KYLEJDOWSON must actually have to be working like me &amp; @dowson_brady because I havent got any snap chat videos today\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 43.266979174s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '43s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 43.23159326s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '43s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: I think @Sam_Canaday &amp; @KYLEJDOWSON must actually have to be working like me &amp; @dowson_brady because I havent got any snap chat videos today\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 28.150864556s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '28s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 28.111218838s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '28s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: I think @Sam_Canaday &amp; @KYLEJDOWSON must actually have to be working like me &amp; @dowson_brady because I havent got any snap chat videos today\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 13.028899931s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '13s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 12.985018706s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '12s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: I think @Sam_Canaday &amp; @KYLEJDOWSON must actually have to be working like me &amp; @dowson_brady because I havent got any snap chat videos today\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...: 100%|| 20/20 [01:15<00:00,  3.78s/it]\n",
      "Processing samples for emotion: fear...:  35%|      | 7/20 [00:04<00:09,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 45.948738092s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 45.909331114s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Bout ta get my @dontbreathe on up in here! @WarrenTheaters #nervous #icantholdmybreaththatlong\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 30.832059157s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '30s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 30.799340733s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '30s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Bout ta get my @dontbreathe on up in here! @WarrenTheaters #nervous #icantholdmybreaththatlong\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 15.731804244s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '15s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 15.69085488s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '15s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Bout ta get my @dontbreathe on up in here! @WarrenTheaters #nervous #icantholdmybreaththatlong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: fear...:  50%|     | 10/20 [00:52<01:16,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 4.17 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: fear...: 100%|| 20/20 [01:03<00:00,  3.19s/it]\n",
      "Processing samples for emotion: joy...:  15%|        | 3/20 [00:01<00:09,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 45.152673542s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 45.117796858s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: The smell of freshly cut grass didn't even cheer me up...boy oh boy\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 30.047958478s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '30s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 30.007410121s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '30s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: The smell of freshly cut grass didn't even cheer me up...boy oh boy\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 14.72559038s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 14.686352158s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: The smell of freshly cut grass didn't even cheer me up...boy oh boy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...:  25%|       | 5/20 [00:48<03:01, 12.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 4.06 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...:  95%|| 19/20 [01:02<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 44.459525941s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '44s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 44.404508197s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '44s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: @Geminiak @LondonNPC you're welcome! #wordgeek \\nAlso, good to put a face to the twitter feed, even if it was only a cheery hello! \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 29.326205565s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '29s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 29.28263838s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '29s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: @Geminiak @LondonNPC you're welcome! #wordgeek \\nAlso, good to put a face to the twitter feed, even if it was only a cheery hello! \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 14.20926783s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 14.168003276s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: @Geminiak @LondonNPC you're welcome! #wordgeek \\nAlso, good to put a face to the twitter feed, even if it was only a cheery hello! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...: 100%|| 20/20 [01:48<00:00,  5.45s/it]\n",
      "Processing samples for emotion: sadness...:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 3.77 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...:  75%|  | 15/20 [00:14<00:03,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 48.90 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...: 100%|| 20/20 [01:07<00:00,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to ./results/llm_classification_results/results_samples_20_shots_1.csv\n",
      "Accuracy: 56.25%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.46      0.65      0.54        20\n",
      "        fear       0.73      0.40      0.52        20\n",
      "         joy       0.57      0.85      0.68        20\n",
      "     sadness       0.64      0.35      0.45        20\n",
      "\n",
      "    accuracy                           0.56        80\n",
      "   macro avg       0.60      0.56      0.55        80\n",
      "weighted avg       0.60      0.56      0.55        80\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If you see '429 RESOURCE_EXHAUSTED' errors it's fine, wait until the data gets processed, it will keep retrying until it finishes\n",
    "\n",
    "# Example of running the experiment with 1-shot prompting\n",
    "run_experiment(train_df, test_df, num_test_samples=20, num_shots=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You will be given a text extracted from social media and your task is to classify the text into one of the following emotion categories: \n",
      "\"anger\" | \"fear\" | \"joy\" | \"sadness\"\n",
      "    \n",
      "\n",
      "Examples: \n",
      "Text: @TDsNation I blame how broken madden is this year\n",
      "Class: anger\n",
      "\n",
      "Text: @DouthatNYT @jbouie @DamonLinker Yes, it is bad to point out racism lest it provoke the racists.  Some racists do indeed not like it.\n",
      "Class: anger\n",
      "\n",
      "Text: @thatomahapa the best revenge is to get yourself a good woman and move on. Leave her and her hairline to figure themselves out alone\n",
      "Class: anger\n",
      "\n",
      "Text: The most important thing to #bestrong is to hold your  #thoughts\n",
      "Class: anger\n",
      "\n",
      "Text: @TDsNation i watch all your videos but i like madden better!\n",
      "Class: anger\n",
      "\n",
      "Text: @MichaelSalfino It still destroys Fear The Walking Dead. That show is horrible\n",
      "Class: fear\n",
      "\n",
      "Text: bout to read this article 'Moving the Conversation Forward: Homosexuality &amp; Christianity' from someone in the foursquare church #nervous\n",
      "Class: fear\n",
      "\n",
      "Text: @TimesNow indian army crossed loc into pok to bust terror camp on 20th Sept night?\n",
      "Class: fear\n",
      "\n",
      "Text: Every year I go to universal studios to horror nights as a 3rd wheel lol \n",
      "Class: fear\n",
      "\n",
      "Text: Although this war will be under the guise of combating terrorism it will in fact be a war against poverty, ignorance and just stupidity.\n",
      "Class: fear\n",
      "\n",
      "Text: Thinking about trying some comedy on youtube. Always been fond of it. Time to nut up.  #comedy #maybeoneday #hopefullyfunny #LOL\n",
      "Class: joy\n",
      "\n",
      "Text: @LoriAlan1 Seriously. Digging those eyebrows. #animated\n",
      "Class: joy\n",
      "\n",
      "Text: Tom Phillips being all jovial at the start of this week's show when Joe is strutting out after that video package is quite the juxtaposition\n",
      "Class: joy\n",
      "\n",
      "Text: Top seed Johnson chases double delight at Tour Championship\n",
      "Class: joy\n",
      "\n",
      "Text: Optimism leads to success. - Bill Kerr @Coach__Kerr #success #optimism #goals\n",
      "Class: joy\n",
      "\n",
      "Text: The voice is all about Miley and Alicia this year. No longer about the contestants. #sad @thevoice\n",
      "Class: sadness\n",
      "\n",
      "Text: Niggas murking in each other. In murky water, I try to swim.\n",
      "Class: sadness\n",
      "\n",
      "Text: In serious need of a nap\n",
      "Class: sadness\n",
      "\n",
      "Text: Even a pencil never #stayed  with me until it's #end  \n",
      "Class: sadness\n",
      "\n",
      "Text: @Ren102e906 Just do what you can, don't get discouraged, maybe some prayers for divine intervention to help you would help :)\n",
      "Class: sadness\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:  55%|    | 11/20 [00:07<00:06,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 42.376578001s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 42.344063473s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: I think @Sam_Canaday &amp; @KYLEJDOWSON must actually have to be working like me &amp; @dowson_brady because I havent got any snap chat videos today\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 27.256488443s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '27s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 27.220291161s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '27s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: I think @Sam_Canaday &amp; @KYLEJDOWSON must actually have to be working like me &amp; @dowson_brady because I havent got any snap chat videos today\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 12.157048477s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '12s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 12.125024022s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '12s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: I think @Sam_Canaday &amp; @KYLEJDOWSON must actually have to be working like me &amp; @dowson_brady because I havent got any snap chat videos today\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:  75%|  | 15/20 [00:56<00:27,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 3.51 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...: 100%|| 20/20 [01:03<00:00,  3.19s/it]\n",
      "Processing samples for emotion: fear...:  35%|      | 7/20 [00:05<00:11,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 40.753293368s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '40s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 40.715170105s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '40s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Bout ta get my @dontbreathe on up in here! @WarrenTheaters #nervous #icantholdmybreaththatlong\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 25.637240465s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '25s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 25.593176005s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '25s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Bout ta get my @dontbreathe on up in here! @WarrenTheaters #nervous #icantholdmybreaththatlong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: fear...:  50%|     | 10/20 [00:38<00:54,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 17.76 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: fear...: 100%|| 20/20 [01:04<00:00,  3.22s/it]\n",
      "Processing samples for emotion: joy...:  15%|        | 3/20 [00:02<00:11,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 40.074155343s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '40s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 40.039780245s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '40s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: The smell of freshly cut grass didn't even cheer me up...boy oh boy\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 24.962349721s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 24.922984019s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: The smell of freshly cut grass didn't even cheer me up...boy oh boy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...:  25%|       | 5/20 [00:33<02:05,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 17.96 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...:  95%|| 19/20 [01:02<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 39.505283763s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '39s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 39.474190008s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '39s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: @Geminiak @LondonNPC you're welcome! #wordgeek \\nAlso, good to put a face to the twitter feed, even if it was only a cheery hello! \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 24.399240911s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15, model: gemini-2.5-flash-lite\\nPlease retry in 24.360801703s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: @Geminiak @LondonNPC you're welcome! #wordgeek \\nAlso, good to put a face to the twitter feed, even if it was only a cheery hello! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: joy...: 100%|| 20/20 [01:33<00:00,  4.69s/it]\n",
      "Processing samples for emotion: sadness...:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 18.17 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...:  75%|  | 15/20 [00:29<00:04,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit of 15 requests per minute reached. Waiting for 48.67 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: sadness...: 100%|| 20/20 [01:21<00:00,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to ./results/llm_classification_results/results_samples_20_shots_5.csv\n",
      "Accuracy: 58.75%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.48      0.70      0.57        20\n",
      "        fear       0.75      0.30      0.43        20\n",
      "         joy       0.63      0.85      0.72        20\n",
      "     sadness       0.62      0.50      0.56        20\n",
      "\n",
      "    accuracy                           0.59        80\n",
      "   macro avg       0.62      0.59      0.57        80\n",
      "weighted avg       0.62      0.59      0.57        80\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If you see '429 RESOURCE_EXHAUSTED' errors it's fine, wait until the data gets processed, it will keep retrying until it finishes\n",
    "\n",
    "# Example of running the experiment with 5-shot prompting\n",
    "run_experiment(train_df, test_df, num_test_samples=20, num_shots=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_10_1_1_'></a>[**>>> Exercise 6 (Take home):**](#toc0_)\n",
    "\n",
    "Compare and discuss the overall results of the zero-shot, 1-shot and 5-shot classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "# Answer below using markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comparison and Discussion of Zero-Shot, 1-Shot, and 5-Shot Classification Results**\n",
    "\n",
    "#### **1. Overall Performance Trend**\n",
    "\n",
    "Across the three settings, the performance improves as the number of shots increases.\n",
    "As seen from the results: more shots  the model better understands the classification logic  more accurate predictions.\n",
    "\n",
    "* Zero-shot: Most unstable, the model relies purely on its pretrained knowledge.\n",
    "\n",
    "* 1-shot: Adding one example per emotion noticeably improves predictions for fear and anger.\n",
    "\n",
    "* 5-shot: The most stable overall, with significant improvement especially in the anger category.\n",
    "\n",
    "#### **2. Problems**\n",
    "\n",
    "The fear category remains the most difficult emotion overall, with frequent confusion between anger and joy. The model still shows a tendency to collapse multiple negative emotions into similar predictions, suggesting that semantic boundaries between negative emotional expressions are not fully captured. Moreover, even with 5-shot prompting, sadness continues to be partially confused with anger due to shared wording patterns in social-media style texts. These limitations indicate that prompt examples alone cannot fully resolve category overlap.\n",
    "\n",
    "#### **3. Improvement**\n",
    "\n",
    "* Providing higher-quality few-shot examples, especially those that highlight the distinction between fear vs. anger, could strengthen category boundaries.\n",
    "\n",
    "* Incorporating longer context windows or emotion-specific linguistic cues into prompts may help the model better understand subtle sentiment differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_10_1_2_'></a>[**>>> Exercise 7 (Take home):**](#toc0_)\n",
    "\n",
    "**Case Study:** Check the results' files inside the `results/llm_classification_results` directory and find cases where the **text classification improves with more examples** (pred emotion is right with examples), **cases where it does not improve** (pred emotion always wrong) and **cases where the classification got worse with more examples** (pred emotion goes from right to wrong with examples). For this you need to load the results with pandas and handle the data using its dataframe functions. Discuss about the findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text true_emotion   pred_0  \\\n",
      "3   @LiamCannon1 He's just too raging to type prop...        anger      joy   \n",
      "9   @MaddenFreestyle i turn the game on wanting to...        anger  sadness   \n",
      "12  @DailyMirror i love how theres no outrage that...        anger      joy   \n",
      "22  @ChrissyCostanza and have social anxiety. Ther...         fear      joy   \n",
      "34  We can easily #forgive a #child who is #afrai...         fear  sadness   \n",
      "\n",
      "     pred_1   pred_5  \n",
      "3     anger    anger  \n",
      "9   sadness    anger  \n",
      "12    anger    anger  \n",
      "22     fear  sadness  \n",
      "34     fear     fear   \n",
      "\n",
      "                                                 text true_emotion   pred_0  \\\n",
      "2   I think our defense here at USC is playing wel...        anger      joy   \n",
      "4   i live and die for mchanzo honeymoon crashing ...        anger  sadness   \n",
      "5   @LaureEve I am sitting here wrapped in a fluff...        anger      joy   \n",
      "11  I think @Sam_Canaday &amp; @KYLEJDOWSON must a...        anger  sadness   \n",
      "16             @TrussElise Obama must be fuming.. lol        anger      joy   \n",
      "\n",
      "     pred_1   pred_5  \n",
      "2       joy      joy  \n",
      "4   sadness  sadness  \n",
      "5       joy      joy  \n",
      "11  sadness  sadness  \n",
      "16      joy      joy   \n",
      "\n",
      "                                                 text true_emotion   pred_0  \\\n",
      "28  @madhav_pastey moral of the story, never check...         fear     fear   \n",
      "70  @Eeevah14 don't I know it, try not to fret my ...      sadness  sadness   \n",
      "\n",
      "   pred_1   pred_5  \n",
      "28   fear  sadness  \n",
      "70   fear     fear   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Answer here\n",
    "base_dir = \"./results/llm_classification_results\"\n",
    "\n",
    "# load csv\n",
    "df_0 = pd.read_csv(os.path.join(base_dir, \"results_samples_20_shots_0.csv\"))\n",
    "df_1 = pd.read_csv(os.path.join(base_dir, \"results_samples_20_shots_1.csv\"))\n",
    "df_5 = pd.read_csv(os.path.join(base_dir, \"results_samples_20_shots_5.csv\"))\n",
    "\n",
    "# rename prediction emotion label \n",
    "df_0 = df_0.rename(columns={\"predicted_emotion\": \"pred_0\"})\n",
    "df_1 = df_1.rename(columns={\"predicted_emotion\": \"pred_1\"})\n",
    "df_5 = df_5.rename(columns={\"predicted_emotion\": \"pred_5\"})\n",
    "\n",
    "# align outputs (text + emotions)\n",
    "df_merged = (\n",
    "df_0[[\"text\", \"true_emotion\", \"pred_0\"]]\n",
    ".merge(df_1[[\"text\", \"true_emotion\", \"pred_1\"]], on=[\"text\", \"true_emotion\"])\n",
    ".merge(df_5[[\"text\", \"true_emotion\", \"pred_5\"]], on=[\"text\", \"true_emotion\"])\n",
    ")\n",
    "\n",
    "# Improved case\n",
    "improved_mask = ((df_merged[\"pred_0\"] != df_merged[\"true_emotion\"]) & ((df_merged[\"pred_1\"] == df_merged[\"true_emotion\"]) | (df_merged[\"pred_5\"] == df_merged[\"true_emotion\"])))\n",
    "df_improved = df_merged[improved_mask]\n",
    "\n",
    "# Never improved case\n",
    "no_improve_mask = ((df_merged[\"pred_0\"] != df_merged[\"true_emotion\"]) & (df_merged[\"pred_1\"] != df_merged[\"true_emotion\"]) & (df_merged[\"pred_5\"] != df_merged[\"true_emotion\"]))\n",
    "df_no_improve = df_merged[no_improve_mask]\n",
    "\n",
    "# Got worsed case\n",
    "worse_mask = ((df_merged[\"pred_0\"] == df_merged[\"true_emotion\"]) &((df_merged[\"pred_1\"] != df_merged[\"true_emotion\"]) | (df_merged[\"pred_5\"] != df_merged[\"true_emotion\"])))\n",
    "df_worse = df_merged[worse_mask]\n",
    "\n",
    "# Print results\n",
    "print(df_improved.head(), \"\\n\")\n",
    "print(df_no_improve.head(), \"\\n\")\n",
    "print(df_worse.head(), \"\\n\")\n",
    "\n",
    "# Save as CSV\n",
    "df_improved.to_csv(os.path.join(base_dir, \"cases_improved.csv\"), index=False)\n",
    "df_no_improve.to_csv(os.path.join(base_dir, \"cases_no_improve.csv\"), index=False)\n",
    "df_worse.to_csv(os.path.join(base_dir, \"cases_worse.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Findings**\n",
    "\n",
    "#### 1. Improved Cases  Examples Provide Useful Semantic Framing\n",
    "\n",
    "This improvement occurs because the examples help the LLM better recognize emotion-specific linguistic patterns. Demonstrations clarify category boundaries, especially between semantically similar emotions such as anger vs. sadness or fear vs. sadness. Thus, few-shot prompting provides an effective semantic scaffold that guides the model toward the correct label.\n",
    "\n",
    "#### 2. No Improvement  Examples Do Not Address the Models Semantic Gaps\n",
    "\n",
    "These failures commonly appear in the anger category, suggesting that the examples may not sufficiently cover the full diversity of how anger is expressed. Texts with implicit emotion, sarcasm, weak cues, or ambiguous context remain difficult for the model, and few-shot prompting cannot compensate when the examples lack coverage or the texts emotional signal is too subtle. In these cases, model errors persist due to intrinsic ambiguity or insufficient representativeness in the examples.\n",
    "\n",
    "#### 3. Worse Cases  Examples Introduce Bias or Misleading Patterns\n",
    "\n",
    "This happens when the LLM overfits the linguistic style of the examples, causing it to prioritize example, like phrasing over the actual input. If the examples disproportionately emphasize certain emotional cues, the model may generalize incorrectly and shift ambiguous texts into the wrong category. This demonstrates a classic few-shot limitation: poor or overly narrow examples can misguide the model more than having no examples at all.\n",
    "\n",
    "#### 4. Conclusion\n",
    "\n",
    "The results show that few-shot prompting can improve classification when examples provide diverse and accurate semantic cues. However, when examples lack coverage or introduce stylistic or category biasthe model may fail to improve or even perform worse. \n",
    "\n",
    "**Ultimately, the quality and representativeness of examples matter far more than the number of examples.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_11_'></a>[**2.7 Extra LLM Related Materials:**](#toc0_)\n",
    "So this will be it for the lab, but here are some extra materials if you would like to explore:\n",
    "\n",
    "- **How to use OpenAI ChatGPT model's API (Not Free API):** [Basics Video](https://www.youtube.com/watch?v=e9P7FLi5Zy8), [Basics GitHub](https://github.com/gkamradt/langchain-tutorials/blob/main/chatapi/ChatAPI%20%2B%20LangChain%20Basics.ipynb), [RAG's Basics Video](https://www.youtube.com/watch?v=9AXP7tCI9PI&t=300s), [RAG's Basics GitHub](https://github.com/techleadhd/chatgpt-retrieval)\n",
    "\n",
    "- **Advanced topic - QLoRA (Quantized Low-Rank Adapter):** QLoRA is a method used to make fine-tuning large language models more efficient. It works by adding a small, trainable part (LoRA) to a pre-trained model, while keeping the rest of the model frozen. At the same time, it reduces the size of the models data using a process called quantization, which makes the model require less memory. This allows you to fine-tune large models without needing as much computational power, making it easier to adapt models for specific tasks. Materials: [Paper GitHub](https://github.com/artidoro/qlora?tab=readme-ov-file), [Llama 3 Application Video](https://www.youtube.com/watch?v=YJNbgusTSF0&t=512s),[Llama 3 Application GitHub](https://github.com/adidror005/youtube-videos/blob/main/LLAMA_3_Fine_Tuning_for_Sequence_Classification_Actual_Video.ipynb)\n",
    "\n",
    "- **How to Fine-tune and run local LLMs with the `unsloth` library:** [unsloth tutorials](https://docs.unsloth.ai/models/tutorials-how-to-fine-tune-and-run-llms)\n",
    "\n",
    "- **Google's Agent Development Kit Documentation:** [ADK](https://google.github.io/adk-docs/)\n",
    "\n",
    "- **Build AI agents with LangGraph:** [LangGraph Documentation](https://langchain-ai.github.io/langgraph/concepts/why-langgraph/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fF1woa8YTp5"
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "4e5eiVLOYTp5"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DM2025-Lab2-Exercise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 594.85,
   "position": {
    "height": "40px",
    "left": "723px",
    "right": "20px",
    "top": "80px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
